{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Two:  Sentiment Classification\n",
    "\n",
    "For this exercise you will be using the \"SemEval 2017 task 4\" corpus provided on the module website, available through the following link: https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs918/semeval-tweets.tar.bz2 You will focus particularly on Subtask A, i.e. classifying the overall sentiment of a tweet as positive, negative or neutral.\n",
    "\n",
    "You are requested to produce a Jupyter notebook for the coursework submission. The input to your program is the SemEval data downloaded. Note that TAs need to run your program on their own machine by using the original SemEval data. As such, don‚Äôt submit a Python program that takes as input some preprocessed files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary packages\n",
    "You may import more packages here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import re\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/dcs/large/u2164966/Natural Language Processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test sets\n",
    "testsets = ['twitter-test1.txt', 'twitter-test2.txt', 'twitter-test3.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skeleton: Evaluation code for the test sets\n",
    "def read_test(testset):\n",
    "    '''\n",
    "    readin the testset and return a dictionary\n",
    "    :param testset: str, the file name of the testset to compare\n",
    "    '''\n",
    "    id_gts = {}\n",
    "    with open(testset, 'r', encoding='utf8') as fh:\n",
    "        for line in fh:\n",
    "            fields = line.split('\\t')\n",
    "            tweetid = fields[0]\n",
    "            gt = fields[1]\n",
    "\n",
    "            id_gts[tweetid] = gt\n",
    "\n",
    "    return id_gts\n",
    "\n",
    "\n",
    "def confusion(id_preds, testset, classifier):\n",
    "    '''\n",
    "    print the confusion matrix of {'positive', 'netative'} between preds and testset\n",
    "    :param id_preds: a dictionary of predictions formated as {<tweetid>:<sentiment>, ... }\n",
    "    :param testset: str, the file name of the testset to compare\n",
    "    :classifier: str, the name of the classifier\n",
    "    '''\n",
    "    id_gts = read_test(testset)\n",
    "\n",
    "    gts = []\n",
    "    for m, c1 in id_gts.items():\n",
    "        if c1 not in gts:\n",
    "            gts.append(c1)\n",
    "\n",
    "    gts = ['positive', 'negative', 'neutral']\n",
    "\n",
    "    conf = {}\n",
    "    for c1 in gts:\n",
    "        conf[c1] = {}\n",
    "        for c2 in gts:\n",
    "            conf[c1][c2] = 0\n",
    "\n",
    "    for tweetid, gt in id_gts.items():\n",
    "        if tweetid in id_preds:\n",
    "            pred = id_preds[tweetid]\n",
    "        else:\n",
    "            pred = 'neutral'\n",
    "        conf[pred][gt] += 1\n",
    "\n",
    "    print(''.ljust(12) + '  '.join(gts))\n",
    "\n",
    "    for c1 in gts:\n",
    "        print(c1.ljust(12), end='')\n",
    "        for c2 in gts:\n",
    "            if sum(conf[c1].values()) > 0:\n",
    "                print('%.3f     ' % (conf[c1][c2] / float(sum(conf[c1].values()))), end='')\n",
    "            else:\n",
    "                print('0.000     ', end='')\n",
    "        print('')\n",
    "\n",
    "    print('')\n",
    "\n",
    "\n",
    "def evaluate(id_preds, testset, classifier):\n",
    "    '''\n",
    "    print the macro-F1 score of {'positive', 'netative'} between preds and testset\n",
    "    :param id_preds: a dictionary of predictions formated as {<tweetid>:<sentiment>, ... }\n",
    "    :param testset: str, the file name of the testset to compare\n",
    "    :classifier: str, the name of the classifier\n",
    "    '''\n",
    "    id_gts = read_test(testset)\n",
    "\n",
    "    acc_by_class = {}\n",
    "    for gt in ['positive', 'negative', 'neutral']:\n",
    "        acc_by_class[gt] = {'tp': 0, 'fp': 0, 'tn': 0, 'fn': 0}\n",
    "\n",
    "    catf1s = {}\n",
    "\n",
    "    ok = 0\n",
    "    for tweetid, gt in id_gts.items():\n",
    "        if tweetid in id_preds:\n",
    "            pred = id_preds[tweetid]\n",
    "        else:\n",
    "            pred = 'neutral'\n",
    "\n",
    "        if gt == pred:\n",
    "            ok += 1\n",
    "            acc_by_class[gt]['tp'] += 1\n",
    "        else:\n",
    "            acc_by_class[gt]['fn'] += 1\n",
    "            acc_by_class[pred]['fp'] += 1\n",
    "\n",
    "    catcount = 0\n",
    "    itemcount = 0\n",
    "    macro = {'p': 0, 'r': 0, 'f1': 0}\n",
    "    micro = {'p': 0, 'r': 0, 'f1': 0}\n",
    "    semevalmacro = {'p': 0, 'r': 0, 'f1': 0}\n",
    "\n",
    "    microtp = 0\n",
    "    microfp = 0\n",
    "    microtn = 0\n",
    "    microfn = 0\n",
    "    for cat, acc in acc_by_class.items():\n",
    "        catcount += 1\n",
    "\n",
    "        microtp += acc['tp']\n",
    "        microfp += acc['fp']\n",
    "        microtn += acc['tn']\n",
    "        microfn += acc['fn']\n",
    "\n",
    "        p = 0\n",
    "        if (acc['tp'] + acc['fp']) > 0:\n",
    "            p = float(acc['tp']) / (acc['tp'] + acc['fp'])\n",
    "\n",
    "        r = 0\n",
    "        if (acc['tp'] + acc['fn']) > 0:\n",
    "            r = float(acc['tp']) / (acc['tp'] + acc['fn'])\n",
    "\n",
    "        f1 = 0\n",
    "        if (p + r) > 0:\n",
    "            f1 = 2 * p * r / (p + r)\n",
    "\n",
    "        catf1s[cat] = f1\n",
    "\n",
    "        n = acc['tp'] + acc['fn']\n",
    "\n",
    "        macro['p'] += p\n",
    "        macro['r'] += r\n",
    "        macro['f1'] += f1\n",
    "\n",
    "        if cat in ['positive', 'negative']:\n",
    "            semevalmacro['p'] += p\n",
    "            semevalmacro['r'] += r\n",
    "            semevalmacro['f1'] += f1\n",
    "\n",
    "        itemcount += n\n",
    "\n",
    "    micro['p'] = float(microtp) / float(microtp + microfp)\n",
    "    micro['r'] = float(microtp) / float(microtp + microfn)\n",
    "    micro['f1'] = 2 * float(micro['p']) * micro['r'] / float(micro['p'] + micro['r'])\n",
    "\n",
    "    semevalmacrof1 = semevalmacro['f1'] / 2\n",
    "\n",
    "    print(testset + ' (' + classifier + '): %.3f' % semevalmacrof1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load training set, dev set and testing set\n",
    "Here, you need to load the training set, the development set and the test set. For better classification results, you may need to preprocess tweets before sending them to the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting semeval-tweets.tar.bz2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.11/tarfile.py:2283: RuntimeWarning: The default behavior of tarfile extraction has been changed to disallow common exploits (including CVE-2007-4559). By default, absolute/parent paths are disallowed and some mode bits are cleared. See https://access.redhat.com/articles/7004769 for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# First, extract the compressed archive\n",
    "import tarfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Path to your compressed file\n",
    "compressed_file = 'semeval-tweets.tar.bz2'\n",
    "extraction_dir = 'semeval-tweets'\n",
    "\n",
    "# Extract the archive\n",
    "try:\n",
    "    print(f\"Extracting {compressed_file}...\")\n",
    "    with tarfile.open(compressed_file, 'r:bz2') as tar:\n",
    "        tar.extractall(path=extraction_dir)\n",
    "    print(\"Extraction completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error extracting file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 45101 tweets from twitter-training-data.txt\n",
      "Sentiments distribution in twitter-training-data.txt: {'positive': 15986, 'negative': 8326, 'neutral': 20789}\n",
      "Loaded 2000 tweets from twitter-dev-data.txt\n",
      "Sentiments distribution in twitter-dev-data.txt: {'positive': 703, 'negative': 378, 'neutral': 919}\n",
      "Loaded 3531 tweets from twitter-test1.txt\n",
      "Sentiments distribution in twitter-test1.txt: {'positive': 1470, 'negative': 557, 'neutral': 1504}\n",
      "Loaded 1853 tweets from twitter-test2.txt\n",
      "Sentiments distribution in twitter-test2.txt: {'positive': 982, 'negative': 202, 'neutral': 669}\n",
      "Loaded 2379 tweets from twitter-test3.txt\n",
      "Sentiments distribution in twitter-test3.txt: {'positive': 1033, 'negative': 363, 'neutral': 983}\n"
     ]
    }
   ],
   "source": [
    "# Helper function to count sentiment classes\n",
    "def sentiment_counts(sentiments):\n",
    "    counts = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "    for sentiment in sentiments:\n",
    "        if sentiment in counts:\n",
    "            counts[sentiment] += 1\n",
    "    return counts\n",
    "\n",
    "# Load training set, dev set and testing set\n",
    "data = {}\n",
    "tweetids = {}\n",
    "tweetgts = {}\n",
    "tweets = {}\n",
    "\n",
    "# Array of testsets\n",
    "testsets = ['twitter-test1.txt', 'twitter-test2.txt', 'twitter-test3.txt']\n",
    "\n",
    "# Define base directory where files are located\n",
    "base_dir = os.path.join('semeval-tweets', 'semeval-tweets')\n",
    "\n",
    "# Add dev set to the list of datasets to load\n",
    "datasets = ['twitter-training-data.txt', 'twitter-dev-data.txt'] + testsets\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    data[dataset] = []\n",
    "    tweets[dataset] = []\n",
    "    tweetids[dataset] = []\n",
    "    tweetgts[dataset] = []\n",
    "    \n",
    "    file_path = os.path.join(base_dir, dataset)\n",
    "    \n",
    "    # Read the dataset\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                # Split by tab character\n",
    "                fields = line.strip().split('\\t')\n",
    "                \n",
    "                # Check if line has enough fields\n",
    "                if len(fields) >= 3:\n",
    "                    tweet_id = fields[0]          # First column: tweet ID\n",
    "                    sentiment = fields[1]         # Second column: sentiment label\n",
    "                    tweet_text = fields[2]        # Third column: tweet text\n",
    "                    \n",
    "                    # Store the data\n",
    "                    data[dataset].append((tweet_id, sentiment, tweet_text))\n",
    "                    tweetids[dataset].append(tweet_id)\n",
    "                    tweetgts[dataset].append(sentiment)\n",
    "                    tweets[dataset].append(tweet_text)\n",
    "        \n",
    "        print(f\"Loaded {len(tweets[dataset])} tweets from {dataset}\")\n",
    "        print(f\"Sentiments distribution in {dataset}: {sentiment_counts(tweetgts[dataset])}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {dataset}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build sentiment classifiers\n",
    "You need to create your own classifiers (at least 3 classifiers). For each classifier, you can choose between the bag-of-word features and the word-embedding-based features. Each classifier has to be evaluated over 3 test sets. Make sure your classifier produce consistent performance across the test sets. Marking will be based on the performance over all 5 test sets (2 of them are not provided to you)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: emoji\n",
      "Successfully installed emoji-2.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import html\n",
    "from typing import List, Dict, Optional, Union, Set, Tuple\n",
    "import warnings\n",
    "import emoji\n",
    "\n",
    "# Suppress any warnings to keep the notebook clean\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class TwitterPreprocessor:\n",
    "    \"\"\"\n",
    "    A comprehensive text preprocessing pipeline for Twitter data, \n",
    "    optimized for sentiment analysis tasks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 remove_urls: bool = True,\n",
    "                 remove_mentions: bool = True,\n",
    "                 replace_emojis: bool = True,\n",
    "                 handle_negations: bool = True,\n",
    "                 replace_elongations: bool = True,\n",
    "                 handle_hashtags: bool = True,\n",
    "                 remove_numbers: bool = True):\n",
    "        \"\"\"\n",
    "        Initialize the preprocessor with configurable options.\n",
    "        \n",
    "        Args:\n",
    "            remove_urls: Whether to replace URLs with <URL> tag\n",
    "            remove_mentions: Whether to replace @mentions with <USER> tag\n",
    "            replace_emojis: Whether to replace emojis with semantic tags\n",
    "            handle_negations: Whether to mark words after negation terms\n",
    "            replace_elongations: Whether to normalize elongated words\n",
    "            handle_hashtags: Whether to process hashtags\n",
    "            remove_numbers: Whether to replace numbers with <NUMBER> tag\n",
    "        \"\"\"\n",
    "        self.remove_urls = remove_urls\n",
    "        self.remove_mentions = remove_mentions\n",
    "        self.replace_emojis = replace_emojis\n",
    "        self.handle_negations = handle_negations\n",
    "        self.replace_elongations = replace_elongations\n",
    "        self.handle_hashtags = handle_hashtags\n",
    "        self.remove_numbers = remove_numbers\n",
    "        \n",
    "        # Regex flags for multiline processing\n",
    "        self.flags = re.MULTILINE | re.DOTALL\n",
    "        \n",
    "        # Stopwords and function words that shouldn't be negated\n",
    "        self.non_negatable_words = self._get_non_negatable_words()\n",
    "        \n",
    "        # Compile all regex patterns for efficiency\n",
    "        self._compile_regex_patterns()\n",
    "    \n",
    "    def _compile_regex_patterns(self):\n",
    "        \"\"\"Compile all regex patterns used in preprocessing for better performance.\"\"\"\n",
    "        # Entity patterns\n",
    "        self.url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "        self.email_pattern = re.compile(r'[\\w.+-]+@[\\w-]+\\.(?:[\\w-]\\.?)+[\\w-]')\n",
    "        self.mention_pattern = re.compile(r'@\\w+')\n",
    "        self.hashtag_pattern = re.compile(r'#(\\w+)')\n",
    "        self.hashtag_split_pattern = re.compile(r'(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|_')\n",
    "        self.number_pattern = re.compile(r'\\b[-+]?[\\d,]*\\.?\\d+\\b')\n",
    "        self.emoticon_pattern = self._get_emoticon_patterns()\n",
    "        \n",
    "        # Text feature patterns\n",
    "        self.elongated_pattern = re.compile(r'\\b(\\w*?)(.)\\2{2,}\\b')\n",
    "        self.repeated_punct_pattern = re.compile(r'([!?])\\1{1,}')  # Only for ! and ?\n",
    "        self.ellipsis_pattern = re.compile(r'\\.{3,}')\n",
    "        self.word_split_pattern = re.compile(r'[/\\-_]')\n",
    "        self.all_caps_pattern = re.compile(r'\\b([A-Z]{2,})\\b(?!>)')\n",
    "        self.emphasis_pattern = re.compile(r'\\*(\\w+|\\s+\\w+\\s+)\\*')\n",
    "        \n",
    "        # Contraction and possessive patterns\n",
    "        self.contraction_patterns = self._get_contraction_patterns()\n",
    "        self.possessive_pattern = re.compile(r'(\\w+)\\'s\\b', re.IGNORECASE)\n",
    "        \n",
    "        # Negation pattern - improved to match specific negation terms\n",
    "        self.negation_pattern = re.compile(\n",
    "            r'\\b(?:not|no|never|n\\'t|isn\\'t|aren\\'t|wasn\\'t|weren\\'t|haven\\'t|'\n",
    "            r'hasn\\'t|hadn\\'t|won\\'t|wouldn\\'t|don\\'t|doesn\\'t|didn\\'t)\\b'\n",
    "            r'(?:\\s+(?:so|very|too|that|just|a|the|an|very|really|much|\\w+ly))?'  # Optional intensifiers\n",
    "            r'\\s+(\\w+(?:\\s+\\w+)?)'  # Capture up to 2 words that might be negated\n",
    "        )\n",
    "        \n",
    "        # Double negation pattern - to avoid applying negation twice\n",
    "        self.double_negation_pattern = re.compile(\n",
    "            r'\\b(?:not|no|never|n\\'t)\\b\\s+\\w+\\s+\\b(?:not|no|never|n\\'t)\\b'\n",
    "        )\n",
    "        \n",
    "        # Heart emoticon pattern - needs to be detected before number handling\n",
    "        self.heart_pattern = re.compile(r'<3')\n",
    "        \n",
    "        # Control characters and spacing\n",
    "        self.control_char_pattern = re.compile(r'[\\n\\t\\r]')\n",
    "        self.multi_space_pattern = re.compile(r'\\s+')\n",
    "        \n",
    "        # Special protected tags pattern\n",
    "        self.protected_tags_pattern = re.compile(\n",
    "            r'<(?:URL|USER|EMAIL|NUMBER|HASHTAG|SMILE|LOL|SAD|NEUTRAL|HEART|'\n",
    "            r'REPEAT|ELONG|ALLCAPS|ANGRY|LOVE|EMPHASIS|ELLIPSIS)>|</HASHTAG>'\n",
    "        )\n",
    "        \n",
    "        # Emoji dictionaries for Unicode emoji handling\n",
    "        self.emoji_mappings = self._get_emoji_mappings()\n",
    "    \n",
    "    def _get_emoticon_patterns(self) -> Dict[str, re.Pattern]:\n",
    "        \"\"\"Create patterns for detecting common emoticons.\"\"\"\n",
    "        eyes = r'[8:=;]'\n",
    "        nose = r\"['`\\-^]?\"\n",
    "        \n",
    "        return {\n",
    "            'smile': re.compile(f'{eyes}{nose}[)Dd]+|[(Dd]+{nose}{eyes}'),\n",
    "            'lol': re.compile(f'{eyes}{nose}[pP]+'),\n",
    "            'sad': re.compile(f'{eyes}{nose}\\\\(+|\\\\)+{nose}{eyes}'),\n",
    "            'neutral': re.compile(f'{eyes}{nose}[|\\\\\\\\/]'),\n",
    "            'heart': re.compile(r'‚ô•')  # Moved <3 to separate pattern\n",
    "        }\n",
    "        \n",
    "    def _get_emoji_mappings(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"Define mappings for Unicode emojis to sentiment categories.\"\"\"\n",
    "        return {\n",
    "            'SMILE': [\n",
    "                'üòÄ', 'üòÉ', 'üòÑ', 'üòÅ', 'üòÜ', 'üòä', 'üôÇ', 'üòâ', 'üòå', 'üòç', \n",
    "                'ü•∞', 'üòò', 'üòó', 'üòô', 'üòö', 'üòã', 'üòõ', 'üòù', 'üòú', 'ü§™',\n",
    "                'ü§ó', 'ü§≠', 'ü•≤', '‚ò∫Ô∏è', 'üëç', 'üí™', 'üî•', '‚ú®', 'üíØ', 'üëä',\n",
    "                'üëè', 'üôè', 'ü§ù', 'üëå', 'üëë', 'üíê', 'üåü', '‚≠ê', 'üåà', 'üåû'\n",
    "            ],\n",
    "            'SAD': [\n",
    "                '‚òπÔ∏è', 'üòû', 'üòî', 'üòü', 'üòï', 'üôÅ', 'üò£', 'üòñ', 'üò´', 'üò©',\n",
    "                'ü•∫', 'üò¢', 'üò≠', 'üòÆ‚Äçüí®', 'üò§', 'ü•±', 'üò¥', 'üëé', 'üíî', 'üòø'\n",
    "            ],\n",
    "            'ANGRY': [\n",
    "                'üò†', 'üò°', 'ü§¨', 'üëø', 'üò§', 'üòæ', 'üí¢', 'üóØÔ∏è', '‚ö°', '‚ò†Ô∏è'\n",
    "            ],\n",
    "            'LOL': [\n",
    "                'üòÇ', 'ü§£', 'ü§≠', 'ü§™', 'ü§°'\n",
    "            ],\n",
    "            'NEUTRAL': [\n",
    "                'üòê', 'üòë', 'üò∂', 'ü§ê', 'üò∂‚Äçüå´Ô∏è', 'üòè', 'üòí', 'ü§∑', 'ü§∑‚Äç‚ôÇÔ∏è', \n",
    "                'ü§∑‚Äç‚ôÄÔ∏è', 'üëÄ', 'üßê', 'ü§î'\n",
    "            ],\n",
    "            'HEART': [\n",
    "                '‚ù§Ô∏è', 'üß°', 'üíõ', 'üíö', 'üíô', 'üíú', 'üñ§', 'ü§ç', 'ü§é', '‚ù£Ô∏è',\n",
    "                'üíï', 'üíû', 'üíì', 'üíó', 'üíñ', 'üíò', 'üíù', 'üíü', 'üíå', '‚ô•Ô∏è'\n",
    "            ],\n",
    "            'LOVE': [\n",
    "                'ü•∞', 'üòç', 'üòò', 'üòó', 'üòô', 'üòö', 'üíë', 'üë©‚Äç‚ù§Ô∏è‚Äçüë®', 'üë®‚Äç‚ù§Ô∏è‚Äçüë®', 'üë©‚Äç‚ù§Ô∏è‚Äçüë©',\n",
    "                'üíè', 'üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë®', 'üë®‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë®', 'üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë©'\n",
    "            ],\n",
    "            'PARTY': [\n",
    "                'üéâ', 'üéä', 'üéÇ', 'üéà', 'üéÅ', 'üéÜ', 'üéá', 'üéÄ', 'üçæ', 'ü•Ç'\n",
    "            ],\n",
    "            'FOOD': [\n",
    "                'üçï', 'üçî', 'üçü', 'üå≠', 'üçø', 'üßÇ', 'ü•ì', 'üçñ', 'üçó', 'ü•©',\n",
    "                'üç§', 'üç≥', 'üç≤', 'ü•£', 'ü•ó', 'üçú', 'üçù', 'üç±', 'üçö', 'üçõ',\n",
    "                'üç†', 'üç¢', 'üç£', 'üç§', 'üç•', 'ü•Æ', 'üç°', 'ü•ü', 'ü•†', 'ü•°',\n",
    "                'üç¶', 'üçß', 'üç®', 'üç©', 'üç™', 'üéÇ', 'üç∞', 'üßÅ', 'ü•ß', 'üç´',\n",
    "                'üç¨', 'üç≠', 'üçÆ', 'üçØ', 'üçº', 'ü•õ', '‚òï', 'üçµ', 'üç∂', 'üçæ',\n",
    "                'üç∑', 'üç∏', 'üçπ', 'üç∫', 'üçª', 'ü•Ç', 'ü•É', 'üßÉ', 'üßâ', 'üßä'\n",
    "            ],\n",
    "            'SARCASM': [\n",
    "                'üôÑ', 'üòí', 'üòè', 'ü§¶', 'ü§¶‚Äç‚ôÇÔ∏è', 'ü§¶‚Äç‚ôÄÔ∏è', 'ü§®', 'üßê'\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def _get_contraction_patterns(self) -> Dict[str, str]:\n",
    "        \"\"\"Define mappings for expanding English contractions.\"\"\"\n",
    "        return {\n",
    "            r\"\\bwon\\'t\\b\": \"will not\",\n",
    "            r\"\\bcan\\'t\\b\": \"cannot\",\n",
    "            r\"\\bcan't\\b\": \"cannot\",\n",
    "            r\"\\bn\\'t\\b\": \" not\",\n",
    "            r\"\\bn't\\b\": \" not\",\n",
    "            r\"\\b\\'re\\b\": \" are\",\n",
    "            r\"\\b're\\b\": \" are\",\n",
    "            r\"\\b\\'ve\\b\": \" have\",\n",
    "            r\"\\b've\\b\": \" have\",\n",
    "            r\"\\b\\'ll\\b\": \" will\",\n",
    "            r\"\\b'll\\b\": \" will\",\n",
    "            r\"\\b\\'d\\b\": \" would\",\n",
    "            r\"\\b'd\\b\": \" would\",\n",
    "            r\"\\b\\'m\\b\": \" am\",\n",
    "            r\"\\b'm\\b\": \" am\"\n",
    "        }\n",
    "    \n",
    "    def decode_html_entities(self, text: str) -> str:\n",
    "        \"\"\"Decode HTML entities like &amp; to &.\"\"\"\n",
    "        return html.unescape(text)\n",
    "        \n",
    "    def normalize_unicode(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Normalize Unicode characters and remove control characters.\n",
    "        \n",
    "        Args:\n",
    "            text: Input text\n",
    "            \n",
    "        Returns:\n",
    "            Normalized text with consistent Unicode representation\n",
    "        \"\"\"\n",
    "        # Normalize to NFKD form and remove accents\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        text = ''.join([c for c in text if not unicodedata.combining(c)])\n",
    "        \n",
    "        # Remove control characters\n",
    "        text = self.control_char_pattern.sub(' ', text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def replace_urls(self, text: str) -> str:\n",
    "        \"\"\"Replace URLs with <URL> tag.\"\"\"\n",
    "        if self.remove_urls:\n",
    "            return self.url_pattern.sub('<URL>', text)\n",
    "        return text\n",
    "    \n",
    "    def replace_emails(self, text: str) -> str:\n",
    "        \"\"\"Replace email addresses with <EMAIL> tag.\"\"\"\n",
    "        return self.email_pattern.sub('<EMAIL>', text)\n",
    "    \n",
    "    def replace_mentions(self, text: str) -> str:\n",
    "        \"\"\"Replace user mentions with <USER> tag.\"\"\"\n",
    "        if self.remove_mentions:\n",
    "            return self.mention_pattern.sub('<USER>', text)\n",
    "        return text\n",
    "    \n",
    "    def replace_heart_emoticon(self, text: str) -> str:\n",
    "        \"\"\"Replace heart emoticon with <HEART> tag before number processing.\"\"\"\n",
    "        return self.heart_pattern.sub('<HEART>', text)\n",
    "    \n",
    "    def replace_numbers(self, text: str) -> str:\n",
    "        \"\"\"Replace numeric values with <NUMBER> tag.\"\"\"\n",
    "        if self.remove_numbers:\n",
    "            return self.number_pattern.sub('<NUMBER>', text)\n",
    "        return text\n",
    "    \n",
    "    def process_hashtags(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Process hashtags by splitting them into component words and adding <HASHTAG> tags.\n",
    "        For example: #DataScience -> <HASHTAG> data science </HASHTAG>\n",
    "        Handles both camelCase and underscores.\n",
    "        \"\"\"\n",
    "        if not self.handle_hashtags:\n",
    "            return text\n",
    "            \n",
    "        def split_hashtag(match):\n",
    "            tag = match.group(1)\n",
    "            # Convert camelCase or PascalCase or snake_case to space-separated words\n",
    "            words = self.hashtag_split_pattern.sub(' ', tag)\n",
    "            # Add spaces for all-caps hashtags (e.g., #NASA -> N A S A)\n",
    "            if tag.isupper() and len(tag) > 1:\n",
    "                words = ' '.join(list(words))\n",
    "            return f'<HASHTAG> {words.lower()} </HASHTAG>'\n",
    "            \n",
    "        return self.hashtag_pattern.sub(split_hashtag, text)\n",
    "    \n",
    "    def replace_emoticons(self, text: str) -> str:\n",
    "        \"\"\"Replace text-based emoticons with semantic tags.\"\"\"\n",
    "        if not self.replace_emojis:\n",
    "            return text\n",
    "            \n",
    "        for emotion, pattern in self.emoticon_pattern.items():\n",
    "            text = pattern.sub(f'<{emotion.upper()}>', text)\n",
    "        \n",
    "        return text\n",
    "        \n",
    "    def replace_unicode_emojis(self, text: str) -> str:\n",
    "        \"\"\"Replace Unicode emojis with semantic tags.\"\"\"\n",
    "        if not self.replace_emojis:\n",
    "            return text\n",
    "            \n",
    "        # Extract emojis and their positions\n",
    "        emoji_list = emoji.emoji_list(text)\n",
    "        \n",
    "        # Replace from end to beginning to avoid position shifts\n",
    "        result = text\n",
    "        for item in reversed(emoji_list):\n",
    "            emoji_char = item['emoji']\n",
    "            start, end = item['match_start'], item['match_end']\n",
    "            \n",
    "            # Find which category this emoji belongs to\n",
    "            category = None\n",
    "            for cat, emoji_chars in self.emoji_mappings.items():\n",
    "                if emoji_char in emoji_chars:\n",
    "                    category = cat\n",
    "                    break\n",
    "            \n",
    "            # If found, replace with the category tag\n",
    "            if category:\n",
    "                result = result[:start] + f\" <{category}> \" + result[end:]\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def handle_emphasis(self, text: str) -> str:\n",
    "        \"\"\"Convert *emphasized* text to an <EMPHASIS> tag.\"\"\"\n",
    "        return self.emphasis_pattern.sub(r'<EMPHASIS>\\1</EMPHASIS>', text)\n",
    "    \n",
    "    def handle_ellipsis(self, text: str) -> str:\n",
    "        \"\"\"Replace ellipsis with <ELLIPSIS> tag to distinguish from repeated punctuation.\"\"\"\n",
    "        return self.ellipsis_pattern.sub(' <ELLIPSIS> ', text)\n",
    "    \n",
    "    def expand_contractions(self, text: str) -> str:\n",
    "        \"\"\"Expand common English contractions.\"\"\"\n",
    "        for pattern, replacement in self.contraction_patterns.items():\n",
    "            text = re.sub(pattern, replacement, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def handle_possessives(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Preserve possessive forms instead of expanding them as contractions.\n",
    "        For example: \"competitor's\" should remain as a possessive, not \"competitor is\"\n",
    "        \"\"\"\n",
    "        return self.possessive_pattern.sub(r'\\1s', text)\n",
    "    \n",
    "    def expand_contractions(self, text: str) -> str:\n",
    "        \"\"\"Expand common English contractions.\"\"\"\n",
    "        for pattern, replacement in self.contraction_patterns.items():\n",
    "            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def handle_text_features(self, text: str) -> str:\n",
    "        \"\"\"Process text features like all-caps and elongated words.\"\"\"\n",
    "        # Mark all-caps words and convert to lowercase\n",
    "        text = self.all_caps_pattern.sub(lambda m: f'{m.group(1).lower()}<ALLCAPS>', text)\n",
    "        \n",
    "        # Mark and normalize elongated words\n",
    "        if self.replace_elongations:\n",
    "            text = self.elongated_pattern.sub(lambda m: f'{m.group(1)}{m.group(2)} <ELONG>', text)\n",
    "        \n",
    "        # Mark repeated punctuation (only for ! and ?)\n",
    "        text = self.repeated_punct_pattern.sub(lambda m: f'{m.group(1)} <REPEAT>', text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def mark_negations(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Mark words following negation terms with NEG_ prefix, with improved scope detection.\n",
    "        Only negates sentiment-carrying words, not function words.\n",
    "        \"\"\"\n",
    "        if not self.handle_negations:\n",
    "            return text\n",
    "        \n",
    "        # First check if there's a double negation, which would be a positive\n",
    "        if self.double_negation_pattern.search(text):\n",
    "            # Don't mark negations in double negative constructions\n",
    "            return text\n",
    "            \n",
    "        def negate(match):\n",
    "            negation = match.group(0)\n",
    "            following_words = match.group(1) if match.group(1) else \"\"\n",
    "            \n",
    "            # Split the following words\n",
    "            words = following_words.split()\n",
    "            \n",
    "            # Only negate sentiment-relevant terms and limit the scope\n",
    "            negated_words = []\n",
    "            for word in words:\n",
    "                # Skip negation for stopwords, function words, protected tags\n",
    "                word_lower = word.lower()\n",
    "                if (self.protected_tags_pattern.search(word) or \n",
    "                    word_lower in self.non_negatable_words or\n",
    "                    word in string.punctuation):\n",
    "                    negated_words.append(word)\n",
    "                else:\n",
    "                    # Only negate content words that might carry sentiment\n",
    "                    negated_words.append(f'NEG_{word}')\n",
    "            \n",
    "            # Join the negated words back together\n",
    "            negated_text = ' '.join(negated_words)\n",
    "            \n",
    "            # Return the original negation term followed by the negated words\n",
    "            return negation.replace(following_words, negated_text)\n",
    "            \n",
    "        return self.negation_pattern.sub(negate, text)\n",
    "    \n",
    "    def normalize_spacing(self, text: str) -> str:\n",
    "        \"\"\"Normalize spacing in text.\"\"\"\n",
    "        # Replace multiple spaces with a single space\n",
    "        text = self.multi_space_pattern.sub(' ', text)\n",
    "        # Strip leading and trailing spaces\n",
    "        return text.strip()\n",
    "    \n",
    "    def preprocess(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Apply the complete preprocessing pipeline to input text.\n",
    "        \n",
    "        Args:\n",
    "            text: Raw input text\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text ready for sentiment analysis\n",
    "        \"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return \"\"\n",
    "        \n",
    "        # Step 1: Decode HTML entities\n",
    "        text = self.decode_html_entities(text)\n",
    "            \n",
    "        # Step 2: Basic normalization\n",
    "        text = self.normalize_unicode(text)\n",
    "        \n",
    "        # Step 3: Handle <3 heart emoticon before number processing\n",
    "        text = self.replace_heart_emoticon(text)\n",
    "        \n",
    "        # Step 4: Replace Unicode emojis - must be done early \n",
    "        # before they could be affected by other processing\n",
    "        text = self.replace_unicode_emojis(text)\n",
    "        \n",
    "        # Step 5: Replace entities\n",
    "        text = self.replace_urls(text)\n",
    "        text = self.replace_emails(text)\n",
    "        text = self.replace_mentions(text)\n",
    "        text = self.replace_numbers(text)\n",
    "        \n",
    "        # Step 6: Process hashtags\n",
    "        text = self.process_hashtags(text)\n",
    "        \n",
    "        # Step 7: Replace text-based emoticons\n",
    "        text = self.replace_emoticons(text)\n",
    "        \n",
    "        # Step 8: Handle special text features\n",
    "        text = self.handle_emphasis(text)\n",
    "        text = self.handle_ellipsis(text)\n",
    "        \n",
    "        # Step 9: Handle possessives (before expanding contractions)\n",
    "        text = self.handle_possessives(text)\n",
    "        \n",
    "        # Step 10: Expand contractions\n",
    "        text = self.expand_contractions(text)\n",
    "        \n",
    "        # Step 11: Handle text features\n",
    "        text = self.handle_text_features(text)\n",
    "        \n",
    "        # Step 12: Mark negations (important for sentiment)\n",
    "        text = self.mark_negations(text)\n",
    "        \n",
    "        # Step 13: Final cleanup\n",
    "        text = self.normalize_spacing(text)\n",
    "        \n",
    "        # Step 14: Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def preprocess_batch(self, texts: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Preprocess a batch of texts.\n",
    "        \n",
    "        Args:\n",
    "            texts: List of raw input texts\n",
    "            \n",
    "        Returns:\n",
    "            List of preprocessed texts\n",
    "        \"\"\"\n",
    "        return [self.preprocess(text) for text in texts]\n",
    "\n",
    "    def _get_non_negatable_words(self) -> Set[str]:\n",
    "        \"\"\"Return a set of words that shouldn't be negated.\"\"\"\n",
    "        return {\n",
    "            # Articles\n",
    "            'a', 'an', 'the',\n",
    "            # Prepositions\n",
    "            'in', 'on', 'at', 'by', 'for', 'with', 'about', 'against', 'between', \n",
    "            'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', \n",
    "            'from', 'up', 'down', 'of', 'off',\n",
    "            # Conjunctions\n",
    "            'and', 'but', 'or', 'nor', 'so', 'yet', 'because', 'although', 'since',\n",
    "            # Pronouns\n",
    "            'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them',\n",
    "            'my', 'your', 'his', 'its', 'our', 'their', 'mine', 'yours', 'hers', 'ours', 'theirs',\n",
    "            'this', 'that', 'these', 'those', 'who', 'whom', 'whose', 'which', 'what',\n",
    "            # Other function words\n",
    "            'is', 'am', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n",
    "            'do', 'does', 'did', 'will', 'would', 'shall', 'should', 'can', 'could', 'may',\n",
    "            'might', 'must', 'ought', 'there', 'here', 'now', 'then', 'always', 'never'\n",
    "        }\n",
    "\n",
    "# Example function for tokenization after preprocessing\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Tokenize preprocessed text into words.\n",
    "    \n",
    "    Args:\n",
    "        text: Preprocessed text\n",
    "        \n",
    "    Returns:\n",
    "        List of tokens\n",
    "    \"\"\"\n",
    "    # Simple whitespace tokenization for preprocessed text\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "# Function to show example preprocessing\n",
    "def show_preprocessing_example(preprocessor: TwitterPreprocessor, example_texts: List[str]):\n",
    "    \"\"\"\n",
    "    Demonstrate preprocessing on example texts.\n",
    "    \n",
    "    Args:\n",
    "        preprocessor: Initialized TwitterPreprocessor\n",
    "        example_texts: List of example raw texts\n",
    "    \"\"\"\n",
    "    for i, text in enumerate(example_texts):\n",
    "        processed = preprocessor.preprocess(text)\n",
    "        print(f\"Example {i+1}:\")\n",
    "        print(f\"Original: {text}\")\n",
    "        print(f\"Processed: {processed}\")\n",
    "        print(f\"Tokens: {tokenize(processed)}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1:\n",
      "Original: I absolutely LOVE this new phone!!! The battery life is incredible :D #technology #happy\n",
      "Processed: i absolutely love<allcaps> this new phone! <repeat> the battery life is incredible <smile> <hashtag> technology </hashtag> <hashtag> happy </hashtag>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 2:\n",
      "Original: Just upgraded to the latest iOS 14.5 @Apple and it's not working properly... üò† #disappointed\n",
      "Processed: just upgraded to the latest ios <number> <user> and its not neg_working neg_properly <ellipsis> <angry> <hashtag> disappointed </hashtag>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 3:\n",
      "Original: This movie wasn't as good as everyone said it would be. http://example.com/movie\n",
      "Processed: this movie wasn't neg_as neg_good as everyone said it would be. <url>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 4:\n",
      "Original: @JohnDoe can't believe you didn't like the concert! It was sooooo amazing!! <3\n",
      "Processed: <user> cannot believe you didn't neg_like the concert! it was so <elong> amazing! <repeat> <heart>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 5:\n",
      "Original: The price increased from $49.99 to $59.99 which isn't fair to loyal customers :(\n",
      "Processed: the price increased from $<number> to $<number> which isn't neg_fair to loyal customers <sad>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 6:\n",
      "Original: This restaurant has 5-star service but the food is only so-so. #foodie\n",
      "Processed: this restaurant has <number>-star service but the food is only so-so. <hashtag> foodie </hashtag>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 7:\n",
      "Original: RT @CelebChef: @FoodNetwork Your recipe for lasagna is absolutely to die for! Best I've ever had.\n",
      "Processed: rt<allcaps> <user>: <user> your recipe for lasagna is absolutely to die for! best i have ever had.\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 8:\n",
      "Original: Got my exam results today üò≠üò≠üò≠ But I passed! üéâüéâüéâ\n",
      "Processed: got my exam results today <sad> <sad> <sad> but i passed! <party> <party> <party>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 9:\n",
      "Original: Oh great, another Monday morning meeting. Just what I needed to start my week.\n",
      "Processed: oh great, another monday morning meeting. just what i needed to start my week.\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 10:\n",
      "Original: The paella was muy delicioso! Best Spanish restaurant in town. #yummy\n",
      "Processed: the paella was muy delicioso! best spanish restaurant in town. <hashtag> yummy </hashtag>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 11:\n",
      "Original: I &amp; my friend enjoyed the movie. It was &quot;fantastic&quot;!\n",
      "Processed: i & my friend enjoyed the movie. it was \"fantastic\"!\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 12:\n",
      "Original: I'm in caf√© drinking a latt√© with my fianc√© ‚Äì it's tr√®s magnifique!\n",
      "Processed: i am in cafe drinking a latte with my fiance ‚Äì its tres magnifique!\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 13:\n",
      "Original: CANNOT BELIEVE HOW AMAZING THIS CONCERT IS!!! MIND = BLOWN\n",
      "Processed: cannot<allcaps> believe<allcaps> how<allcaps> amazing<allcaps> this<allcaps> concert<allcaps> is<allcaps>! <repeat> mind<allcaps> = blown<allcaps>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 14:\n",
      "Original: Just finished my workout. #FeelingSoGood #FitLife\n",
      "Processed: just finished my workout. <hashtag> feeling so good </hashtag> <hashtag> fit life </hashtag>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 15:\n",
      "Original: My 2nd time at this restaurant. The 1st was better tbh.\n",
      "Processed: my 2nd time at this restaurant. the 1st was better tbh.\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 16:\n",
      "Original: OMG this new phone is lit AF! IMO it's the best one yet. ROFL at their competitors.\n",
      "Processed: omg<allcaps> this new phone is lit af<allcaps>! imo<allcaps> its the best one yet. rofl<allcaps> at their competitors.\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 17:\n",
      "Original: Check out these reviews https://example.com/rev1 and https://example.com/rev2 before buying\n",
      "Processed: check out these reviews <url> and <url> before buying\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 18:\n",
      "Original: My friend said \"this was great\" but my sister said 'it was terrible'\n",
      "Processed: my friend said \"this was great\" but my sister said 'it was terrible'\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 19:\n",
      "Original: If you like action movies, you'll love this. If not, you'll hate it.\n",
      "Processed: if you like action movies, you will love this. if not, you will hate it.\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 20:\n",
      "Original: I don't think it's not worth the money, but I wouldn't say it's amazing either.\n",
      "Processed: i don't neg_think its not neg_worth the money, but i wouldn't neg_say its amazing either.\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 21:\n",
      "Original: The Jan 15th release was better than the Mar 3rd one. #ProductUpdates\n",
      "Processed: the jan 15th release was better than the mar 3rd one. <hashtag> product updates </hashtag>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 22:\n",
      "Original: New version is better than old one but still worse than the competitor's.\n",
      "Processed: new version is better than old one but still worse than the competitors.\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 23:\n",
      "Original: This product is *absolutely* *incredible* and I *love* it!\n",
      "Processed: this product is <emphasis>absolutely</emphasis> <emphasis>incredible</emphasis> and i <emphasis>love</emphasis> it!\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 24:\n",
      "Original: Started watching the movie, hated the first hour, but the ending was incredible!\n",
      "Processed: started watching the movie, hated the first hour, but the ending was incredible!\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 25:\n",
      "Original: What do you think of the new update? POLL: Love it / Hate it / Neutral\n",
      "Processed: what do you think of the new update? poll<allcaps>: love it / hate it / neutral\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 26:\n",
      "Original: After trying the new restaurant: üçïüë®‚Äçüç≥üëåüíØ\n",
      "Processed: after trying the new restaurant: <food> üë®‚Äçüç≥ <smile> <smile>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 27:\n",
      "Original: Just had the worst customer service experience. #never_shopping_here_again\n",
      "Processed: just had the worst customer service experience. <hashtag> never neg_shopping here again </hashtag>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 28:\n",
      "Original: The concert was... interesting... not what I expected...\n",
      "Processed: the concert was <ellipsis> interesting <ellipsis> not what i expected <ellipsis>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 29:\n",
      "Original: This made me smile :) üòä and laugh üòÇ but also cry üò¢ :'(\n",
      "Processed: this made me smile <smile> <smile> and laugh <lol> but also cry <sad> <sad>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 30:\n",
      "Original: Just ran 5K in 30 mins! #personal_best #running101 #fitness4life\n",
      "Processed: just ran 5k in <number> mins! <hashtag> personal best </hashtag> <hashtag> running101 </hashtag> <hashtag> fitness4life </hashtag>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 31:\n",
      "Original: Spending 3 hours on hold with customer service. So productive! üôÑ\n",
      "Processed: spending <number> hours on hold with customer service. so productive! <sarcasm>\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet 32:\n",
      "Original: I think @TechGuru's review was spot on! The phone camera is superb.\n",
      "Processed: i think <user>'s review was spot on! the phone camera is superb.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create example tweets\n",
    "example_tweets = [\n",
    "    # Basic positive with multiple features\n",
    "    \"I absolutely LOVE this new phone!!! The battery life is incredible :D #technology #happy\",\n",
    "    \n",
    "    # Negative with mention and emoji\n",
    "    \"Just upgraded to the latest iOS 14.5 @Apple and it's not working properly... üò† #disappointed\",\n",
    "    \n",
    "    # Neutral with URL\n",
    "    \"This movie wasn't as good as everyone said it would be. http://example.com/movie\",\n",
    "    \n",
    "    # Mixed sentiment with repeated characters and heart emoticon\n",
    "    \"@JohnDoe can't believe you didn't like the concert! It was sooooo amazing!! <3\",\n",
    "    \n",
    "    # Negative with pricing and emoticon\n",
    "    \"The price increased from $49.99 to $59.99 which isn't fair to loyal customers :(\",\n",
    "    \n",
    "    # Mixed sentiment with hashtag\n",
    "    \"This restaurant has 5-star service but the food is only so-so. #foodie\",\n",
    "    \n",
    "    # Retweet with nested mentions\n",
    "    \"RT @CelebChef: @FoodNetwork Your recipe for lasagna is absolutely to die for! Best I've ever had.\",\n",
    "    \n",
    "    # Multiple emojis with contrasting sentiment\n",
    "    \"Got my exam results today üò≠üò≠üò≠ But I passed! üéâüéâüéâ\",\n",
    "    \n",
    "    # Sarcasm (hard to detect)\n",
    "    \"Oh great, another Monday morning meeting. Just what I needed to start my week.\",\n",
    "    \n",
    "    # Non-English content mixed with English\n",
    "    \"The paella was muy delicioso! Best Spanish restaurant in town. #yummy\",\n",
    "    \n",
    "    # HTML entities\n",
    "    \"I &amp; my friend enjoyed the movie. It was &quot;fantastic&quot;!\",\n",
    "    \n",
    "    # Unicode characters\n",
    "    \"I'm in caf√© drinking a latt√© with my fianc√© ‚Äì it's tr√®s magnifique!\",\n",
    "    \n",
    "    # All caps for emphasis\n",
    "    \"CANNOT BELIEVE HOW AMAZING THIS CONCERT IS!!! MIND = BLOWN\",\n",
    "    \n",
    "    # Hashtag with CamelCase and sentiment\n",
    "    \"Just finished my workout. #FeelingSoGood #FitLife\",\n",
    "    \n",
    "    # Numbers as text\n",
    "    \"My 2nd time at this restaurant. The 1st was better tbh.\",\n",
    "    \n",
    "    # Abbreviations and slang\n",
    "    \"OMG this new phone is lit AF! IMO it's the best one yet. ROFL at their competitors.\",\n",
    "    \n",
    "    # Multiple URLs\n",
    "    \"Check out these reviews https://example.com/rev1 and https://example.com/rev2 before buying\",\n",
    "    \n",
    "    # Mixed quotes\n",
    "    \"My friend said \\\"this was great\\\" but my sister said 'it was terrible'\",\n",
    "    \n",
    "    # Conditional sentiment\n",
    "    \"If you like action movies, you'll love this. If not, you'll hate it.\",\n",
    "    \n",
    "    # Negation with complex structure\n",
    "    \"I don't think it's not worth the money, but I wouldn't say it's amazing either.\",\n",
    "    \n",
    "    # Date references\n",
    "    \"The Jan 15th release was better than the Mar 3rd one. #ProductUpdates\",\n",
    "    \n",
    "    # Comparative sentiment\n",
    "    \"New version is better than old one but still worse than the competitor's.\",\n",
    "    \n",
    "    # Asterisks for emphasis\n",
    "    \"This product is *absolutely* *incredible* and I *love* it!\",\n",
    "    \n",
    "    # Sentiment transition in single tweet\n",
    "    \"Started watching the movie, hated the first hour, but the ending was incredible!\",\n",
    "    \n",
    "    # Special Twitter formatting like polls\n",
    "    \"What do you think of the new update? POLL: Love it / Hate it / Neutral\",\n",
    "    \n",
    "    # Emoji-only sentiment\n",
    "    \"After trying the new restaurant: üçïüë®‚Äçüç≥üëåüíØ\",\n",
    "    \n",
    "    # Multi-word hashtag with underscores\n",
    "    \"Just had the worst customer service experience. #never_shopping_here_again\",\n",
    "    \n",
    "    # Ellipsis usage\n",
    "    \"The concert was... interesting... not what I expected...\",\n",
    "    \n",
    "    # Unicode emojis and emoticons mixed\n",
    "    \"This made me smile :) üòä and laugh üòÇ but also cry üò¢ :'(\",\n",
    "    \n",
    "    # Numbers and symbols in hashtags\n",
    "    \"Just ran 5K in 30 mins! #personal_best #running101 #fitness4life\",\n",
    "    \n",
    "    # Irony with emojis (difficult to detect)\n",
    "    \"Spending 3 hours on hold with customer service. So productive! üôÑ\",\n",
    "    \n",
    "    # Mentions in middle of sentences\n",
    "    \"I think @TechGuru's review was spot on! The phone camera is superb.\"\n",
    "]\n",
    "\n",
    "# Initialize the preprocessor\n",
    "preprocessor = TwitterPreprocessor(\n",
    "    remove_urls=True,\n",
    "    remove_mentions=True,\n",
    "    replace_emojis=True,\n",
    "    handle_negations=True,\n",
    "    replace_elongations=True,\n",
    "    handle_hashtags=True,\n",
    "    remove_numbers=True\n",
    ")\n",
    "\n",
    "# Process each example tweet\n",
    "processed_tweets = []\n",
    "for i, tweet in enumerate(example_tweets):\n",
    "    processed = preprocessor.preprocess(tweet)\n",
    "    processed_tweets.append(processed)\n",
    "    \n",
    "    print(f\"Tweet {i+1}:\")\n",
    "    print(f\"Original: {tweet}\")\n",
    "    print(f\"Processed: {processed}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: dill in /usr/lib/python3.9/site-packages (0.3.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def create_naive_bayes_classifier(features='bow'):\n",
    "    \"\"\"\n",
    "    Create and return a Naive Bayes classifier for tweet sentiment analysis.\n",
    "    \n",
    "    Args:\n",
    "        features: Feature type to use ('bow' for bag-of-words or 'tfidf' for TF-IDF)\n",
    "    \n",
    "    Returns:\n",
    "        A scikit-learn Pipeline that combines preprocessing, feature extraction, and classification\n",
    "    \"\"\"\n",
    "    # Initialize the preprocessor\n",
    "    preprocessor = TwitterPreprocessor(\n",
    "        remove_urls=True,\n",
    "        remove_mentions=True,\n",
    "        replace_emojis=True,\n",
    "        handle_negations=True,\n",
    "        replace_elongations=True,\n",
    "        handle_hashtags=True,\n",
    "        remove_numbers=True\n",
    "    )\n",
    "    \n",
    "    # Select feature extraction method\n",
    "    if features == 'bow':\n",
    "        # Bag of Words vectorizer\n",
    "        vectorizer = CountVectorizer(\n",
    "            analyzer='word',\n",
    "            tokenizer=lambda x: x.split(),  # Simple space tokenization\n",
    "            preprocessor=lambda x: x,  # No additional preprocessing\n",
    "            min_df=5,  # Ignore terms that appear in less than 5 documents\n",
    "            max_df=0.7,  # Ignore terms that appear in more than 70% of documents\n",
    "            ngram_range=(1, 2)  # Include unigrams and bigrams\n",
    "        )\n",
    "    elif features == 'tfidf':\n",
    "        # TF-IDF vectorizer\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            analyzer='word',\n",
    "            tokenizer=lambda x: x.split(),\n",
    "            preprocessor=lambda x: x,\n",
    "            min_df=5,\n",
    "            max_df=0.7,\n",
    "            ngram_range=(1, 2),\n",
    "            use_idf=True,\n",
    "            sublinear_tf=True  # Apply sublinear tf scaling\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported feature type: {features}\")\n",
    "    \n",
    "    # Create a pipeline\n",
    "    nb_pipeline = Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('classifier', MultinomialNB(alpha=1.0))  # Laplace smoothing\n",
    "    ])\n",
    "    \n",
    "    return nb_pipeline, preprocessor\n",
    "\n",
    "def train_naive_bayes(tweets, labels, features='bow'):\n",
    "    \"\"\"\n",
    "    Train a Naive Bayes classifier on tweet data.\n",
    "    \n",
    "    Args:\n",
    "        tweets: List of raw tweet texts\n",
    "        labels: List of sentiment labels corresponding to tweets\n",
    "        features: Feature type to use ('bow' or 'tfidf')\n",
    "    \n",
    "    Returns:\n",
    "        Trained classifier pipeline and preprocessor\n",
    "    \"\"\"\n",
    "    # Create classifier pipeline and preprocessor\n",
    "    classifier_pipeline, preprocessor = create_naive_bayes_classifier(features)\n",
    "    \n",
    "    # Preprocess tweets\n",
    "    preprocessed_tweets = preprocessor.preprocess_batch(tweets)\n",
    "    \n",
    "    # Train the classifier\n",
    "    classifier_pipeline.fit(preprocessed_tweets, labels)\n",
    "    \n",
    "    return classifier_pipeline, preprocessor\n",
    "\n",
    "def predict_sentiments(classifier_pipeline, preprocessor, tweets):\n",
    "    \"\"\"\n",
    "    Predict sentiments for a list of tweets.\n",
    "    \n",
    "    Args:\n",
    "        classifier_pipeline: Trained classifier pipeline\n",
    "        preprocessor: Initialized TwitterPreprocessor\n",
    "        tweets: List of raw tweet texts\n",
    "    \n",
    "    Returns:\n",
    "        List of predicted sentiment labels\n",
    "    \"\"\"\n",
    "    # Preprocess tweets\n",
    "    preprocessed_tweets = preprocessor.preprocess_batch(tweets)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = classifier_pipeline.predict(preprocessed_tweets)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "def evaluate_classifier(classifier_pipeline, preprocessor, test_tweets, test_labels, average='macro'):\n",
    "    \"\"\"\n",
    "    Evaluate the classifier using various metrics including F1 score.\n",
    "    \n",
    "    Args:\n",
    "        classifier_pipeline: Trained classifier pipeline\n",
    "        preprocessor: Initialized TwitterPreprocessor\n",
    "        test_tweets: List of test tweet texts\n",
    "        test_labels: True labels for test tweets\n",
    "        average: Averaging method for F1 score ('macro', 'micro', 'weighted', or None)\n",
    "                 For multi-class problems, 'macro' treats all classes equally\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing accuracy, precision, recall, and F1 score\n",
    "    \"\"\"\n",
    "    # Get predictions\n",
    "    predictions = predict_sentiments(classifier_pipeline, preprocessor, test_tweets)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions, average=average, zero_division=0)\n",
    "    recall = recall_score(test_labels, predictions, average=average, zero_division=0)\n",
    "    f1 = f1_score(test_labels, predictions, average=average, zero_division=0)\n",
    "    \n",
    "    # Return all metrics as a dictionary\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Naive Bayes classifier with BOW features...\n",
      "\n",
      "== Development Set Metrics ==\n",
      "Accuracy: 0.6240\n",
      "Precision: 0.6095\n",
      "Recall: 0.6314\n",
      "F1 Score: 0.6161\n",
      "\n",
      "== Test Set: twitter-test1.txt ==\n",
      "Accuracy: 0.6174\n",
      "Precision: 0.6034\n",
      "Recall: 0.5780\n",
      "F1 Score: 0.5874\n",
      "\n",
      "== Test Set: twitter-test2.txt ==\n",
      "Accuracy: 0.6611\n",
      "Precision: 0.6429\n",
      "Recall: 0.5794\n",
      "F1 Score: 0.6010\n",
      "\n",
      "== Test Set: twitter-test3.txt ==\n",
      "Accuracy: 0.6116\n",
      "Precision: 0.5737\n",
      "Recall: 0.5685\n",
      "F1 Score: 0.5699\n",
      "\n",
      "== Summary of Results ==\n",
      "Dataset              Accuracy   Precision  Recall     F1 Score  \n",
      "------------------------------------------------------------\n",
      "Dev Set              0.6240     0.6095     0.6314     0.6161    \n",
      "twitter-test1.txt    0.6174     0.6034     0.5780     0.5874    \n",
      "twitter-test2.txt    0.6611     0.6429     0.5794     0.6010    \n",
      "twitter-test3.txt    0.6116     0.5737     0.5685     0.5699    \n",
      "Model saved as naive_bayes_classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "# First train the model on training data\n",
    "train_tweets = tweets['twitter-training-data.txt']\n",
    "train_labels = tweetgts['twitter-training-data.txt']\n",
    "\n",
    "print(\"Training Naive Bayes classifier with BOW features...\")\n",
    "classifier, preprocessor = train_naive_bayes(train_tweets, train_labels, features='bow')\n",
    "\n",
    "# Evaluate on development set\n",
    "dev_tweets = tweets['twitter-dev-data.txt']\n",
    "dev_labels = tweetgts['twitter-dev-data.txt']\n",
    "\n",
    "dev_metrics = evaluate_classifier(classifier, preprocessor, dev_tweets, dev_labels)\n",
    "\n",
    "print('\\n== Development Set Metrics ==')\n",
    "print(f\"Accuracy: {dev_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {dev_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {dev_metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {dev_metrics['f1_score']:.4f}\")  # macro F1 score\n",
    "\n",
    "# List of test datasets\n",
    "test_datasets = ['twitter-test1.txt', 'twitter-test2.txt', 'twitter-test3.txt']\n",
    "\n",
    "# Evaluate on each test set\n",
    "for test_set in test_datasets:\n",
    "    print(f\"\\n== Test Set: {test_set} ==\")\n",
    "    \n",
    "    # Skip if dataset doesn't exist\n",
    "    if test_set not in tweets or test_set not in tweetgts:\n",
    "        print(f\"Dataset {test_set} not found, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    test_tweets = tweets[test_set]\n",
    "    test_labels = tweetgts[test_set]\n",
    "    \n",
    "    # Evaluate model\n",
    "    test_metrics = evaluate_classifier(classifier, preprocessor, test_tweets, test_labels)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {test_metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {test_metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {test_metrics['f1_score']:.4f}\")\n",
    "\n",
    "# Optionally, summarize all metrics in a table\n",
    "print(\"\\n== Summary of Results ==\")\n",
    "print(f\"{'Dataset':<20} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1 Score':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Development set\n",
    "print(f\"{'Dev Set':<20} {dev_metrics['accuracy']:<10.4f} {dev_metrics['precision']:<10.4f} {dev_metrics['recall']:<10.4f} {dev_metrics['f1_score']:<10.4f}\")\n",
    "\n",
    "# Test sets\n",
    "for test_set in test_datasets:\n",
    "    if test_set in tweets and test_set in tweetgts:\n",
    "        test_tweets = tweets[test_set]\n",
    "        test_labels = tweetgts[test_set]\n",
    "        test_metrics = evaluate_classifier(classifier, preprocessor, test_tweets, test_labels)\n",
    "        print(f\"{test_set:<20} {test_metrics['accuracy']:<10.4f} {test_metrics['precision']:<10.4f} {test_metrics['recall']:<10.4f} {test_metrics['f1_score']:<10.4f}\")\n",
    "\n",
    "# Save the classifier and preprocessor to a dill file\n",
    "import dill\n",
    "\n",
    "with open('naive_bayes_classifier.pkl', 'wb') as f:\n",
    "    dill.dump((classifier, preprocessor), f)\n",
    "\n",
    "print(\"Model saved as naive_bayes_classifier.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MaxENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings...\n",
      "Loading Opinion Lexicon...\n",
      "Extracting features from training data...\n",
      "Running grid search for hyperparameter tuning...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best parameters for Logistic Regression found: {'C': 10, 'class_weight': None, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best cross-validation score: 0.60\n",
      "\n",
      "== Development Set Metrics (Solver: lbfgs) ==\n",
      "Accuracy: 0.6095\n",
      "Precision: 0.6157\n",
      "Recall: 0.5627\n",
      "F1 Score: 0.5773\n",
      "Confusion Matrix:\n",
      "[[146 184  48]\n",
      " [ 65 671 183]\n",
      " [ 25 276 402]]\n",
      "\n",
      "== Test Set: twitter-test1.txt (Solver: lbfgs) ==\n",
      "Accuracy: 0.5990\n",
      "Precision: 0.6430\n",
      "Recall: 0.5227\n",
      "F1 Score: 0.5355\n",
      "Confusion Matrix:\n",
      "[[ 132  333   92]\n",
      " [  26 1155  323]\n",
      " [  27  615  828]]\n",
      "\n",
      "== Test Set: twitter-test2.txt (Solver: lbfgs) ==\n",
      "Accuracy: 0.6050\n",
      "Precision: 0.5873\n",
      "Recall: 0.5019\n",
      "F1 Score: 0.5038\n",
      "Confusion Matrix:\n",
      "[[ 33  98  71]\n",
      " [ 13 492 164]\n",
      " [ 16 370 596]]\n",
      "\n",
      "== Test Set: twitter-test3.txt (Solver: lbfgs) ==\n",
      "Accuracy: 0.5965\n",
      "Precision: 0.5839\n",
      "Recall: 0.5239\n",
      "F1 Score: 0.5302\n",
      "Confusion Matrix:\n",
      "[[ 90 207  66]\n",
      " [ 56 756 171]\n",
      " [ 34 426 573]]\n",
      "\n",
      "=== Summary of Results ===\n",
      "\n",
      "Solver: lbfgs\n",
      "Dev Set:\n",
      "  Accuracy : 0.6095\n",
      "  Precision: 0.6157\n",
      "  Recall   : 0.5627\n",
      "  F1 Score : 0.5773\n",
      "  Confusion Matrix:\n",
      "[[146 184  48]\n",
      " [ 65 671 183]\n",
      " [ 25 276 402]]\n",
      "\n",
      "Test Set: twitter-test1.txt\n",
      "  Accuracy : 0.5990\n",
      "  Precision: 0.6430\n",
      "  Recall   : 0.5227\n",
      "  F1 Score : 0.5355\n",
      "  Confusion Matrix:\n",
      "[[ 132  333   92]\n",
      " [  26 1155  323]\n",
      " [  27  615  828]]\n",
      "\n",
      "Test Set: twitter-test2.txt\n",
      "  Accuracy : 0.6050\n",
      "  Precision: 0.5873\n",
      "  Recall   : 0.5019\n",
      "  F1 Score : 0.5038\n",
      "  Confusion Matrix:\n",
      "[[ 33  98  71]\n",
      " [ 13 492 164]\n",
      " [ 16 370 596]]\n",
      "\n",
      "Test Set: twitter-test3.txt\n",
      "  Accuracy : 0.5965\n",
      "  Precision: 0.5839\n",
      "  Recall   : 0.5239\n",
      "  F1 Score : 0.5302\n",
      "  Confusion Matrix:\n",
      "[[ 90 207  66]\n",
      " [ 56 756 171]\n",
      " [ 34 426 573]]\n",
      "\n",
      "Model saved as maxent_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 1) Load GloVe Embeddings\n",
    "# -----------------------------------------------\n",
    "def load_glove_embeddings(glove_file_path, embedding_dim=100):\n",
    "    \"\"\"\n",
    "    Load GloVe embeddings into a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        glove_file_path (str): Path to the GloVe file (e.g. 'glove.6B.100d.txt').\n",
    "        embedding_dim (int): Dimensionality of the embeddings.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Mapping of words to their embedding vectors.\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            if len(vector) == embedding_dim:\n",
    "                embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 2) Load Opinion Lexicon (English)\n",
    "# -----------------------------------------------\n",
    "def load_opinion_lexicon(positive_file, negative_file):\n",
    "    \"\"\"\n",
    "    Load the Opinion Lexicon from the specified positive and negative word files.\n",
    "    \n",
    "    Args:\n",
    "        positive_file (str): Path to the file containing positive words.\n",
    "        negative_file (str): Path to the file containing negative words.\n",
    "    \n",
    "    Returns:\n",
    "        (set, set): A tuple containing the set of positive words and the set of negative words.\n",
    "    \"\"\"\n",
    "    positive_words = set()\n",
    "    negative_words = set()\n",
    "    \n",
    "    with open(positive_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith(';'):\n",
    "                positive_words.add(line.lower())\n",
    "                \n",
    "    with open(negative_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith(';'):\n",
    "                negative_words.add(line.lower())\n",
    "                \n",
    "    return positive_words, negative_words\n",
    "\n",
    "# Global lexicon sets (to be loaded in main)\n",
    "GLOBAL_POSITIVE_WORDS = set()\n",
    "GLOBAL_NEGATIVE_WORDS = set()\n",
    "\n",
    "def get_sentiment_features(tweet):\n",
    "    \"\"\"\n",
    "    Compute sentiment features using the Opinion Lexicon.\n",
    "    \n",
    "    Args:\n",
    "        tweet (str): Tweet text.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Array with [positive_count, negative_count, compound_score].\n",
    "    \"\"\"\n",
    "    tokens = tweet.lower().split()\n",
    "    pos_count = sum(1 for token in tokens if token in GLOBAL_POSITIVE_WORDS)\n",
    "    neg_count = sum(1 for token in tokens if token in GLOBAL_NEGATIVE_WORDS)\n",
    "    total = len(tokens) if tokens else 1\n",
    "    # Compound score: normalized difference between positive and negative counts\n",
    "    compound = (pos_count - neg_count) / total\n",
    "    return np.array([pos_count, neg_count, compound])\n",
    "\n",
    "def tweet_to_combined_features(tweet, glove_embeddings, embedding_dim=100):\n",
    "    \"\"\"\n",
    "    Convert a tweet into a combined feature vector consisting of:\n",
    "      - The average GloVe embedding (dense features)\n",
    "      - Sentiment scores from the Opinion Lexicon (lexicon-based features)\n",
    "    \n",
    "    Args:\n",
    "        tweet (str): Preprocessed tweet text.\n",
    "        glove_embeddings (dict): Loaded GloVe embeddings.\n",
    "        embedding_dim (int): Dimensionality of the GloVe embeddings.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Combined feature vector.\n",
    "    \"\"\"\n",
    "    # Compute average GloVe embedding\n",
    "    tokens = tweet.split()  # Assuming text has already been preprocessed\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        if token in glove_embeddings:\n",
    "            vectors.append(glove_embeddings[token])\n",
    "        else:\n",
    "            vectors.append(np.zeros(embedding_dim))\n",
    "    glove_feature = np.mean(vectors, axis=0) if vectors else np.zeros(embedding_dim)\n",
    "    \n",
    "    # Compute sentiment features from Opinion Lexicon\n",
    "    sentiment_feature = get_sentiment_features(tweet)\n",
    "    \n",
    "    # Concatenate both feature sets\n",
    "    combined_feature = np.concatenate([glove_feature, sentiment_feature])\n",
    "    return combined_feature\n",
    "\n",
    "def prepare_combined_features(tweets_list, glove_embeddings, embedding_dim=100):\n",
    "    \"\"\"\n",
    "    Prepare a feature matrix by converting each tweet into its combined feature vector.\n",
    "    \n",
    "    Args:\n",
    "        tweets_list (list): List of preprocessed tweet texts.\n",
    "        glove_embeddings (dict): Loaded GloVe embeddings.\n",
    "        embedding_dim (int): Dimensionality of the GloVe embeddings.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: 2D array where each row is a combined tweet vector.\n",
    "    \"\"\"\n",
    "    features = np.array([tweet_to_combined_features(tweet, glove_embeddings, embedding_dim)\n",
    "                         for tweet in tweets_list])\n",
    "    return features\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 3) Evaluation Functions\n",
    "# -----------------------------------------------\n",
    "def evaluate_classifier(classifier, preprocessor, tweets, labels):\n",
    "    \"\"\"\n",
    "    Evaluate the classifier by preprocessing tweets, extracting features,\n",
    "    predicting sentiments, and computing evaluation metrics.\n",
    "    \n",
    "    Args:\n",
    "        classifier: Trained classifier.\n",
    "        preprocessor: Preprocessor instance with a 'preprocess' method.\n",
    "        tweets (list): List of raw tweet texts.\n",
    "        labels (list): True sentiment labels.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with 'accuracy', 'precision', 'recall', and 'f1_score'.\n",
    "    \"\"\"\n",
    "    # Preprocess tweets using the provided preprocessor\n",
    "    processed_tweets = [preprocessor.preprocess(tweet) for tweet in tweets]\n",
    "    # Use the global glove embeddings and embedding_dim variables with combined features\n",
    "    X = prepare_combined_features(processed_tweets, global_glove_embeddings, global_embedding_dim)\n",
    "    predictions = classifier.predict(X)\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(labels, predictions),\n",
    "        'precision': precision_score(labels, predictions, average='macro'),\n",
    "        'recall': recall_score(labels, predictions, average='macro'),\n",
    "        'f1_score': f1_score(labels, predictions, average='macro')\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def predict_sentiments_maxent(classifier, preprocessor, tweets):\n",
    "    \"\"\"\n",
    "    Predict sentiments for a list of tweets using the classifier.\n",
    "    \n",
    "    Args:\n",
    "        classifier: Trained classifier.\n",
    "        preprocessor: Preprocessor instance with a 'preprocess' method.\n",
    "        tweets (list): List of raw tweet texts.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Predicted sentiment labels.\n",
    "    \"\"\"\n",
    "    processed_tweets = [preprocessor.preprocess(tweet) for tweet in tweets]\n",
    "    X = prepare_combined_features(processed_tweets, global_glove_embeddings, global_embedding_dim)\n",
    "    return classifier.predict(X)\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 4) Maximum Entropy Classifier with Grid Search\n",
    "# -----------------------------------------------\n",
    "def run_grid_search(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Run grid search on a logistic regression (MaxEnt) classifier with multiple solvers,\n",
    "    penalties, and class_weight options. Returns the best logistic regression estimator.\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    # Define parameter grids for different solvers\n",
    "    param_grid_lr = [\n",
    "        {\n",
    "            'solver': ['lbfgs'],\n",
    "            'penalty': ['l2'],\n",
    "            'C': [0.01, 0.1, 1, 10, 100],\n",
    "            'class_weight': [None, 'balanced'],\n",
    "            'multi_class': ['multinomial']\n",
    "        },\n",
    "        {\n",
    "            'solver': ['liblinear'],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'C': [0.01, 0.1, 1, 10, 100],\n",
    "            'class_weight': [None, 'balanced'],\n",
    "            'multi_class': ['ovr']  # liblinear supports only one-vs-rest\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    grid_search_lr = GridSearchCV(estimator=lr, param_grid=param_grid_lr, cv=5,\n",
    "                                  scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    grid_search_lr.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters for Logistic Regression found:\", grid_search_lr.best_params_)\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(grid_search_lr.best_score_))\n",
    "    \n",
    "    best_lr = grid_search_lr.best_estimator_\n",
    "    return best_lr\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 5) Main Function\n",
    "# -----------------------------------------------\n",
    "def main():\n",
    "    # Path to the GloVe file and embedding dimensions\n",
    "    glove_file_path = 'glove.6B.100d.txt'  # Update this path as needed\n",
    "    embedding_dim = 100\n",
    "\n",
    "    # Load GloVe embeddings and assign to global variables\n",
    "    print(\"Loading GloVe embeddings...\")\n",
    "    glove_embeddings = load_glove_embeddings(glove_file_path, embedding_dim)\n",
    "    global global_glove_embeddings, global_embedding_dim\n",
    "    global_glove_embeddings = glove_embeddings\n",
    "    global_embedding_dim = embedding_dim\n",
    "\n",
    "    # Load Opinion Lexicon from provided files\n",
    "    positive_lexicon_file = 'positive-words.txt'\n",
    "    negative_lexicon_file = 'negative-words.txt'\n",
    "    print(\"Loading Opinion Lexicon...\")\n",
    "    global GLOBAL_POSITIVE_WORDS, GLOBAL_NEGATIVE_WORDS\n",
    "    GLOBAL_POSITIVE_WORDS, GLOBAL_NEGATIVE_WORDS = load_opinion_lexicon(positive_lexicon_file, negative_lexicon_file)\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # Define data from your tweet-processing pipeline\n",
    "    # (Assumes tweets and tweetgts dictionaries are defined elsewhere)\n",
    "    train_tweets = tweets['twitter-training-data.txt']\n",
    "    train_labels = tweetgts['twitter-training-data.txt']\n",
    "\n",
    "    # Development set\n",
    "    dev_tweets = tweets['twitter-dev-data.txt']\n",
    "    dev_labels = tweetgts['twitter-dev-data.txt']\n",
    "\n",
    "    # Test sets\n",
    "    test_datasets = ['twitter-test1.txt', 'twitter-test2.txt', 'twitter-test3.txt']\n",
    "    # ---------------------------------------------------------------\n",
    "\n",
    "    # Instantiate your preprocessor (assumed to be defined elsewhere)\n",
    "    preprocessor = TwitterPreprocessor(\n",
    "        remove_urls=True,\n",
    "        remove_mentions=True,\n",
    "        replace_emojis=True,\n",
    "        handle_negations=True,\n",
    "        replace_elongations=True,\n",
    "        handle_hashtags=True,\n",
    "        remove_numbers=True\n",
    "    )\n",
    "    \n",
    "    # Prepare feature matrices for training data\n",
    "    print(\"Extracting features from training data...\")\n",
    "    # Note: It is assumed that the tweets in train_tweets are raw texts.\n",
    "    processed_train = [preprocessor.preprocess(tweet) for tweet in train_tweets]\n",
    "    X_train = prepare_combined_features(processed_train, glove_embeddings, embedding_dim)\n",
    "    \n",
    "    # Run grid search to find the best classifier\n",
    "    print(\"Running grid search for hyperparameter tuning...\")\n",
    "    best_model = run_grid_search(X_train, train_labels)\n",
    "    classifier = best_model  # For clarity in evaluation code\n",
    "\n",
    "    # Define the solver used\n",
    "    solver = \"lbfgs\"\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Evaluate on Dev Set\n",
    "    # ----------------------------\n",
    "    dev_metrics = evaluate_classifier(classifier, preprocessor, dev_tweets, dev_labels)\n",
    "    dev_predictions = predict_sentiments_maxent(classifier, preprocessor, dev_tweets)\n",
    "    dev_cm = confusion_matrix(dev_labels, dev_predictions)\n",
    "    \n",
    "    print(f\"\\n== Development Set Metrics (Solver: {solver}) ==\")\n",
    "    print(f\"Accuracy: {dev_metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {dev_metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {dev_metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {dev_metrics['f1_score']:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(dev_cm)\n",
    "    \n",
    "    results = {}\n",
    "    results[solver] = {\n",
    "        'dev': {\n",
    "            'metrics': dev_metrics,\n",
    "            'confusion_matrix': dev_cm\n",
    "        },\n",
    "        'tests': {}\n",
    "    }\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Evaluate on Test Sets\n",
    "    # ----------------------------\n",
    "    for test_set in test_datasets:\n",
    "        print(f\"\\n== Test Set: {test_set} (Solver: {solver}) ==\")\n",
    "        if test_set not in tweets or test_set not in tweetgts:\n",
    "            print(f\"Dataset {test_set} not found, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        test_tweets = tweets[test_set]\n",
    "        test_labels = tweetgts[test_set]\n",
    "        \n",
    "        test_metrics = evaluate_classifier(classifier, preprocessor, test_tweets, test_labels)\n",
    "        test_predictions = predict_sentiments_maxent(classifier, preprocessor, test_tweets)\n",
    "        test_cm = confusion_matrix(test_labels, test_predictions)\n",
    "        \n",
    "        print(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "        print(f\"Precision: {test_metrics['precision']:.4f}\")\n",
    "        print(f\"Recall: {test_metrics['recall']:.4f}\")\n",
    "        print(f\"F1 Score: {test_metrics['f1_score']:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(test_cm)\n",
    "        \n",
    "        results[solver]['tests'][test_set] = {\n",
    "            'metrics': test_metrics,\n",
    "            'confusion_matrix': test_cm\n",
    "        }\n",
    "    \n",
    "    # ============================\n",
    "    # Summary of Results\n",
    "    # ============================\n",
    "    print(\"\\n=== Summary of Results ===\")\n",
    "    for solver_key, data in results.items():\n",
    "        dev = data['dev']['metrics']\n",
    "        print(f\"\\nSolver: {solver_key}\")\n",
    "        print(\"Dev Set:\")\n",
    "        print(f\"  Accuracy : {dev['accuracy']:.4f}\")\n",
    "        print(f\"  Precision: {dev['precision']:.4f}\")\n",
    "        print(f\"  Recall   : {dev['recall']:.4f}\")\n",
    "        print(f\"  F1 Score : {dev['f1_score']:.4f}\")\n",
    "        print(\"  Confusion Matrix:\")\n",
    "        print(data['dev']['confusion_matrix'])\n",
    "        \n",
    "        for test_set, test_data in data['tests'].items():\n",
    "            test_metrics = test_data['metrics']\n",
    "            print(f\"\\nTest Set: {test_set}\")\n",
    "            print(f\"  Accuracy : {test_metrics['accuracy']:.4f}\")\n",
    "            print(f\"  Precision: {test_metrics['precision']:.4f}\")\n",
    "            print(f\"  Recall   : {test_metrics['recall']:.4f}\")\n",
    "            print(f\"  F1 Score : {test_metrics['f1_score']:.4f}\")\n",
    "            print(\"  Confusion Matrix:\")\n",
    "            print(test_data['confusion_matrix'])\n",
    "\n",
    "    # ----------------------------\n",
    "    # Save the classifier and preprocessor to a pickle file using dill\n",
    "    # ----------------------------\n",
    "    with open('maxent_model.pkl', 'wb') as f:\n",
    "        dill.dump((classifier, preprocessor), f)\n",
    "    print(\"\\nModel saved as maxent_model.pkl\")\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-18 15:03:41--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2025-03-18 15:03:41--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2025-03-18 15:03:42--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‚Äòglove.6B.zip‚Äô\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  2.39MB/s    in 4m 10s  \n",
      "\n",
      "2025-03-18 15:07:53 (3.29 MB/s) - ‚Äòglove.6B.zip‚Äô saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "!unzip glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs918_assignment_2.ipynb  glove.6B.300d.txt  semeval-tweets\n",
      "glove.6B.100d.txt\t  glove.6B.50d.txt   semeval-tweets.tar.bz2\n",
      "glove.6B.200d.txt\t  glove.6B.zip\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document length statistics:\n",
      "- Min length: 2\n",
      "- Max length: 65\n",
      "- Mean length: 20.97\n",
      "- Median length: 21.00\n",
      "- Standard deviation: 6.01\n",
      "- 95th percentile: 30.00\n",
      "\n",
      "Recommended maximum sequence length: 30\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting max_sequence_length = 30\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "preprocessor = TwitterPreprocessor(\n",
    "    remove_urls=True,\n",
    "    remove_mentions=True,\n",
    "    replace_emojis=True,\n",
    "    handle_negations=True,\n",
    "    replace_elongations=True,\n",
    "    handle_hashtags=True,\n",
    "    remove_numbers=True\n",
    ")\n",
    "\n",
    "def analyze_document_lengths(texts, visualize=True, percentile=95):\n",
    "    \"\"\"\n",
    "    Analyze the length of documents in a corpus and determine an appropriate\n",
    "    maximum sequence length.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of text documents/tweets\n",
    "        visualize: Whether to create a visualization of document lengths\n",
    "        percentile: Which percentile to use for max_length recommendation\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing various length statistics\n",
    "    \"\"\"\n",
    "    # Tokenize the texts\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    \n",
    "    # Convert texts to sequences\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    \n",
    "    # Calculate lengths of each sequence\n",
    "    sequence_lengths = [len(seq) for seq in sequences]\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats = {\n",
    "        'max_length': max(sequence_lengths),\n",
    "        'min_length': min(sequence_lengths),\n",
    "        'mean_length': np.mean(sequence_lengths),\n",
    "        'median_length': np.median(sequence_lengths),\n",
    "        'std_length': np.std(sequence_lengths),\n",
    "        f'{percentile}th_percentile': np.percentile(sequence_lengths, percentile)\n",
    "    }\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Document length statistics:\")\n",
    "    print(f\"- Min length: {stats['min_length']}\")\n",
    "    print(f\"- Max length: {stats['max_length']}\")\n",
    "    print(f\"- Mean length: {stats['mean_length']:.2f}\")\n",
    "    print(f\"- Median length: {stats['median_length']:.2f}\")\n",
    "    print(f\"- Standard deviation: {stats['std_length']:.2f}\")\n",
    "    print(f\"- {percentile}th percentile: {stats[f'{percentile}th_percentile']:.2f}\")\n",
    "    \n",
    "    recommended_length = int(stats[f'{percentile}th_percentile'])\n",
    "    print(f\"\\nRecommended maximum sequence length: {recommended_length}\")\n",
    "    \n",
    "    # Visualize the distribution of sequence lengths\n",
    "    if visualize:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(sequence_lengths, bins=50, alpha=0.7)\n",
    "        plt.axvline(recommended_length, color='r', linestyle='dashed', linewidth=2, \n",
    "                   label=f'{percentile}th Percentile: {recommended_length}')\n",
    "        plt.axvline(stats['mean_length'], color='g', linestyle='dashed', linewidth=2,\n",
    "                   label=f'Mean: {stats[\"mean_length\"]:.2f}')\n",
    "        plt.axvline(stats['median_length'], color='y', linestyle='dashed', linewidth=2,\n",
    "                   label=f'Median: {stats[\"median_length\"]:.2f}')\n",
    "        plt.xlabel('Sequence Length')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Distribution of Document Lengths')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return stats, recommended_length\n",
    "\n",
    "# Combine all your training, validation, and test sets to get a complete picture\n",
    "all_texts = []\n",
    "for dataset in ['twitter-training-data.txt', 'twitter-dev-data.txt']:\n",
    "    if dataset in tweets:\n",
    "        all_texts.extend(preprocessor.preprocess_batch(tweets[dataset]))\n",
    "\n",
    "# Analyze document lengths\n",
    "stats, recommended_max_length = analyze_document_lengths(all_texts, visualize=True, percentile=95)\n",
    "\n",
    "# Use the recommended length to set max_sequence_length for your model\n",
    "max_sequence_length = recommended_max_length\n",
    "print(f\"Setting max_sequence_length = {max_sequence_length}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic LSTM\n",
    "\n",
    "Despite this seq length of 128 seems to perform better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 0.8679, Train Acc: 0.5811 | Dev Loss: 0.8230, Dev Acc: 0.6150\n",
      "Epoch 2/10 - Train Loss: 0.7933, Train Acc: 0.6305 | Dev Loss: 0.7818, Dev Acc: 0.6440\n",
      "Epoch 3/10 - Train Loss: 0.7624, Train Acc: 0.6471 | Dev Loss: 0.7514, Dev Acc: 0.6580\n",
      "Epoch 4/10 - Train Loss: 0.7402, Train Acc: 0.6573 | Dev Loss: 0.7446, Dev Acc: 0.6650\n",
      "Epoch 5/10 - Train Loss: 0.7181, Train Acc: 0.6721 | Dev Loss: 0.7407, Dev Acc: 0.6660\n",
      "Epoch 6/10 - Train Loss: 0.6953, Train Acc: 0.6854 | Dev Loss: 0.7417, Dev Acc: 0.6615\n",
      "Epoch 7/10 - Train Loss: 0.6714, Train Acc: 0.6983 | Dev Loss: 0.7323, Dev Acc: 0.6700\n",
      "Epoch 8/10 - Train Loss: 0.6435, Train Acc: 0.7128 | Dev Loss: 0.7337, Dev Acc: 0.6660\n",
      "Epoch 9/10 - Train Loss: 0.6152, Train Acc: 0.7279 | Dev Loss: 0.7477, Dev Acc: 0.6540\n",
      "Epoch 10/10 - Train Loss: 0.5806, Train Acc: 0.7443 | Dev Loss: 0.7701, Dev Acc: 0.6480\n",
      "Final Development set accuracy: 0.6480\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# -------------------------------\n",
    "# Data Preparation for Basic LSTM\n",
    "# -------------------------------\n",
    "# Load your raw tweet texts and labels from files or dataframes\n",
    "# Note: This is a placeholder - you would need to define how to load tweets and labels\n",
    "raw_train_texts = tweets['twitter-training-data.txt']\n",
    "train_labels_str = tweetgts['twitter-training-data.txt']\n",
    "raw_dev_texts = tweets['twitter-dev-data.txt']\n",
    "dev_labels_str = tweetgts['twitter-dev-data.txt']\n",
    "\n",
    "# Preprocess the tweets - this assumes a TwitterPreprocessor is defined elsewhere\n",
    "preprocessor = TwitterPreprocessor(\n",
    "    remove_urls=True,\n",
    "    remove_mentions=True,\n",
    "    replace_emojis=True,\n",
    "    handle_negations=True,\n",
    "    replace_elongations=True,\n",
    "    handle_hashtags=True,\n",
    "    remove_numbers=True\n",
    ")\n",
    "\n",
    "# Preprocess the tweets\n",
    "train_texts = preprocessor.preprocess_batch(raw_train_texts)\n",
    "dev_texts = preprocessor.preprocess_batch(raw_dev_texts)\n",
    "\n",
    "# Encode sentiment labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_int = label_encoder.fit_transform(train_labels_str)\n",
    "dev_labels_int = label_encoder.transform(dev_labels_str)\n",
    "\n",
    "# Tokenizer parameters - using 5,000 as per requirements\n",
    "max_num_words = 5000\n",
    "max_sequence_length = 128   # 128 to encapsulate eveything\n",
    "embedding_dim = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_num_words)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Convert tweets to sequences and pad them\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "train_data = pad_sequences(train_sequences, maxlen=max_sequence_length)\n",
    "dev_sequences = tokenizer.texts_to_sequences(dev_texts)\n",
    "dev_data = pad_sequences(dev_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# -------------------------------\n",
    "# Prepare the GloVe Embedding Matrix\n",
    "# -------------------------------\n",
    "glove_file_path = \"glove.6B.100d.txt\"  # Using the 100d GloVe embeddings\n",
    "embedding_index = {}\n",
    "with open(glove_file_path, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs\n",
    "\n",
    "num_words = min(max_num_words, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_num_words:\n",
    "        continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# -------------------------------\n",
    "# Prepare Torch Tensors and DataLoaders\n",
    "# -------------------------------\n",
    "train_tensor = torch.tensor(train_data, dtype=torch.long)\n",
    "train_labels_tensor = torch.tensor(train_labels_int, dtype=torch.long)\n",
    "dev_tensor = torch.tensor(dev_data, dtype=torch.long)\n",
    "dev_labels_tensor = torch.tensor(dev_labels_int, dtype=torch.long)\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(train_tensor, train_labels_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_dataset = TensorDataset(dev_tensor, dev_labels_tensor)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size)\n",
    "\n",
    "# -------------------------------\n",
    "# Define the Basic LSTM Model\n",
    "# -------------------------------\n",
    "class BasicLSTMClassifier(nn.Module):\n",
    "    def __init__(self, num_words, embedding_dim, embedding_matrix, hidden_dim, num_classes):\n",
    "        super(BasicLSTMClassifier, self).__init__()\n",
    "        # Embedding layer with pretrained GloVe embeddings (frozen)\n",
    "        self.embedding = nn.Embedding(num_words, embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False  # Freeze the embedding layer\n",
    "        \n",
    "        # Single LSTM layer (not bidirectional)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Linear classifier layer\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len)\n",
    "        x = self.embedding(x)  # (batch, seq_len, embedding_dim)\n",
    "        # Pass through LSTM\n",
    "        lstm_out, (hidden, _) = self.lstm(x)  # hidden: (1, batch, hidden_dim)\n",
    "        \n",
    "        # Use the final hidden state for classification\n",
    "        hidden = hidden.squeeze(0)  # (batch, hidden_dim)\n",
    "        \n",
    "        # Pass through linear layer for classification\n",
    "        logits = self.fc(hidden)\n",
    "        return logits\n",
    "\n",
    "# -------------------------------\n",
    "# Model Parameters and Instantiation\n",
    "# -------------------------------\n",
    "hidden_dim = 128\n",
    "num_classes = 3  # Assuming 3 sentiment classes (negative, neutral, positive)\n",
    "\n",
    "model = BasicLSTMClassifier(\n",
    "    num_words=num_words,\n",
    "    embedding_dim=embedding_dim,\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# -------------------------------\n",
    "# Training Setup\n",
    "# -------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "\n",
    "# -------------------------------\n",
    "# Training Loop\n",
    "# -------------------------------\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_inputs, batch_labels in train_loader:\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item() * batch_inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += batch_labels.size(0)\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "    \n",
    "    train_loss = epoch_loss / total\n",
    "    train_accuracy = correct / total\n",
    "    \n",
    "    # Evaluate on the development set\n",
    "    model.eval()\n",
    "    dev_loss = 0.0\n",
    "    dev_correct = 0\n",
    "    dev_total = 0\n",
    "    with torch.no_grad():\n",
    "        for dev_inputs, dev_labels in dev_loader:\n",
    "            dev_inputs = dev_inputs.to(device)\n",
    "            dev_labels = dev_labels.to(device)\n",
    "            outputs = model(dev_inputs)\n",
    "            loss = criterion(outputs, dev_labels)\n",
    "            dev_loss += loss.item() * dev_inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            dev_total += dev_labels.size(0)\n",
    "            dev_correct += (predicted == dev_labels).sum().item()\n",
    "    \n",
    "    dev_loss = dev_loss / dev_total\n",
    "    dev_accuracy = dev_correct / dev_total\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f} | Dev Loss: {dev_loss:.4f}, Dev Acc: {dev_accuracy:.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Final Evaluation on Dev Set\n",
    "# -------------------------------\n",
    "model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for dev_inputs, _ in dev_loader:\n",
    "        dev_inputs = dev_inputs.to(device)\n",
    "        outputs = model(dev_inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "print(f\"Final Development set accuracy: {dev_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set: twitter-test1.txt\n",
      "Test Loss: 0.7535\n",
      "Test Accuracy: 0.6621\n",
      "Precision: 0.6566\n",
      "Recall: 0.6195\n",
      "F1 Score: 0.6327\n",
      "Confusion Matrix:\n",
      "[[ 255  245   57]\n",
      " [  77 1066  361]\n",
      " [  72  381 1017]]\n",
      "\n",
      "Evaluating on test set: twitter-test2.txt\n",
      "Test Loss: 0.7091\n",
      "Test Accuracy: 0.6859\n",
      "Precision: 0.6651\n",
      "Recall: 0.6317\n",
      "F1 Score: 0.6423\n",
      "Confusion Matrix:\n",
      "[[ 95  74  33]\n",
      " [ 34 477 158]\n",
      " [ 24 259 699]]\n",
      "\n",
      "Evaluating on test set: twitter-test3.txt\n",
      "Test Loss: 0.8334\n",
      "Test Accuracy: 0.6318\n",
      "Precision: 0.6147\n",
      "Recall: 0.5967\n",
      "F1 Score: 0.6007\n",
      "Confusion Matrix:\n",
      "[[168 161  34]\n",
      " [ 90 708 185]\n",
      " [ 67 339 627]]\n",
      "\n",
      "Basic LSTM model saved as basic_lstm_model.pt\n",
      "Tokenizer, label encoder, and preprocessor saved as tokenizer.pkl, label_encoder.pkl, and preprocessor.pkl respectively.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "import numpy as np\n",
    "import dill  # For serializing objects that pickle might not handle\n",
    "\n",
    "# Iterate through each test set (assumed to be defined in a list called testsets)\n",
    "for test_set in testsets:\n",
    "    print(f\"\\nEvaluating on test set: {test_set}\")\n",
    "    \n",
    "    # Get the raw texts and sentiment labels\n",
    "    test_texts = tweets[test_set]\n",
    "    test_labels_str = tweetgts[test_set]\n",
    "    \n",
    "    # Preprocess the texts using the existing preprocessor\n",
    "    processed_test_texts = preprocessor.preprocess_batch(test_texts)\n",
    "    \n",
    "    # Tokenize and pad sequences\n",
    "    test_sequences = tokenizer.texts_to_sequences(processed_test_texts)\n",
    "    test_data = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
    "    \n",
    "    # Convert to torch tensors\n",
    "    test_tensor = torch.tensor(test_data, dtype=torch.long)\n",
    "    \n",
    "    # Encode sentiment labels to integers using the same label encoder\n",
    "    test_labels_int = label_encoder.transform(test_labels_str)\n",
    "    test_labels_tensor = torch.tensor(test_labels_int, dtype=torch.long)\n",
    "    \n",
    "    # Create a DataLoader for batching - note that we no longer include engineered features\n",
    "    test_dataset = torch.utils.data.TensorDataset(test_tensor, test_labels_tensor)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    test_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass: only pass the tokenized inputs (no engineered features)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_true.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_loss /= total\n",
    "    test_accuracy = correct / total\n",
    "    \n",
    "    # Compute metrics using scikit-learn\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(all_true, all_preds),\n",
    "        'precision': precision_score(all_true, all_preds, average='macro', zero_division=0),\n",
    "        'recall': recall_score(all_true, all_preds, average='macro', zero_division=0),\n",
    "        'f1_score': f1_score(all_true, all_preds, average='macro', zero_division=0)\n",
    "    }\n",
    "    \n",
    "    cm = confusion_matrix(all_true, all_preds)\n",
    "    \n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1_score']:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "# ----------------------------\n",
    "# Save the basic LSTM model and associated components\n",
    "# ----------------------------\n",
    "\n",
    "# Save the basic LSTM model's state dictionary\n",
    "torch.save(model.state_dict(), 'basic_lstm_model.pt')\n",
    "print(\"\\nBasic LSTM model saved as basic_lstm_model.pt\")\n",
    "\n",
    "# Save tokenizer, label encoder, and preprocessor using dill\n",
    "with open('basic_tokenizer.pkl', 'wb') as f:\n",
    "    dill.dump(tokenizer, f)\n",
    "with open('basic_label_encoder.pkl', 'wb') as f:\n",
    "    dill.dump(label_encoder, f)\n",
    "with open('basic_preprocessor.pkl', 'wb') as f:\n",
    "    dill.dump(preprocessor, f)\n",
    "print(\"Tokenizer, label encoder, and preprocessor saved as tokenizer.pkl, label_encoder.pkl, and preprocessor.pkl respectively.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Improved LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Train Loss: 0.8407, Train Acc: 0.5980 | Dev Loss: 0.7575, Dev Acc: 0.6530\n",
      "Epoch 2/15 - Train Loss: 0.7671, Train Acc: 0.6434 | Dev Loss: 0.7299, Dev Acc: 0.6645\n",
      "Epoch 3/15 - Train Loss: 0.7358, Train Acc: 0.6591 | Dev Loss: 0.7237, Dev Acc: 0.6680\n",
      "Epoch 4/15 - Train Loss: 0.7079, Train Acc: 0.6757 | Dev Loss: 0.7389, Dev Acc: 0.6570\n",
      "Epoch 5/15 - Train Loss: 0.6808, Train Acc: 0.6871 | Dev Loss: 0.6991, Dev Acc: 0.6895\n",
      "Epoch 6/15 - Train Loss: 0.6557, Train Acc: 0.7032 | Dev Loss: 0.6856, Dev Acc: 0.6950\n",
      "Epoch 7/15 - Train Loss: 0.6312, Train Acc: 0.7166 | Dev Loss: 0.6908, Dev Acc: 0.6995\n",
      "Epoch 8/15 - Train Loss: 0.6055, Train Acc: 0.7325 | Dev Loss: 0.6923, Dev Acc: 0.6990\n",
      "Epoch 9/15 - Train Loss: 0.5752, Train Acc: 0.7485 | Dev Loss: 0.7094, Dev Acc: 0.6880\n",
      "Epoch 10/15 - Train Loss: 0.5417, Train Acc: 0.7651 | Dev Loss: 0.7282, Dev Acc: 0.6810\n",
      "Epoch 00010: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Early stopping triggered after 10 epochs\n",
      "Final Development set accuracy: 0.6995\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.58      0.62       378\n",
      "     neutral       0.69      0.74      0.71       919\n",
      "    positive       0.73      0.71      0.72       703\n",
      "\n",
      "    accuracy                           0.70      2000\n",
      "   macro avg       0.70      0.68      0.69      2000\n",
      "weighted avg       0.70      0.70      0.70      2000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[220 133  25]\n",
      " [ 82 678 159]\n",
      " [ 26 176 501]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# -------------------------------\n",
    "# Load Opinion Lexicon English Words\n",
    "# -------------------------------\n",
    "def load_opinion_lexicon(filepath):\n",
    "    words = set()\n",
    "    with open(filepath, 'r', encoding='latin-1') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            # Ignore comments and blank lines\n",
    "            if line and not line.startswith(';'):\n",
    "                words.add(line.lower())\n",
    "    return words\n",
    "\n",
    "# Paths to the opinion lexicon files (adjust paths as needed)\n",
    "positive_lexicon_path = \"positive-words.txt\"\n",
    "negative_lexicon_path = \"negative-words.txt\"\n",
    "\n",
    "positive_words = load_opinion_lexicon(positive_lexicon_path)\n",
    "negative_words = load_opinion_lexicon(negative_lexicon_path)\n",
    "\n",
    "# -------------------------------\n",
    "# Additional Feature Engineering Functions\n",
    "# -------------------------------\n",
    "def extract_engineered_features(tweet):\n",
    "    \"\"\"\n",
    "    Extracts engineered features from a tweet:\n",
    "      - Lexicon counts: positive and negative word counts (2 features)\n",
    "      - Ratio of positive to negative words (1 feature)\n",
    "      - Sentiment score: (pos - neg) / (pos + neg) (1 feature)\n",
    "      - Tweet length in words (1 feature)\n",
    "      - Capitalization ratio (1 feature)\n",
    "    Total = 6 features per tweet.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Tokenize and prepare for analysis\n",
    "    tokens = tweet.split()\n",
    "    text_length = len(tokens)\n",
    "    uppercase_count = sum(1 for c in tweet if c.isupper())\n",
    "    \n",
    "    # Lexicon-based counts using Opinion Lexicon\n",
    "    pos_count = sum(1 for t in tokens if t.lower() in positive_words)\n",
    "    neg_count = sum(1 for t in tokens if t.lower() in negative_words)\n",
    "    \n",
    "    # Calculate ratio (handle division by zero)\n",
    "    pos_neg_ratio = pos_count / max(1, neg_count)\n",
    "    \n",
    "    # Calculate sentiment score: (pos - neg) / (pos + neg)\n",
    "    total_sentiment_words = pos_count + neg_count\n",
    "    sentiment_score = 0 if total_sentiment_words == 0 else (pos_count - neg_count) / total_sentiment_words\n",
    "    \n",
    "    # Calculate capitalization ratio\n",
    "    cap_ratio = 0 if len(tweet) == 0 else uppercase_count / len(tweet)\n",
    "    \n",
    "    # Combine all features\n",
    "    features.extend([pos_count, neg_count, pos_neg_ratio, sentiment_score, text_length, cap_ratio])\n",
    "    \n",
    "    return features\n",
    "\n",
    "# -------------------------------\n",
    "# Data Preparation for LSTM (and engineered features)\n",
    "# -------------------------------\n",
    "# Load your raw tweet texts and labels from files or dataframes\n",
    "raw_train_texts = tweets['twitter-training-data.txt']\n",
    "train_labels_str = tweetgts['twitter-training-data.txt']\n",
    "raw_dev_texts = tweets['twitter-dev-data.txt']\n",
    "dev_labels_str = tweetgts['twitter-dev-data.txt']\n",
    "\n",
    "# Instantiate your TwitterPreprocessor (assumed to be defined elsewhere)\n",
    "preprocessor = TwitterPreprocessor(\n",
    "    remove_urls=True,\n",
    "    remove_mentions=True,\n",
    "    replace_emojis=True,\n",
    "    handle_negations=True,\n",
    "    replace_elongations=True,\n",
    "    handle_hashtags=True,\n",
    "    remove_numbers=True\n",
    ")\n",
    "\n",
    "# Preprocess the tweets (for the LSTM branch)\n",
    "train_texts = preprocessor.preprocess_batch(raw_train_texts)\n",
    "dev_texts = preprocessor.preprocess_batch(raw_dev_texts)\n",
    "\n",
    "# Compute engineered features\n",
    "train_engineered = [extract_engineered_features(tweet) for tweet in train_texts]\n",
    "dev_engineered = [extract_engineered_features(tweet) for tweet in dev_texts]\n",
    "\n",
    "# Encode sentiment labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_int = label_encoder.fit_transform(train_labels_str)\n",
    "dev_labels_int = label_encoder.transform(dev_labels_str)\n",
    "\n",
    "# Tokenizer parameters\n",
    "max_num_words = 40000\n",
    "max_sequence_length = 128   # Adjust depending on tweet lengths\n",
    "embedding_dim = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_num_words)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Convert tweets to sequences and pad them\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "train_data = pad_sequences(train_sequences, maxlen=max_sequence_length)\n",
    "dev_sequences = tokenizer.texts_to_sequences(dev_texts)\n",
    "dev_data = pad_sequences(dev_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# -------------------------------\n",
    "# Prepare the GloVe Embedding Matrix\n",
    "# -------------------------------\n",
    "glove_file_path = \"glove.6B.100d.txt\"\n",
    "embedding_index = {}\n",
    "with open(glove_file_path, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs\n",
    "\n",
    "num_words = min(max_num_words, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_num_words:\n",
    "        continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# -------------------------------\n",
    "# Prepare Torch Tensors and DataLoaders\n",
    "# -------------------------------\n",
    "train_tensor = torch.tensor(train_data, dtype=torch.long)\n",
    "train_labels_tensor = torch.tensor(train_labels_int, dtype=torch.long)\n",
    "dev_tensor = torch.tensor(dev_data, dtype=torch.long)\n",
    "dev_labels_tensor = torch.tensor(dev_labels_int, dtype=torch.long)\n",
    "\n",
    "# Engineered features: convert to float tensors\n",
    "train_engineered_tensor = torch.tensor(np.array(train_engineered), dtype=torch.float32)\n",
    "dev_engineered_tensor = torch.tensor(np.array(dev_engineered), dtype=torch.float32)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Combine inputs: sequences and engineered features\n",
    "train_dataset = TensorDataset(train_tensor, train_engineered_tensor, train_labels_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_dataset = TensorDataset(dev_tensor, dev_engineered_tensor, dev_labels_tensor)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size)\n",
    "\n",
    "# -------------------------------\n",
    "# Define an Attention Module\n",
    "# -------------------------------\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        # Compute attention weights from bidirectional LSTM outputs (hidden_dim*2)\n",
    "        self.attn = nn.Linear(hidden_dim * 2, 1)\n",
    "        \n",
    "    def forward(self, lstm_out):\n",
    "        # lstm_out: (batch, seq_len, hidden_dim*2)\n",
    "        weights = self.attn(lstm_out)             # (batch, seq_len, 1)\n",
    "        weights = torch.softmax(weights, dim=1)    # softmax over sequence length\n",
    "        context = torch.sum(weights * lstm_out, dim=1)  # weighted sum: (batch, hidden_dim*2)\n",
    "        return context\n",
    "\n",
    "# -------------------------------\n",
    "# Define the Enhanced LSTM Model\n",
    "# -------------------------------\n",
    "class EnhancedLSTMClassifier(nn.Module):\n",
    "    def __init__(self, num_words, embedding_dim, embedding_matrix, hidden_dim, num_layers,\n",
    "                 num_classes, dropout, num_engineered_features, engineered_hidden_dim):\n",
    "        super(EnhancedLSTMClassifier, self).__init__()\n",
    "        # Embedding layer with pretrained GloVe embeddings (frozen)\n",
    "        self.embedding = nn.Embedding(num_words, embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        # Attention mechanism over LSTM outputs\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        \n",
    "        # Global pooling layers (average and max pooling)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Engineered features branch\n",
    "        self.feat_fc = nn.Linear(num_engineered_features, engineered_hidden_dim)\n",
    "        # Feature gating parameter (learnable scalar)\n",
    "        self.feat_gate = nn.Parameter(torch.ones(1))\n",
    "        \n",
    "        # Combine LSTM branch and engineered features branch\n",
    "        # For LSTM branch, we use attention output (hidden_dim*2), average and max pool (each hidden_dim*2)\n",
    "        lstm_feature_dim = hidden_dim * 2 * 3  # 3 components concatenated\n",
    "        combined_dim = lstm_feature_dim + engineered_hidden_dim\n",
    "        self.fc_combined = nn.Linear(combined_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x, engineered_features):\n",
    "        # x: (batch, seq_len)\n",
    "        x = self.embedding(x)  # (batch, seq_len, embedding_dim)\n",
    "        lstm_out, _ = self.lstm(x)  # (batch, seq_len, hidden_dim*2)\n",
    "        \n",
    "        # Compute attention output\n",
    "        attn_out = self.attention(lstm_out)  # (batch, hidden_dim*2)\n",
    "        \n",
    "        # Global average pooling and max pooling\n",
    "        avg_pool = torch.mean(lstm_out, dim=1)        # (batch, hidden_dim*2)\n",
    "        max_pool, _ = torch.max(lstm_out, dim=1)        # (batch, hidden_dim*2)\n",
    "        \n",
    "        # Concatenate LSTM branch features\n",
    "        lstm_features = torch.cat((attn_out, avg_pool, max_pool), dim=1)  # (batch, hidden_dim*2*3)\n",
    "        lstm_features = self.dropout(lstm_features)\n",
    "        \n",
    "        # Engineered features branch\n",
    "        feat = self.feat_fc(engineered_features)  # (batch, engineered_hidden_dim)\n",
    "        feat = torch.relu(feat)\n",
    "        feat = self.dropout(feat)\n",
    "        # Apply gating: learned scalar controls the contribution of engineered features\n",
    "        feat = self.feat_gate * feat\n",
    "        \n",
    "        # Combine both branches\n",
    "        combined = torch.cat((lstm_features, feat), dim=1)  # (batch, combined_dim)\n",
    "        logits = self.fc_combined(combined)\n",
    "        return logits\n",
    "\n",
    "# -------------------------------\n",
    "# Model Parameters and Instantiation\n",
    "# -------------------------------\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "num_classes = 3\n",
    "dropout = 0.5\n",
    "# Number of engineered features is 6 (2 lexicon counts + 4 additional features)\n",
    "num_engineered_features = 6\n",
    "engineered_hidden_dim = 32\n",
    "\n",
    "model = EnhancedLSTMClassifier(\n",
    "    num_words=num_words,\n",
    "    embedding_dim=embedding_dim,\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=num_layers,\n",
    "    num_classes=num_classes,\n",
    "    dropout=dropout,\n",
    "    num_engineered_features=num_engineered_features,\n",
    "    engineered_hidden_dim=engineered_hidden_dim\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# -------------------------------\n",
    "# Training Setup\n",
    "# -------------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # weight decay for regularization\n",
    "num_epochs = 15\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=2, verbose=True\n",
    ")\n",
    "\n",
    "# Early stopping parameters\n",
    "best_dev_acc = 0\n",
    "patience = 3\n",
    "patience_counter = 0\n",
    "\n",
    "# -------------------------------\n",
    "# Training Loop\n",
    "# -------------------------------\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_inputs, batch_engineered, batch_labels in train_loader:\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "        batch_engineered = batch_engineered.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs, batch_engineered)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item() * batch_inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += batch_labels.size(0)\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "    \n",
    "    train_loss = epoch_loss / total\n",
    "    train_accuracy = correct / total\n",
    "    \n",
    "    # Evaluate on the development set\n",
    "    model.eval()\n",
    "    dev_loss = 0.0\n",
    "    dev_correct = 0\n",
    "    dev_total = 0\n",
    "    with torch.no_grad():\n",
    "        for dev_inputs, dev_engineered, dev_labels in dev_loader:\n",
    "            dev_inputs = dev_inputs.to(device)\n",
    "            dev_engineered = dev_engineered.to(device)\n",
    "            dev_labels = dev_labels.to(device)\n",
    "            outputs = model(dev_inputs, dev_engineered)\n",
    "            loss = criterion(outputs, dev_labels)\n",
    "            dev_loss += loss.item() * dev_inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            dev_total += dev_labels.size(0)\n",
    "            dev_correct += (predicted == dev_labels).sum().item()\n",
    "    \n",
    "    dev_loss = dev_loss / dev_total\n",
    "    dev_accuracy = dev_correct / dev_total\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f} | Dev Loss: {dev_loss:.4f}, Dev Acc: {dev_accuracy:.4f}\")\n",
    "    \n",
    "    # Learning rate scheduling and early stopping\n",
    "    scheduler.step(dev_accuracy)\n",
    "    if dev_accuracy > best_dev_acc:\n",
    "        best_dev_acc = dev_accuracy\n",
    "        patience_counter = 0\n",
    "        # Save the best model state\n",
    "        torch.save(model.state_dict(), 'best_sentiment_model.pt')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "# -------------------------------\n",
    "# Final Evaluation on Development Set\n",
    "# -------------------------------\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_sentiment_model.pt'))\n",
    "model.eval()\n",
    "\n",
    "dev_correct = 0\n",
    "dev_total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for dev_inputs, dev_engineered, dev_labels in dev_loader:\n",
    "        dev_inputs = dev_inputs.to(device)\n",
    "        dev_engineered = dev_engineered.to(device)\n",
    "        dev_labels = dev_labels.to(device)\n",
    "        \n",
    "        outputs = model(dev_inputs, dev_engineered)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        dev_total += dev_labels.size(0)\n",
    "        dev_correct += (predicted == dev_labels).sum().item()\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(dev_labels.cpu().numpy())\n",
    "\n",
    "final_accuracy = dev_correct / dev_total\n",
    "print(f\"Final Development set accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "# Optionally: Calculate per-class metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "class_names = label_encoder.classes_\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Evaluating on test set: twitter-test1.txt\n",
      "==================================================\n",
      "Test Loss: 0.6809\n",
      "Test Accuracy: 0.6995\n",
      "Macro Precision: 0.7313\n",
      "Macro Recall: 0.6356\n",
      "Macro F1 Score: 0.6578\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.39      0.53       557\n",
      "     neutral       0.63      0.81      0.71      1504\n",
      "    positive       0.78      0.70      0.73      1470\n",
      "\n",
      "    accuracy                           0.70      3531\n",
      "   macro avg       0.73      0.64      0.66      3531\n",
      "weighted avg       0.72      0.70      0.69      3531\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 220  288   49]\n",
      " [  33 1224  247]\n",
      " [  28  416 1026]]\n",
      "\n",
      "==================================================\n",
      "Evaluating on test set: twitter-test2.txt\n",
      "==================================================\n",
      "Test Loss: 0.6398\n",
      "Test Accuracy: 0.6945\n",
      "Macro Precision: 0.7260\n",
      "Macro Recall: 0.6297\n",
      "Macro F1 Score: 0.6518\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.42      0.55       202\n",
      "     neutral       0.58      0.78      0.66       669\n",
      "    positive       0.81      0.69      0.75       982\n",
      "\n",
      "    accuracy                           0.69      1853\n",
      "   macro avg       0.73      0.63      0.65      1853\n",
      "weighted avg       0.72      0.69      0.69      1853\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 84  92  26]\n",
      " [ 14 521 134]\n",
      " [  8 292 682]]\n",
      "\n",
      "==================================================\n",
      "Evaluating on test set: twitter-test3.txt\n",
      "==================================================\n",
      "Test Loss: 0.7514\n",
      "Test Accuracy: 0.6620\n",
      "Macro Precision: 0.6692\n",
      "Macro Recall: 0.6140\n",
      "Macro F1 Score: 0.6269\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.43      0.51       363\n",
      "     neutral       0.59      0.80      0.68       983\n",
      "    positive       0.78      0.61      0.69      1033\n",
      "\n",
      "    accuracy                           0.66      2379\n",
      "   macro avg       0.67      0.61      0.63      2379\n",
      "weighted avg       0.68      0.66      0.66      2379\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[156 172  35]\n",
      " [ 57 784 142]\n",
      " [ 34 364 635]]\n",
      "\n",
      "Comparative Analysis Saved: model_performance_comparison.png\n",
      "\n",
      "Enhanced LSTM model saved as enhanced_lstm_model.pt\n",
      "Tokenizer, label encoder, and preprocessor saved as tokenizer.pkl, label_encoder.pkl, and preprocessor.pkl respectively.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import dill  # For serializing objects that pickle might not handle\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Store results for all test sets\n",
    "all_results = {}\n",
    "\n",
    "# Iterate through each test set\n",
    "for test_set in testsets:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Evaluating on test set: {test_set}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Get the raw texts and sentiment labels\n",
    "    test_texts = tweets[test_set]\n",
    "    test_labels_str = tweetgts[test_set]\n",
    "    \n",
    "    # Preprocess the texts using the existing preprocessor\n",
    "    processed_test_texts = preprocessor.preprocess_batch(test_texts)\n",
    "    \n",
    "    # Tokenize and pad sequences (for the LSTM)\n",
    "    test_sequences = tokenizer.texts_to_sequences(processed_test_texts)\n",
    "    test_data = pad_sequences(test_sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "    \n",
    "    # Encode sentiment labels to integers using the same label encoder\n",
    "    test_labels_int = label_encoder.transform(test_labels_str)\n",
    "    test_labels_tensor = torch.tensor(test_labels_int, dtype=torch.long)\n",
    "    \n",
    "    # Convert sequences to torch tensor\n",
    "    test_tensor = torch.tensor(test_data, dtype=torch.long)\n",
    "    \n",
    "    # Extract engineered features for each text\n",
    "    test_engineered = [extract_engineered_features(text) for text in processed_test_texts]\n",
    "    test_engineered_tensor = torch.tensor(np.array(test_engineered), dtype=torch.float32)\n",
    "    \n",
    "    # Create a DataLoader for batching; include sequence inputs, engineered features, and labels\n",
    "    test_dataset = torch.utils.data.TensorDataset(test_tensor, test_engineered_tensor, test_labels_tensor)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    all_probs = []  # Store probabilities for ROC/AUC analysis\n",
    "    test_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, engineered, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            engineered = engineered.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass: include both sequences and engineered features\n",
    "            outputs = model(inputs, engineered)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_true.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    test_loss /= total\n",
    "    test_accuracy = correct / total\n",
    "    \n",
    "    # Compute metrics using scikit-learn\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(all_true, all_preds),\n",
    "        'precision': precision_score(all_true, all_preds, average='macro', zero_division=0),\n",
    "        'recall': recall_score(all_true, all_preds, average='macro', zero_division=0),\n",
    "        'f1_score': f1_score(all_true, all_preds, average='macro', zero_division=0)\n",
    "    }\n",
    "    \n",
    "    # Also calculate per-class metrics\n",
    "    class_metrics = {\n",
    "        'precision': precision_score(all_true, all_preds, average=None, zero_division=0),\n",
    "        'recall': recall_score(all_true, all_preds, average=None, zero_division=0),\n",
    "        'f1_score': f1_score(all_true, all_preds, average=None, zero_division=0)\n",
    "    }\n",
    "    \n",
    "    cm = confusion_matrix(all_true, all_preds)\n",
    "    \n",
    "    # Print comprehensive metrics\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Macro Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Macro Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"Macro F1 Score: {metrics['f1_score']:.4f}\")\n",
    "    \n",
    "    # Print detailed classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_true, all_preds, target_names=label_encoder.classes_))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_)\n",
    "    plt.title(f'Confusion Matrix - {test_set}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'confusion_matrix_{test_set}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate error analysis\n",
    "    error_indices = np.where(np.array(all_preds) != np.array(all_true))[0]\n",
    "    error_analysis = []\n",
    "    \n",
    "    for idx in error_indices[:min(len(error_indices), 10)]:  # Limit to 10 examples\n",
    "        true_label = label_encoder.classes_[all_true[idx]]\n",
    "        pred_label = label_encoder.classes_[all_preds[idx]]\n",
    "        probs = all_probs[idx]\n",
    "        confidence = probs[all_preds[idx]]\n",
    "        \n",
    "        # Get original text\n",
    "        orig_text = test_texts[idx]\n",
    "        error_analysis.append({\n",
    "            'index': idx,\n",
    "            'true_label': true_label,\n",
    "            'predicted_label': pred_label,\n",
    "            'confidence': confidence,\n",
    "            'text': orig_text\n",
    "        })\n",
    "    \n",
    "    # Store results for this test set\n",
    "    all_results[test_set] = {\n",
    "        'metrics': metrics,\n",
    "        'class_metrics': class_metrics,\n",
    "        'confusion_matrix': cm,\n",
    "        'error_analysis': error_analysis\n",
    "    }\n",
    "\n",
    "# Create comparative visualization across test sets\n",
    "if len(testsets) > 1:\n",
    "    # Compare accuracy across test sets\n",
    "    accuracies = [all_results[test_set]['metrics']['accuracy'] for test_set in testsets]\n",
    "    f1_scores = [all_results[test_set]['metrics']['f1_score'] for test_set in testsets]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    x = np.arange(len(testsets))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, accuracies, width, label='Accuracy')\n",
    "    plt.bar(x + width/2, f1_scores, width, label='F1 Score')\n",
    "    \n",
    "    plt.xlabel('Test Sets')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Model Performance Across Test Sets')\n",
    "    plt.xticks(x, testsets)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_performance_comparison.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nComparative Analysis Saved: model_performance_comparison.png\")\n",
    "\n",
    "# ----------------------------\n",
    "# Save the enhanced LSTM model and associated components\n",
    "# ----------------------------\n",
    "\n",
    "# Save the enhanced LSTM model's state dictionary\n",
    "torch.save(model.state_dict(), 'enhanced_lstm_model.pt')\n",
    "print(\"\\nEnhanced LSTM model saved as enhanced_lstm_model.pt\")\n",
    "\n",
    "# Save tokenizer, label encoder, and preprocessor using dill\n",
    "with open('enhance_tokenizer.pkl', 'wb') as f:\n",
    "    dill.dump(tokenizer, f)\n",
    "with open('enhance_label_encoder.pkl', 'wb') as f:\n",
    "    dill.dump(label_encoder, f)\n",
    "with open('enhance_preprocessor.pkl', 'wb') as f:\n",
    "    dill.dump(preprocessor, f)\n",
    "print(\"Tokenizer, label encoder, and preprocessor saved as tokenizer.pkl, label_encoder.pkl, and preprocessor.pkl respectively.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/dcs/pg24/u2164966/.local/lib/python3.11/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Train Loss: 0.6715, Train Acc: 0.6915 | Dev Loss: 0.5695, Dev Acc: 0.7515\n",
      "Epoch 2/3 - Train Loss: 0.4753, Train Acc: 0.7919 | Dev Loss: 0.5772, Dev Acc: 0.7475\n",
      "Epoch 3/3 - Train Loss: 0.3009, Train Acc: 0.8788 | Dev Loss: 0.6822, Dev Acc: 0.7430\n",
      "Final Development set accuracy: 0.7430\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# -------------------------------\n",
    "# Data Preparation for BERT\n",
    "# -------------------------------\n",
    "# Use training tweets and labels\n",
    "train_texts = tweets['twitter-training-data.txt']\n",
    "train_labels_str = tweetgts['twitter-training-data.txt']\n",
    "\n",
    "# Use development set for validation during training\n",
    "dev_texts = tweets['twitter-dev-data.txt']\n",
    "dev_labels_str = tweetgts['twitter-dev-data.txt']\n",
    "\n",
    "# Encode sentiment labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_int = label_encoder.fit_transform(train_labels_str)\n",
    "dev_labels_int = label_encoder.transform(dev_labels_str)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Define maximum sequence length (BERT‚Äôs limit is 512, but shorter lengths speed up training)\n",
    "max_sequence_length = 128\n",
    "\n",
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def encode_texts(texts, max_len):\n",
    "    # The tokenizer returns a dictionary with keys like 'input_ids', 'attention_mask'\n",
    "    return tokenizer(texts, padding='max_length', truncation=True, max_length=max_len, return_tensors='pt')\n",
    "\n",
    "# Encode texts for train and dev sets\n",
    "train_encodings = encode_texts(train_texts, max_sequence_length)\n",
    "dev_encodings = encode_texts(dev_texts, max_sequence_length)\n",
    "\n",
    "# Create a custom Dataset to include encodings and labels\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "      \n",
    "    def __getitem__(self, idx):\n",
    "        # Return a dictionary of tensors\n",
    "        item = {key: tensor[idx] for key, tensor in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = SentimentDataset(train_encodings, train_labels_int)\n",
    "dev_dataset = SentimentDataset(dev_encodings, dev_labels_int)\n",
    "\n",
    "batch_size = 16  # BERT models typically require smaller batch sizes\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size)\n",
    "\n",
    "# -------------------------------\n",
    "# Define and Load the BERT Model\n",
    "# -------------------------------\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# -------------------------------\n",
    "# Training Setup\n",
    "# -------------------------------\n",
    "num_epochs = 3  # Fine-tuning BERT usually requires fewer epochs\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Total training steps for scheduler\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Loss function is built into the model (BertForSequenceClassification uses CrossEntropyLoss)\n",
    "\n",
    "# -------------------------------\n",
    "# Training Loop for BERT\n",
    "# -------------------------------\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        # Move inputs to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_loss += loss.item() * input_ids.size(0)\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_loss = epoch_loss / total\n",
    "    train_accuracy = correct / total\n",
    "    \n",
    "    # Evaluate on the dev set\n",
    "    model.eval()\n",
    "    dev_loss = 0.0\n",
    "    dev_correct = 0\n",
    "    dev_total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dev_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            dev_loss += loss.item() * input_ids.size(0)\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            dev_total += labels.size(0)\n",
    "            dev_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    dev_loss = dev_loss / dev_total\n",
    "    dev_accuracy = dev_correct / dev_total\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f} | Dev Loss: {dev_loss:.4f}, Dev Acc: {dev_accuracy:.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluation on Dev Set (Final)\n",
    "# -------------------------------\n",
    "model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in dev_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "print(f\"Final Development set accuracy: {dev_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set: twitter-test1.txt\n",
      "Test Loss: 0.7547\n",
      "Test Accuracy: 0.7329\n",
      "Precision: 0.7636\n",
      "Recall: 0.6897\n",
      "F1 Score: 0.7133\n",
      "Confusion Matrix:\n",
      "[[ 293  237   27]\n",
      " [  39 1187  278]\n",
      " [  19  343 1108]]\n",
      "\n",
      "Evaluating on test set: twitter-test2.txt\n",
      "Test Loss: 0.6883\n",
      "Test Accuracy: 0.7442\n",
      "Precision: 0.7551\n",
      "Recall: 0.6870\n",
      "F1 Score: 0.7104\n",
      "Confusion Matrix:\n",
      "[[107  79  16]\n",
      " [ 18 495 156]\n",
      " [  8 197 777]]\n",
      "\n",
      "Evaluating on test set: twitter-test3.txt\n",
      "Test Loss: 0.8085\n",
      "Test Accuracy: 0.7201\n",
      "Precision: 0.7248\n",
      "Recall: 0.6942\n",
      "F1 Score: 0.7040\n",
      "Confusion Matrix:\n",
      "[[216 129  18]\n",
      " [ 62 780 141]\n",
      " [ 29 287 717]]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Evaluation on Test Sets\n",
    "# -------------------------------\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "for test_set in testsets:\n",
    "    print(f\"\\nEvaluating on test set: {test_set}\")\n",
    "    \n",
    "    # Get the raw texts and sentiment labels\n",
    "    test_texts = tweets[test_set]\n",
    "    test_labels_str = tweetgts[test_set]\n",
    "    \n",
    "    # Encode texts using BERT tokenizer\n",
    "    test_encodings = encode_texts(test_texts, max_sequence_length)\n",
    "    test_dataset = SentimentDataset(test_encodings, label_encoder.transform(test_labels_str))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    test_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            test_loss += loss.item() * input_ids.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_true.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_loss /= total\n",
    "    test_accuracy = correct / total\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(all_true, all_preds),\n",
    "        'precision': precision_score(all_true, all_preds, average='macro', zero_division=0),\n",
    "        'recall': recall_score(all_true, all_preds, average='macro', zero_division=0),\n",
    "        'f1_score': f1_score(all_true, all_preds, average='macro', zero_division=0)\n",
    "    }\n",
    "    \n",
    "    cm = confusion_matrix(all_true, all_preds)\n",
    "    \n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1_score']:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating on test set: twitter-test1.txt\n",
    "Test Loss: 0.7368\n",
    "Test Accuracy: 0.7386\n",
    "Precision: 0.7705\n",
    "Recall: 0.6967\n",
    "F1 Score: 0.7205\n",
    "Confusion Matrix:\n",
    "[[ 300  235   22]\n",
    " [  37 1203  264]\n",
    " [  19  346 1105]]\n",
    "\n",
    "Evaluating on test set: twitter-test2.txt\n",
    "Test Loss: 0.6700\n",
    "Test Accuracy: 0.7518\n",
    "Precision: 0.7605\n",
    "Recall: 0.6964\n",
    "F1 Score: 0.7182\n",
    "Confusion Matrix:\n",
    "[[109  81  12]\n",
    " [ 19 508 142]\n",
    " [  8 198 776]]\n",
    "\n",
    "Evaluating on test set: twitter-test3.txt\n",
    "Test Loss: 0.8051\n",
    "Test Accuracy: 0.7238\n",
    "Precision: 0.7219\n",
    "Recall: 0.6935\n",
    "F1 Score: 0.7027\n",
    "Confusion Matrix:\n",
    "[[210 138  15]\n",
    " [ 67 780 136]\n",
    " [ 32 269 732]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Different Prompting strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Tweet: 'I love the new design of the app!'. Overall, the sentiment of the tweet is [MASK].\n",
      "Predicted Sentiment: positive\n",
      "Sentiment Scores: {'positive': 7.185812950134277, 'negative': 2.7108802795410156, 'neutral': 3.355437755584717}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "# Set up the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load a masked language model (BertForMaskedLM) instead of your classification model\n",
    "model_name_or_path = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name_or_path)\n",
    "mlm_model = BertForMaskedLM.from_pretrained(model_name_or_path)\n",
    "mlm_model.to(device)\n",
    "mlm_model.eval()\n",
    "\n",
    "def prompt_sentiment(\n",
    "    tweet,\n",
    "    template=\"Tweet: '{}'. Overall, the sentiment of the tweet is [MASK].\",\n",
    "    verbalizer={\n",
    "        \"positive\": [\"great\", \"good\", \"happy\"],\n",
    "        \"negative\": [\"bad\", \"terrible\", \"sad\"],\n",
    "        \"neutral\": [\"okay\", \"neutral\", \"mediocre\"]\n",
    "    }\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a prompt from the tweet, predicts the masked token,\n",
    "    and maps the output to one of the sentiment classes using a verbalizer.\n",
    "    \n",
    "    Args:\n",
    "        tweet (str): The tweet text.\n",
    "        template (str): A prompt template with a [MASK] token.\n",
    "        verbalizer (dict): Mapping from sentiment labels to lists of words.\n",
    "    \n",
    "    Returns:\n",
    "        predicted_sentiment (str): The sentiment label with the highest average score.\n",
    "        sentiment_scores (dict): Scores for each sentiment.\n",
    "        prompt_text (str): The generated prompt.\n",
    "    \"\"\"\n",
    "    # Create the prompt using the template\n",
    "    prompt_text = template.format(tweet)\n",
    "    \n",
    "    # Tokenize the prompt text and move tensors to the model's device\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\")\n",
    "    inputs = {key: tensor.to(device) for key, tensor in inputs.items()}\n",
    "    \n",
    "    # Identify the [MASK] token's position in the input\n",
    "    mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "    \n",
    "    # Get the model's predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = mlm_model(**inputs)\n",
    "    logits = outputs.logits  # Shape: (batch_size, sequence_length, vocab_size)\n",
    "    \n",
    "    # Extract the logits corresponding to the [MASK] token\n",
    "    mask_token_logits = logits[0, mask_token_index, :]\n",
    "    \n",
    "    # Initialize a dictionary to hold aggregated sentiment scores\n",
    "    sentiment_scores = {}\n",
    "    \n",
    "    # For each sentiment, average the logits of the words in the verbalizer list\n",
    "    for sentiment, words in verbalizer.items():\n",
    "        # Convert words to token IDs\n",
    "        word_ids = [tokenizer.convert_tokens_to_ids(word) for word in words]\n",
    "        # Retrieve the logits for these token IDs and calculate the average score\n",
    "        scores = mask_token_logits[0, word_ids]\n",
    "        sentiment_scores[sentiment] = scores.mean().item()\n",
    "    \n",
    "    # Select the sentiment with the highest average score\n",
    "    predicted_sentiment = max(sentiment_scores, key=sentiment_scores.get)\n",
    "    \n",
    "    return predicted_sentiment, sentiment_scores, prompt_text\n",
    "\n",
    "# Example usage\n",
    "tweet_example = \"I love the new design of the app!\"\n",
    "predicted_sentiment, scores, prompt_text = prompt_sentiment(tweet_example)\n",
    "\n",
    "print(\"Prompt:\", prompt_text)\n",
    "print(\"Predicted Sentiment:\", predicted_sentiment)\n",
    "print(\"Sentiment Scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set: twitter-test1.txt\n",
      "Test Accuracy: 0.4163\n",
      "Precision: 0.1388\n",
      "Recall: 0.3333\n",
      "F1 Score: 0.1960\n",
      "Confusion Matrix:\n",
      "[[   0    0  557]\n",
      " [   0    0 1504]\n",
      " [   0    0 1470]]\n",
      "\n",
      "Evaluating on test set: twitter-test2.txt\n",
      "Test Accuracy: 0.5300\n",
      "Precision: 0.1767\n",
      "Recall: 0.3333\n",
      "F1 Score: 0.2309\n",
      "Confusion Matrix:\n",
      "[[  0   0 202]\n",
      " [  0   0 669]\n",
      " [  0   0 982]]\n",
      "\n",
      "Evaluating on test set: twitter-test3.txt\n",
      "Test Accuracy: 0.4346\n",
      "Precision: 0.4781\n",
      "Recall: 0.3343\n",
      "F1 Score: 0.2037\n",
      "Confusion Matrix:\n",
      "[[   1    0  362]\n",
      " [   0    0  983]\n",
      " [   0    0 1033]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Initialize lists to hold the ground truth and predicted labels for each test set\n",
    "for test_set in testsets:\n",
    "    print(f\"\\nEvaluating on test set: {test_set}\")\n",
    "    \n",
    "    # Get the raw tweet texts and their true sentiment labels (as strings)\n",
    "    test_texts = tweets[test_set]\n",
    "    test_labels_str = tweetgts[test_set]  # True labels: e.g., [\"positive\", \"negative\", \"neutral\", ...]\n",
    "    \n",
    "    # List to hold predictions from the prompt-based approach\n",
    "    pred_labels = []\n",
    "    \n",
    "    # Loop over each tweet and get the predicted sentiment using the prompt_sentiment function\n",
    "    for tweet in test_texts:\n",
    "        predicted_sentiment, sentiment_scores, prompt_text = prompt_sentiment(tweet)\n",
    "        pred_labels.append(predicted_sentiment)\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    test_accuracy = accuracy_score(test_labels_str, pred_labels)\n",
    "    precision = precision_score(test_labels_str, pred_labels, average='macro', zero_division=0)\n",
    "    recall = recall_score(test_labels_str, pred_labels, average='macro', zero_division=0)\n",
    "    f1 = f1_score(test_labels_str, pred_labels, average='macro', zero_division=0)\n",
    "    cm = confusion_matrix(test_labels_str, pred_labels)\n",
    "    \n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "Analyze sentiment in tweets. Classify as positive, negative, or neutral.\n",
      "\n",
      "Tweet: 'I love this phone! It's amazing and super fast.'\n",
      "The sentiment is positive.\n",
      "\n",
      "Tweet: 'The food was incredible and the service was top-notch.'\n",
      "The sentiment is positive.\n",
      "\n",
      "Tweet: 'This is the best concert I've ever attended!'\n",
      "The sentiment is positive.\n",
      "\n",
      "Tweet: 'I'm extremely satisfied with my purchase; the quality is excellent.'\n",
      "The sentiment is positive.\n",
      "\n",
      "Tweet: 'This restaurant is terrible; the food was cold and bland.'\n",
      "The sentiment is negative.\n",
      "\n",
      "Tweet: 'I had the worst experience with customer service today.'\n",
      "The sentiment is negative.\n",
      "\n",
      "Tweet: 'The movie was boring and a complete waste of time.'\n",
      "The sentiment is negative.\n",
      "\n",
      "Tweet: 'I'm very disappointed with the product quality, it's subpar.'\n",
      "The sentiment is negative.\n",
      "\n",
      "Tweet: 'The meeting was just average; nothing particularly exciting happened.'\n",
      "The sentiment is neutral.\n",
      "\n",
      "Tweet: 'I have no strong feelings about this product.'\n",
      "The sentiment is neutral.\n",
      "\n",
      "Tweet: 'The movie was okay, not great but not bad either.'\n",
      "The sentiment is neutral.\n",
      "\n",
      "Tweet: 'The service was acceptable and met my expectations.'\n",
      "The sentiment is neutral.\n",
      "\n",
      "\n",
      "\n",
      "Tweet: 'I love the new design of the app!'\n",
      "The sentiment is [MASK].\n",
      "\n",
      "Predicted Sentiment: positive\n",
      "Sentiment Scores: {'positive': 0.5646349191665649, 'negative': 0.18934756517410278, 'neutral': 0.21524015069007874}\n",
      "Debug Info:\n",
      "- Most likely token: 'positive' (probability: 0.5646)\n",
      "- Confidence: 0.3494\n",
      "- Token probabilities by sentiment:\n",
      "  positive:\n",
      "    'positive': 0.564635\n",
      "    'good': 0.006345\n",
      "    'great': 0.000205\n",
      "    'excellent': 0.000241\n",
      "    'wonderful': 0.000010\n",
      "    'fantastic': 0.000004\n",
      "    'amazing': 0.000001\n",
      "  negative:\n",
      "    'negative': 0.189348\n",
      "    'bad': 0.000179\n",
      "    'terrible': 0.000005\n",
      "    'awful': 0.000002\n",
      "    'horrible': 0.000002\n",
      "    'poor': 0.000008\n",
      "    'disappointing': 0.000007\n",
      "  neutral:\n",
      "    'neutral': 0.215240\n",
      "    'okay': 0.000051\n",
      "    'average': 0.000007\n",
      "    'fine': 0.000149\n",
      "    'fair': 0.000028\n",
      "    'moderate': 0.000060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set up the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load a masked language model (BertForMaskedLM)\n",
    "model_name_or_path = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name_or_path)\n",
    "mlm_model = BertForMaskedLM.from_pretrained(model_name_or_path)\n",
    "mlm_model.to(device)\n",
    "mlm_model.eval()\n",
    "\n",
    "def prompt_sentiment_few_shot(\n",
    "    tweet,\n",
    "    few_shot_examples = [\n",
    "        # Positive examples - reduced for clarity\n",
    "        (\"I love this phone! It's amazing and super fast.\", \"positive\"),\n",
    "        (\"The food was incredible and the service was top-notch.\", \"positive\"),\n",
    "        (\"This is the best concert I've ever attended!\", \"positive\"),\n",
    "        (\"I'm extremely satisfied with my purchase; the quality is excellent.\", \"positive\"),\n",
    "        \n",
    "        # Negative examples - reduced for clarity\n",
    "        (\"This restaurant is terrible; the food was cold and bland.\", \"negative\"),\n",
    "        (\"I had the worst experience with customer service today.\", \"negative\"),\n",
    "        (\"The movie was boring and a complete waste of time.\", \"negative\"),\n",
    "        (\"I'm very disappointed with the product quality, it's subpar.\", \"negative\"),\n",
    "        \n",
    "        # Neutral examples - reduced for clarity\n",
    "        (\"The meeting was just average; nothing particularly exciting happened.\", \"neutral\"),\n",
    "        (\"I have no strong feelings about this product.\", \"neutral\"),\n",
    "        (\"The movie was okay, not great but not bad either.\", \"neutral\"),\n",
    "        (\"The service was acceptable and met my expectations.\", \"neutral\")\n",
    "    ],\n",
    "    # Improved template with direct sentiment terms as mask options\n",
    "    template=\"\"\"Analyze sentiment in tweets. Classify as positive, negative, or neutral.\n",
    "\n",
    "{examples}\n",
    "\n",
    "Tweet: '{tweet}'\n",
    "The sentiment is [MASK].\"\"\",\n",
    "    \n",
    "    # Expanded verbalizer with exact tokens from BERT vocabulary\n",
    "    verbalizer={\n",
    "        \"positive\": [\"positive\", \"good\", \"great\", \"excellent\", \"wonderful\", \"fantastic\", \"amazing\"],\n",
    "        \"negative\": [\"negative\", \"bad\", \"terrible\", \"awful\", \"horrible\", \"poor\", \"disappointing\"],\n",
    "        \"neutral\": [\"neutral\", \"okay\", \"average\", \"mediocre\", \"fine\", \"fair\", \"moderate\"]\n",
    "    },\n",
    "    max_length=512\n",
    "):\n",
    "    \"\"\"\n",
    "    Uses BERT's masked language model capabilities for sentiment analysis.\n",
    "    \n",
    "    Args:\n",
    "        tweet (str): The tweet text.\n",
    "        few_shot_examples (list): List of tuples (example_tweet, sentiment_label).\n",
    "        template (str): A prompt template with a [MASK] token.\n",
    "        verbalizer (dict): Mapping from sentiment labels to lists of possible words.\n",
    "        max_length (int): Maximum sequence length for tokenization.\n",
    "    \n",
    "    Returns:\n",
    "        predicted_sentiment (str): The sentiment label with the highest score.\n",
    "        sentiment_scores (dict): Scores for each sentiment.\n",
    "        prompt_text (str): The generated prompt.\n",
    "        debug_info (dict): Additional information for debugging.\n",
    "    \"\"\"\n",
    "    # First, validate that the verbalizer words exist in BERT's vocabulary\n",
    "    valid_verbalizer = {}\n",
    "    token_ids_map = {}\n",
    "    debug_info = {\"token_info\": {}}\n",
    "    \n",
    "    for sentiment, words in verbalizer.items():\n",
    "        valid_words = []\n",
    "        valid_ids = []\n",
    "        \n",
    "        for word in words:\n",
    "            # Check if the word is in BERT's vocabulary\n",
    "            word_id = tokenizer.convert_tokens_to_ids(word)\n",
    "            if word_id != tokenizer.unk_token_id:  # Not unknown token\n",
    "                valid_words.append(word)\n",
    "                valid_ids.append(word_id)\n",
    "                debug_info[\"token_info\"][word] = word_id\n",
    "        \n",
    "        if valid_words:\n",
    "            valid_verbalizer[sentiment] = valid_words\n",
    "            token_ids_map[sentiment] = valid_ids\n",
    "        else:\n",
    "            print(f\"Warning: No valid tokens found for sentiment '{sentiment}'\")\n",
    "    \n",
    "    # Create examples string with consistent formatting\n",
    "    examples_str = \"\"\n",
    "    for ex_tweet, ex_sent in few_shot_examples:\n",
    "        examples_str += f\"Tweet: '{ex_tweet}'\\nThe sentiment is {ex_sent}.\\n\\n\"\n",
    "    \n",
    "    # Construct the prompt\n",
    "    prompt_text = template.format(examples=examples_str, tweet=tweet)\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
    "    inputs = {key: tensor.to(device) for key, tensor in inputs.items()}\n",
    "    \n",
    "    # Verify the [MASK] token is in the input\n",
    "    mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "    \n",
    "    if mask_token_index.numel() == 0:\n",
    "        # If no mask token, try with fewer examples\n",
    "        reduced_examples = few_shot_examples[:len(few_shot_examples)//2]\n",
    "        reduced_examples_str = \"\"\n",
    "        for ex_tweet, ex_sent in reduced_examples:\n",
    "            reduced_examples_str += f\"Tweet: '{ex_tweet}'\\nThe sentiment is {ex_sent}.\\n\\n\"\n",
    "        \n",
    "        prompt_text = template.format(examples=reduced_examples_str, tweet=tweet)\n",
    "        inputs = tokenizer(prompt_text, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
    "        inputs = {key: tensor.to(device) for key, tensor in inputs.items()}\n",
    "        mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "        \n",
    "        if mask_token_index.numel() == 0:\n",
    "            # If still no mask, use minimal prompt\n",
    "            prompt_text = f\"Tweet: '{tweet}'\\nThe sentiment is [MASK].\"\n",
    "            inputs = tokenizer(prompt_text, return_tensors=\"pt\")\n",
    "            inputs = {key: tensor.to(device) for key, tensor in inputs.items()}\n",
    "            mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "            \n",
    "            if mask_token_index.numel() == 0:\n",
    "                raise ValueError(\"Unable to include [MASK] token in the prompt\")\n",
    "    \n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = mlm_model(**inputs)\n",
    "    \n",
    "    # Get logits for the masked token\n",
    "    mask_token_logits = outputs.logits[0, mask_token_index[0], :]\n",
    "    \n",
    "    # Apply softmax to get probabilities\n",
    "    mask_token_probs = F.softmax(mask_token_logits, dim=-1)\n",
    "    \n",
    "    # Calculate score for each sentiment class\n",
    "    sentiment_scores = {}\n",
    "    token_probs = {}\n",
    "    \n",
    "    for sentiment, token_ids in token_ids_map.items():\n",
    "        # Get probability for each verbalizer token - FIXED HERE\n",
    "        probs = [mask_token_probs[tid].item() for tid in token_ids]\n",
    "        token_probs[sentiment] = {\n",
    "            valid_verbalizer[sentiment][i]: prob \n",
    "            for i, prob in enumerate(probs)\n",
    "        }\n",
    "        \n",
    "        # Use the maximum probability as the score for this sentiment\n",
    "        sentiment_scores[sentiment] = max(probs) if probs else 0.0\n",
    "    \n",
    "    # Select the sentiment with the highest score\n",
    "    predicted_sentiment = max(sentiment_scores, key=sentiment_scores.get)\n",
    "    \n",
    "    # Calculate confidence as the difference between top score and second highest\n",
    "    scores_list = sorted(sentiment_scores.values(), reverse=True)\n",
    "    confidence = scores_list[0] - scores_list[1] if len(scores_list) > 1 else scores_list[0]\n",
    "    \n",
    "    # Add more debug information\n",
    "    debug_info[\"token_probs\"] = token_probs\n",
    "    debug_info[\"mask_token_index\"] = mask_token_index[0].item()\n",
    "    debug_info[\"confidence\"] = confidence\n",
    "    \n",
    "    # Get the most likely token as predicted by BERT\n",
    "    top_token_id = torch.argmax(mask_token_logits).item()\n",
    "    top_token = tokenizer.convert_ids_to_tokens(top_token_id)\n",
    "    debug_info[\"top_predicted_token\"] = top_token\n",
    "    debug_info[\"top_token_probability\"] = mask_token_probs[top_token_id].item()\n",
    "    \n",
    "    return predicted_sentiment, sentiment_scores, prompt_text, debug_info\n",
    "\n",
    "# Function to evaluate on a test set\n",
    "def evaluate_model(test_file_path, num_samples=None):\n",
    "    \"\"\"\n",
    "    Evaluates the BERT sentiment model on a test file.\n",
    "    Expected format: one tweet per line with format \"sentiment\\ttweet_text\"\n",
    "    \"\"\"\n",
    "    import random\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "    \n",
    "    # Read test data\n",
    "    test_data = []\n",
    "    with open(test_file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 2:\n",
    "                sentiment, tweet = parts\n",
    "                test_data.append((tweet, sentiment))\n",
    "    \n",
    "    # Sample if requested\n",
    "    if num_samples and num_samples < len(test_data):\n",
    "        test_data = random.sample(test_data, num_samples)\n",
    "        print(f\"Sampled {num_samples} examples from {len(test_data)} total\")\n",
    "    \n",
    "    # Process tweets\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    confidences = []\n",
    "    \n",
    "    for i, (tweet, true_sentiment) in enumerate(test_data):\n",
    "        try:\n",
    "            predicted_sentiment, scores, _, debug_info = prompt_sentiment_few_shot(tweet)\n",
    "            predictions.append(predicted_sentiment)\n",
    "            true_labels.append(true_sentiment)\n",
    "            confidences.append(debug_info[\"confidence\"])\n",
    "            \n",
    "            # Print progress\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(f\"Processed {i+1}/{len(test_data)} tweets\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing tweet: {e}\")\n",
    "            # Skip this example\n",
    "            continue\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='macro', zero_division=0)\n",
    "    recall = recall_score(true_labels, predictions, average='macro', zero_division=0)\n",
    "    f1 = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
    "    cm = confusion_matrix(true_labels, predictions, labels=sorted(set(true_labels)))\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Average Confidence: {sum(confidences)/len(confidences):.6f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Count prediction distribution\n",
    "    pred_counts = {}\n",
    "    for p in predictions:\n",
    "        pred_counts[p] = pred_counts.get(p, 0) + 1\n",
    "    print(f\"Prediction Distribution: {pred_counts}\")\n",
    "    \n",
    "    return accuracy, precision, recall, f1, cm\n",
    "\n",
    "# Example usage\n",
    "tweet_example = \"I love the new design of the app!\"\n",
    "predicted_sentiment, scores, prompt_text, debug_info = prompt_sentiment_few_shot(tweet_example)\n",
    "\n",
    "print(\"Prompt:\")\n",
    "print(prompt_text)\n",
    "print(\"\\nPredicted Sentiment:\", predicted_sentiment)\n",
    "print(\"Sentiment Scores:\", scores)\n",
    "print(\"Debug Info:\")\n",
    "print(f\"- Most likely token: '{debug_info['top_predicted_token']}' (probability: {debug_info['top_token_probability']:.4f})\")\n",
    "print(f\"- Confidence: {debug_info['confidence']:.4f}\")\n",
    "print(f\"- Token probabilities by sentiment:\")\n",
    "for sentiment, token_dict in debug_info[\"token_probs\"].items():\n",
    "    print(f\"  {sentiment}:\")\n",
    "    for token, prob in token_dict.items():\n",
    "        print(f\"    '{token}': {prob:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set: twitter-test1.txt\n",
      "Processed 10/3531 tweets. Estimated time remaining: 75.0s\n",
      "Processed 20/3531 tweets. Estimated time remaining: 73.4s\n",
      "Processed 30/3531 tweets. Estimated time remaining: 72.1s\n",
      "Processed 40/3531 tweets. Estimated time remaining: 71.2s\n",
      "Processed 50/3531 tweets. Estimated time remaining: 70.2s\n",
      "Processed 60/3531 tweets. Estimated time remaining: 69.7s\n",
      "Processed 70/3531 tweets. Estimated time remaining: 69.5s\n",
      "Processed 80/3531 tweets. Estimated time remaining: 69.3s\n",
      "Processed 90/3531 tweets. Estimated time remaining: 69.0s\n",
      "Processed 100/3531 tweets. Estimated time remaining: 68.7s\n",
      "Processed 110/3531 tweets. Estimated time remaining: 68.4s\n",
      "Processed 120/3531 tweets. Estimated time remaining: 68.1s\n",
      "Processed 130/3531 tweets. Estimated time remaining: 67.8s\n",
      "Processed 140/3531 tweets. Estimated time remaining: 67.6s\n",
      "Processed 150/3531 tweets. Estimated time remaining: 67.2s\n",
      "Processed 160/3531 tweets. Estimated time remaining: 67.0s\n",
      "Processed 170/3531 tweets. Estimated time remaining: 66.7s\n",
      "Processed 180/3531 tweets. Estimated time remaining: 66.5s\n",
      "Processed 190/3531 tweets. Estimated time remaining: 66.3s\n",
      "Processed 200/3531 tweets. Estimated time remaining: 66.1s\n",
      "Processed 210/3531 tweets. Estimated time remaining: 65.8s\n",
      "Processed 220/3531 tweets. Estimated time remaining: 65.6s\n",
      "Processed 230/3531 tweets. Estimated time remaining: 65.4s\n",
      "Processed 240/3531 tweets. Estimated time remaining: 65.2s\n",
      "Processed 250/3531 tweets. Estimated time remaining: 65.0s\n",
      "Processed 260/3531 tweets. Estimated time remaining: 64.7s\n",
      "Processed 270/3531 tweets. Estimated time remaining: 64.5s\n",
      "Processed 280/3531 tweets. Estimated time remaining: 64.3s\n",
      "Processed 290/3531 tweets. Estimated time remaining: 64.1s\n",
      "Processed 300/3531 tweets. Estimated time remaining: 63.9s\n",
      "Processed 310/3531 tweets. Estimated time remaining: 63.7s\n",
      "Processed 320/3531 tweets. Estimated time remaining: 63.5s\n",
      "Processed 330/3531 tweets. Estimated time remaining: 63.3s\n",
      "Processed 340/3531 tweets. Estimated time remaining: 63.2s\n",
      "Processed 350/3531 tweets. Estimated time remaining: 63.0s\n",
      "Processed 360/3531 tweets. Estimated time remaining: 62.7s\n",
      "Processed 370/3531 tweets. Estimated time remaining: 62.5s\n",
      "Processed 380/3531 tweets. Estimated time remaining: 62.3s\n",
      "Processed 390/3531 tweets. Estimated time remaining: 62.1s\n",
      "Processed 400/3531 tweets. Estimated time remaining: 61.9s\n",
      "Processed 410/3531 tweets. Estimated time remaining: 61.7s\n",
      "Processed 420/3531 tweets. Estimated time remaining: 61.5s\n",
      "Processed 430/3531 tweets. Estimated time remaining: 61.2s\n",
      "Processed 440/3531 tweets. Estimated time remaining: 61.1s\n",
      "Processed 450/3531 tweets. Estimated time remaining: 60.8s\n",
      "Processed 460/3531 tweets. Estimated time remaining: 60.6s\n",
      "Processed 470/3531 tweets. Estimated time remaining: 60.4s\n",
      "Processed 480/3531 tweets. Estimated time remaining: 60.2s\n",
      "Processed 490/3531 tweets. Estimated time remaining: 60.0s\n",
      "Processed 500/3531 tweets. Estimated time remaining: 59.9s\n",
      "Processed 510/3531 tweets. Estimated time remaining: 59.7s\n",
      "Processed 520/3531 tweets. Estimated time remaining: 59.5s\n",
      "Processed 530/3531 tweets. Estimated time remaining: 59.3s\n",
      "Processed 540/3531 tweets. Estimated time remaining: 59.2s\n",
      "Processed 550/3531 tweets. Estimated time remaining: 59.0s\n",
      "Processed 560/3531 tweets. Estimated time remaining: 58.8s\n",
      "Processed 570/3531 tweets. Estimated time remaining: 58.6s\n",
      "Processed 580/3531 tweets. Estimated time remaining: 58.4s\n",
      "Processed 590/3531 tweets. Estimated time remaining: 58.2s\n",
      "Processed 600/3531 tweets. Estimated time remaining: 58.0s\n",
      "Processed 610/3531 tweets. Estimated time remaining: 57.7s\n",
      "Processed 620/3531 tweets. Estimated time remaining: 57.6s\n",
      "Processed 630/3531 tweets. Estimated time remaining: 57.4s\n",
      "Processed 640/3531 tweets. Estimated time remaining: 57.2s\n",
      "Processed 650/3531 tweets. Estimated time remaining: 57.0s\n",
      "Processed 660/3531 tweets. Estimated time remaining: 56.8s\n",
      "Processed 670/3531 tweets. Estimated time remaining: 56.5s\n",
      "Processed 680/3531 tweets. Estimated time remaining: 56.3s\n",
      "Processed 690/3531 tweets. Estimated time remaining: 56.2s\n",
      "Processed 700/3531 tweets. Estimated time remaining: 56.0s\n",
      "Processed 710/3531 tweets. Estimated time remaining: 55.8s\n",
      "Processed 720/3531 tweets. Estimated time remaining: 55.6s\n",
      "Processed 730/3531 tweets. Estimated time remaining: 55.4s\n",
      "Processed 740/3531 tweets. Estimated time remaining: 55.2s\n",
      "Processed 750/3531 tweets. Estimated time remaining: 55.0s\n",
      "Processed 760/3531 tweets. Estimated time remaining: 54.8s\n",
      "Processed 770/3531 tweets. Estimated time remaining: 54.6s\n",
      "Processed 780/3531 tweets. Estimated time remaining: 54.4s\n",
      "Processed 790/3531 tweets. Estimated time remaining: 54.2s\n",
      "Processed 800/3531 tweets. Estimated time remaining: 54.0s\n",
      "Processed 810/3531 tweets. Estimated time remaining: 53.8s\n",
      "Processed 820/3531 tweets. Estimated time remaining: 53.6s\n",
      "Processed 830/3531 tweets. Estimated time remaining: 53.5s\n",
      "Processed 840/3531 tweets. Estimated time remaining: 53.3s\n",
      "Processed 850/3531 tweets. Estimated time remaining: 53.1s\n",
      "Processed 860/3531 tweets. Estimated time remaining: 52.9s\n",
      "Processed 870/3531 tweets. Estimated time remaining: 52.7s\n",
      "Processed 880/3531 tweets. Estimated time remaining: 52.5s\n",
      "Processed 890/3531 tweets. Estimated time remaining: 52.3s\n",
      "Processed 900/3531 tweets. Estimated time remaining: 52.1s\n",
      "Processed 910/3531 tweets. Estimated time remaining: 51.9s\n",
      "Processed 920/3531 tweets. Estimated time remaining: 51.8s\n",
      "Processed 930/3531 tweets. Estimated time remaining: 51.6s\n",
      "Processed 940/3531 tweets. Estimated time remaining: 51.4s\n",
      "Processed 950/3531 tweets. Estimated time remaining: 51.2s\n",
      "Processed 960/3531 tweets. Estimated time remaining: 51.0s\n",
      "Processed 970/3531 tweets. Estimated time remaining: 50.8s\n",
      "Processed 980/3531 tweets. Estimated time remaining: 50.6s\n",
      "Processed 990/3531 tweets. Estimated time remaining: 50.4s\n",
      "Processed 1000/3531 tweets. Estimated time remaining: 50.2s\n",
      "Processed 1010/3531 tweets. Estimated time remaining: 50.0s\n",
      "Processed 1020/3531 tweets. Estimated time remaining: 49.8s\n",
      "Processed 1030/3531 tweets. Estimated time remaining: 49.6s\n",
      "Processed 1040/3531 tweets. Estimated time remaining: 49.4s\n",
      "Processed 1050/3531 tweets. Estimated time remaining: 49.2s\n",
      "Processed 1060/3531 tweets. Estimated time remaining: 49.0s\n",
      "Processed 1070/3531 tweets. Estimated time remaining: 48.8s\n",
      "Processed 1080/3531 tweets. Estimated time remaining: 48.6s\n",
      "Processed 1090/3531 tweets. Estimated time remaining: 48.4s\n",
      "Processed 1100/3531 tweets. Estimated time remaining: 48.2s\n",
      "Processed 1110/3531 tweets. Estimated time remaining: 48.1s\n",
      "Processed 1120/3531 tweets. Estimated time remaining: 47.9s\n",
      "Processed 1130/3531 tweets. Estimated time remaining: 47.7s\n",
      "Processed 1140/3531 tweets. Estimated time remaining: 47.5s\n",
      "Processed 1150/3531 tweets. Estimated time remaining: 47.3s\n",
      "Processed 1160/3531 tweets. Estimated time remaining: 47.1s\n",
      "Processed 1170/3531 tweets. Estimated time remaining: 46.9s\n",
      "Processed 1180/3531 tweets. Estimated time remaining: 46.7s\n",
      "Processed 1190/3531 tweets. Estimated time remaining: 46.5s\n",
      "Processed 1200/3531 tweets. Estimated time remaining: 46.3s\n",
      "Processed 1210/3531 tweets. Estimated time remaining: 46.1s\n",
      "Processed 1220/3531 tweets. Estimated time remaining: 45.9s\n",
      "Processed 1230/3531 tweets. Estimated time remaining: 45.7s\n",
      "Processed 1240/3531 tweets. Estimated time remaining: 45.5s\n",
      "Processed 1250/3531 tweets. Estimated time remaining: 45.3s\n",
      "Processed 1260/3531 tweets. Estimated time remaining: 45.1s\n",
      "Processed 1270/3531 tweets. Estimated time remaining: 44.9s\n",
      "Processed 1280/3531 tweets. Estimated time remaining: 44.7s\n",
      "Processed 1290/3531 tweets. Estimated time remaining: 44.5s\n",
      "Processed 1300/3531 tweets. Estimated time remaining: 44.3s\n",
      "Processed 1310/3531 tweets. Estimated time remaining: 44.1s\n",
      "Processed 1320/3531 tweets. Estimated time remaining: 43.9s\n",
      "Processed 1330/3531 tweets. Estimated time remaining: 43.7s\n",
      "Processed 1340/3531 tweets. Estimated time remaining: 43.5s\n",
      "Processed 1350/3531 tweets. Estimated time remaining: 43.4s\n",
      "Processed 1360/3531 tweets. Estimated time remaining: 43.2s\n",
      "Processed 1370/3531 tweets. Estimated time remaining: 43.0s\n",
      "Processed 1380/3531 tweets. Estimated time remaining: 42.8s\n",
      "Processed 1390/3531 tweets. Estimated time remaining: 42.6s\n",
      "Processed 1400/3531 tweets. Estimated time remaining: 42.4s\n",
      "Processed 1410/3531 tweets. Estimated time remaining: 42.2s\n",
      "Processed 1420/3531 tweets. Estimated time remaining: 42.0s\n",
      "Processed 1430/3531 tweets. Estimated time remaining: 41.8s\n",
      "Processed 1440/3531 tweets. Estimated time remaining: 41.5s\n",
      "Processed 1450/3531 tweets. Estimated time remaining: 41.3s\n",
      "Processed 1460/3531 tweets. Estimated time remaining: 41.1s\n",
      "Processed 1470/3531 tweets. Estimated time remaining: 41.0s\n",
      "Processed 1480/3531 tweets. Estimated time remaining: 40.8s\n",
      "Processed 1490/3531 tweets. Estimated time remaining: 40.6s\n",
      "Processed 1500/3531 tweets. Estimated time remaining: 40.4s\n",
      "Processed 1510/3531 tweets. Estimated time remaining: 40.2s\n",
      "Processed 1520/3531 tweets. Estimated time remaining: 40.0s\n",
      "Processed 1530/3531 tweets. Estimated time remaining: 39.8s\n",
      "Processed 1540/3531 tweets. Estimated time remaining: 39.6s\n",
      "Processed 1550/3531 tweets. Estimated time remaining: 39.4s\n",
      "Processed 1560/3531 tweets. Estimated time remaining: 39.2s\n",
      "Processed 1570/3531 tweets. Estimated time remaining: 39.0s\n",
      "Processed 1580/3531 tweets. Estimated time remaining: 38.8s\n",
      "Processed 1590/3531 tweets. Estimated time remaining: 38.6s\n",
      "Processed 1600/3531 tweets. Estimated time remaining: 38.4s\n",
      "Processed 1610/3531 tweets. Estimated time remaining: 38.2s\n",
      "Processed 1620/3531 tweets. Estimated time remaining: 38.0s\n",
      "Processed 1630/3531 tweets. Estimated time remaining: 37.8s\n",
      "Processed 1640/3531 tweets. Estimated time remaining: 37.6s\n",
      "Processed 1650/3531 tweets. Estimated time remaining: 37.4s\n",
      "Processed 1660/3531 tweets. Estimated time remaining: 37.2s\n",
      "Processed 1670/3531 tweets. Estimated time remaining: 37.0s\n",
      "Processed 1680/3531 tweets. Estimated time remaining: 36.8s\n",
      "Processed 1690/3531 tweets. Estimated time remaining: 36.6s\n",
      "Processed 1700/3531 tweets. Estimated time remaining: 36.4s\n",
      "Processed 1710/3531 tweets. Estimated time remaining: 36.2s\n",
      "Processed 1720/3531 tweets. Estimated time remaining: 36.0s\n",
      "Processed 1730/3531 tweets. Estimated time remaining: 35.8s\n",
      "Processed 1740/3531 tweets. Estimated time remaining: 35.6s\n",
      "Processed 1750/3531 tweets. Estimated time remaining: 35.4s\n",
      "Processed 1760/3531 tweets. Estimated time remaining: 35.2s\n",
      "Processed 1770/3531 tweets. Estimated time remaining: 35.0s\n",
      "Processed 1780/3531 tweets. Estimated time remaining: 34.8s\n",
      "Processed 1790/3531 tweets. Estimated time remaining: 34.6s\n",
      "Processed 1800/3531 tweets. Estimated time remaining: 34.4s\n",
      "Processed 1810/3531 tweets. Estimated time remaining: 34.2s\n",
      "Processed 1820/3531 tweets. Estimated time remaining: 34.0s\n",
      "Processed 1830/3531 tweets. Estimated time remaining: 33.8s\n",
      "Processed 1840/3531 tweets. Estimated time remaining: 33.6s\n",
      "Processed 1850/3531 tweets. Estimated time remaining: 33.4s\n",
      "Processed 1860/3531 tweets. Estimated time remaining: 33.2s\n",
      "Processed 1870/3531 tweets. Estimated time remaining: 33.0s\n",
      "Processed 1880/3531 tweets. Estimated time remaining: 32.8s\n",
      "Processed 1890/3531 tweets. Estimated time remaining: 32.6s\n",
      "Processed 1900/3531 tweets. Estimated time remaining: 32.4s\n",
      "Processed 1910/3531 tweets. Estimated time remaining: 32.2s\n",
      "Processed 1920/3531 tweets. Estimated time remaining: 32.0s\n",
      "Processed 1930/3531 tweets. Estimated time remaining: 31.8s\n",
      "Processed 1940/3531 tweets. Estimated time remaining: 31.6s\n",
      "Processed 1950/3531 tweets. Estimated time remaining: 31.4s\n",
      "Processed 1960/3531 tweets. Estimated time remaining: 31.2s\n",
      "Processed 1970/3531 tweets. Estimated time remaining: 31.0s\n",
      "Processed 1980/3531 tweets. Estimated time remaining: 30.9s\n",
      "Processed 1990/3531 tweets. Estimated time remaining: 30.7s\n",
      "Processed 2000/3531 tweets. Estimated time remaining: 30.5s\n",
      "Processed 2010/3531 tweets. Estimated time remaining: 30.3s\n",
      "Processed 2020/3531 tweets. Estimated time remaining: 30.1s\n",
      "Processed 2030/3531 tweets. Estimated time remaining: 29.9s\n",
      "Processed 2040/3531 tweets. Estimated time remaining: 29.7s\n",
      "Processed 2050/3531 tweets. Estimated time remaining: 29.5s\n",
      "Processed 2060/3531 tweets. Estimated time remaining: 29.3s\n",
      "Processed 2070/3531 tweets. Estimated time remaining: 29.1s\n",
      "Processed 2080/3531 tweets. Estimated time remaining: 28.9s\n",
      "Processed 2090/3531 tweets. Estimated time remaining: 28.7s\n",
      "Processed 2100/3531 tweets. Estimated time remaining: 28.5s\n",
      "Processed 2110/3531 tweets. Estimated time remaining: 28.3s\n",
      "Processed 2120/3531 tweets. Estimated time remaining: 28.1s\n",
      "Processed 2130/3531 tweets. Estimated time remaining: 27.9s\n",
      "Processed 2140/3531 tweets. Estimated time remaining: 27.7s\n",
      "Processed 2150/3531 tweets. Estimated time remaining: 27.5s\n",
      "Processed 2160/3531 tweets. Estimated time remaining: 27.3s\n",
      "Processed 2170/3531 tweets. Estimated time remaining: 27.1s\n",
      "Processed 2180/3531 tweets. Estimated time remaining: 26.9s\n",
      "Processed 2190/3531 tweets. Estimated time remaining: 26.7s\n",
      "Processed 2200/3531 tweets. Estimated time remaining: 26.5s\n",
      "Processed 2210/3531 tweets. Estimated time remaining: 26.3s\n",
      "Processed 2220/3531 tweets. Estimated time remaining: 26.1s\n",
      "Processed 2230/3531 tweets. Estimated time remaining: 25.9s\n",
      "Processed 2240/3531 tweets. Estimated time remaining: 25.7s\n",
      "Processed 2250/3531 tweets. Estimated time remaining: 25.5s\n",
      "Processed 2260/3531 tweets. Estimated time remaining: 25.3s\n",
      "Processed 2270/3531 tweets. Estimated time remaining: 25.1s\n",
      "Processed 2280/3531 tweets. Estimated time remaining: 24.9s\n",
      "Processed 2290/3531 tweets. Estimated time remaining: 24.7s\n",
      "Processed 2300/3531 tweets. Estimated time remaining: 24.5s\n",
      "Processed 2310/3531 tweets. Estimated time remaining: 24.3s\n",
      "Processed 2320/3531 tweets. Estimated time remaining: 24.1s\n",
      "Processed 2330/3531 tweets. Estimated time remaining: 23.9s\n",
      "Processed 2340/3531 tweets. Estimated time remaining: 23.7s\n",
      "Processed 2350/3531 tweets. Estimated time remaining: 23.5s\n",
      "Processed 2360/3531 tweets. Estimated time remaining: 23.3s\n",
      "Processed 2370/3531 tweets. Estimated time remaining: 23.1s\n",
      "Processed 2380/3531 tweets. Estimated time remaining: 22.9s\n",
      "Processed 2390/3531 tweets. Estimated time remaining: 22.8s\n",
      "Processed 2400/3531 tweets. Estimated time remaining: 22.6s\n",
      "Processed 2410/3531 tweets. Estimated time remaining: 22.4s\n",
      "Processed 2420/3531 tweets. Estimated time remaining: 22.2s\n",
      "Processed 2430/3531 tweets. Estimated time remaining: 22.0s\n",
      "Processed 2440/3531 tweets. Estimated time remaining: 21.8s\n",
      "Processed 2450/3531 tweets. Estimated time remaining: 21.6s\n",
      "Processed 2460/3531 tweets. Estimated time remaining: 21.4s\n",
      "Processed 2470/3531 tweets. Estimated time remaining: 21.2s\n",
      "Processed 2480/3531 tweets. Estimated time remaining: 21.0s\n",
      "Processed 2490/3531 tweets. Estimated time remaining: 20.8s\n",
      "Processed 2500/3531 tweets. Estimated time remaining: 20.6s\n",
      "Processed 2510/3531 tweets. Estimated time remaining: 20.4s\n",
      "Processed 2520/3531 tweets. Estimated time remaining: 20.2s\n",
      "Processed 2530/3531 tweets. Estimated time remaining: 20.0s\n",
      "Processed 2540/3531 tweets. Estimated time remaining: 19.8s\n",
      "Processed 2550/3531 tweets. Estimated time remaining: 19.6s\n",
      "Processed 2560/3531 tweets. Estimated time remaining: 19.4s\n",
      "Processed 2570/3531 tweets. Estimated time remaining: 19.2s\n",
      "Processed 2580/3531 tweets. Estimated time remaining: 19.0s\n",
      "Processed 2590/3531 tweets. Estimated time remaining: 18.8s\n",
      "Processed 2600/3531 tweets. Estimated time remaining: 18.6s\n",
      "Processed 2610/3531 tweets. Estimated time remaining: 18.4s\n",
      "Processed 2620/3531 tweets. Estimated time remaining: 18.2s\n",
      "Processed 2630/3531 tweets. Estimated time remaining: 18.0s\n",
      "Processed 2640/3531 tweets. Estimated time remaining: 17.8s\n",
      "Processed 2650/3531 tweets. Estimated time remaining: 17.6s\n",
      "Processed 2660/3531 tweets. Estimated time remaining: 17.4s\n",
      "Processed 2670/3531 tweets. Estimated time remaining: 17.2s\n",
      "Processed 2680/3531 tweets. Estimated time remaining: 17.0s\n",
      "Processed 2690/3531 tweets. Estimated time remaining: 16.8s\n",
      "Processed 2700/3531 tweets. Estimated time remaining: 16.6s\n",
      "Processed 2710/3531 tweets. Estimated time remaining: 16.4s\n",
      "Processed 2720/3531 tweets. Estimated time remaining: 16.2s\n",
      "Processed 2730/3531 tweets. Estimated time remaining: 16.0s\n",
      "Processed 2740/3531 tweets. Estimated time remaining: 15.8s\n",
      "Processed 2750/3531 tweets. Estimated time remaining: 15.6s\n",
      "Processed 2760/3531 tweets. Estimated time remaining: 15.4s\n",
      "Processed 2770/3531 tweets. Estimated time remaining: 15.2s\n",
      "Processed 2780/3531 tweets. Estimated time remaining: 15.0s\n",
      "Processed 2790/3531 tweets. Estimated time remaining: 14.8s\n",
      "Processed 2800/3531 tweets. Estimated time remaining: 14.6s\n",
      "Processed 2810/3531 tweets. Estimated time remaining: 14.4s\n",
      "Processed 2820/3531 tweets. Estimated time remaining: 14.2s\n",
      "Processed 2830/3531 tweets. Estimated time remaining: 14.0s\n",
      "Processed 2840/3531 tweets. Estimated time remaining: 13.8s\n",
      "Processed 2850/3531 tweets. Estimated time remaining: 13.6s\n",
      "Processed 2860/3531 tweets. Estimated time remaining: 13.4s\n",
      "Processed 2870/3531 tweets. Estimated time remaining: 13.2s\n",
      "Processed 2880/3531 tweets. Estimated time remaining: 13.0s\n",
      "Processed 2890/3531 tweets. Estimated time remaining: 12.8s\n",
      "Processed 2900/3531 tweets. Estimated time remaining: 12.6s\n",
      "Processed 2910/3531 tweets. Estimated time remaining: 12.4s\n",
      "Processed 2920/3531 tweets. Estimated time remaining: 12.2s\n",
      "Processed 2930/3531 tweets. Estimated time remaining: 12.0s\n",
      "Processed 2940/3531 tweets. Estimated time remaining: 11.8s\n",
      "Processed 2950/3531 tweets. Estimated time remaining: 11.6s\n",
      "Processed 2960/3531 tweets. Estimated time remaining: 11.4s\n",
      "Processed 2970/3531 tweets. Estimated time remaining: 11.2s\n",
      "Processed 2980/3531 tweets. Estimated time remaining: 11.0s\n",
      "Processed 2990/3531 tweets. Estimated time remaining: 10.8s\n",
      "Processed 3000/3531 tweets. Estimated time remaining: 10.6s\n",
      "Processed 3010/3531 tweets. Estimated time remaining: 10.4s\n",
      "Processed 3020/3531 tweets. Estimated time remaining: 10.2s\n",
      "Processed 3030/3531 tweets. Estimated time remaining: 10.0s\n",
      "Processed 3040/3531 tweets. Estimated time remaining: 9.8s\n",
      "Processed 3050/3531 tweets. Estimated time remaining: 9.6s\n",
      "Processed 3060/3531 tweets. Estimated time remaining: 9.4s\n",
      "Processed 3070/3531 tweets. Estimated time remaining: 9.2s\n",
      "Processed 3080/3531 tweets. Estimated time remaining: 9.0s\n",
      "Processed 3090/3531 tweets. Estimated time remaining: 8.8s\n",
      "Processed 3100/3531 tweets. Estimated time remaining: 8.6s\n",
      "Processed 3110/3531 tweets. Estimated time remaining: 8.4s\n",
      "Processed 3120/3531 tweets. Estimated time remaining: 8.2s\n",
      "Processed 3130/3531 tweets. Estimated time remaining: 8.0s\n",
      "Processed 3140/3531 tweets. Estimated time remaining: 7.8s\n",
      "Processed 3150/3531 tweets. Estimated time remaining: 7.6s\n",
      "Processed 3160/3531 tweets. Estimated time remaining: 7.4s\n",
      "Processed 3170/3531 tweets. Estimated time remaining: 7.2s\n",
      "Processed 3180/3531 tweets. Estimated time remaining: 7.0s\n",
      "Processed 3190/3531 tweets. Estimated time remaining: 6.8s\n",
      "Processed 3200/3531 tweets. Estimated time remaining: 6.6s\n",
      "Processed 3210/3531 tweets. Estimated time remaining: 6.4s\n",
      "Processed 3220/3531 tweets. Estimated time remaining: 6.2s\n",
      "Processed 3230/3531 tweets. Estimated time remaining: 6.0s\n",
      "Processed 3240/3531 tweets. Estimated time remaining: 5.8s\n",
      "Processed 3250/3531 tweets. Estimated time remaining: 5.6s\n",
      "Processed 3260/3531 tweets. Estimated time remaining: 5.4s\n",
      "Processed 3270/3531 tweets. Estimated time remaining: 5.2s\n",
      "Processed 3280/3531 tweets. Estimated time remaining: 5.0s\n",
      "Processed 3290/3531 tweets. Estimated time remaining: 4.8s\n",
      "Processed 3300/3531 tweets. Estimated time remaining: 4.6s\n",
      "Processed 3310/3531 tweets. Estimated time remaining: 4.4s\n",
      "Processed 3320/3531 tweets. Estimated time remaining: 4.2s\n",
      "Processed 3330/3531 tweets. Estimated time remaining: 4.0s\n",
      "Processed 3340/3531 tweets. Estimated time remaining: 3.8s\n",
      "Processed 3350/3531 tweets. Estimated time remaining: 3.6s\n",
      "Processed 3360/3531 tweets. Estimated time remaining: 3.4s\n",
      "Processed 3370/3531 tweets. Estimated time remaining: 3.2s\n",
      "Processed 3380/3531 tweets. Estimated time remaining: 3.0s\n",
      "Processed 3390/3531 tweets. Estimated time remaining: 2.8s\n",
      "Processed 3400/3531 tweets. Estimated time remaining: 2.6s\n",
      "Processed 3410/3531 tweets. Estimated time remaining: 2.4s\n",
      "Processed 3420/3531 tweets. Estimated time remaining: 2.2s\n",
      "Processed 3430/3531 tweets. Estimated time remaining: 2.0s\n",
      "Processed 3440/3531 tweets. Estimated time remaining: 1.8s\n",
      "Processed 3450/3531 tweets. Estimated time remaining: 1.6s\n",
      "Processed 3460/3531 tweets. Estimated time remaining: 1.4s\n",
      "Processed 3470/3531 tweets. Estimated time remaining: 1.2s\n",
      "Processed 3480/3531 tweets. Estimated time remaining: 1.0s\n",
      "Processed 3490/3531 tweets. Estimated time remaining: 0.8s\n",
      "Processed 3500/3531 tweets. Estimated time remaining: 0.6s\n",
      "Processed 3510/3531 tweets. Estimated time remaining: 0.4s\n",
      "Processed 3520/3531 tweets. Estimated time remaining: 0.2s\n",
      "Processed 3530/3531 tweets. Estimated time remaining: 0.0s\n",
      "\n",
      "Class-specific metrics:\n",
      "negative: Precision=1.0000, Recall=0.0018, F1=0.0036\n",
      "neutral: Precision=0.4407, Recall=0.8477, F1=0.5799\n",
      "positive: Precision=0.5432, Recall=0.2354, F1=0.3284\n",
      "\n",
      "Test Accuracy: 0.4594\n",
      "Precision: 0.6613\n",
      "Recall: 0.3616\n",
      "F1 Score: 0.3040\n",
      "Average Confidence: 0.327619\n",
      "Prediction Distribution: {'positive': 637, 'neutral': 2893, 'negative': 1}\n",
      "Confusion Matrix:\n",
      "[[   1  494   62]\n",
      " [   0 1275  229]\n",
      " [   0 1124  346]]\n",
      "\n",
      "Top 5 most predicted tokens:\n",
      "'neutral': 2893 times (81.9%)\n",
      "'positive': 627 times (17.8%)\n",
      "'good': 10 times (0.3%)\n",
      "'negative': 1 times (0.0%)\n",
      "\n",
      "Total evaluation time: 70.83 seconds (0.020s per tweet)\n",
      "\n",
      "Evaluating on test set: twitter-test2.txt\n",
      "Processed 10/1853 tweets. Estimated time remaining: 36.4s\n",
      "Processed 20/1853 tweets. Estimated time remaining: 36.2s\n",
      "Processed 30/1853 tweets. Estimated time remaining: 36.5s\n",
      "Processed 40/1853 tweets. Estimated time remaining: 36.5s\n",
      "Processed 50/1853 tweets. Estimated time remaining: 36.4s\n",
      "Processed 60/1853 tweets. Estimated time remaining: 36.4s\n",
      "Processed 70/1853 tweets. Estimated time remaining: 36.1s\n",
      "Processed 80/1853 tweets. Estimated time remaining: 35.9s\n",
      "Processed 90/1853 tweets. Estimated time remaining: 35.8s\n",
      "Processed 100/1853 tweets. Estimated time remaining: 35.6s\n",
      "Processed 110/1853 tweets. Estimated time remaining: 35.4s\n",
      "Processed 120/1853 tweets. Estimated time remaining: 35.3s\n",
      "Processed 130/1853 tweets. Estimated time remaining: 35.1s\n",
      "Processed 140/1853 tweets. Estimated time remaining: 34.9s\n",
      "Processed 150/1853 tweets. Estimated time remaining: 34.7s\n",
      "Processed 160/1853 tweets. Estimated time remaining: 34.5s\n",
      "Processed 170/1853 tweets. Estimated time remaining: 34.3s\n",
      "Processed 180/1853 tweets. Estimated time remaining: 34.1s\n",
      "Processed 190/1853 tweets. Estimated time remaining: 33.9s\n",
      "Processed 200/1853 tweets. Estimated time remaining: 33.6s\n",
      "Processed 210/1853 tweets. Estimated time remaining: 33.4s\n",
      "Processed 220/1853 tweets. Estimated time remaining: 33.3s\n",
      "Processed 230/1853 tweets. Estimated time remaining: 33.1s\n",
      "Processed 240/1853 tweets. Estimated time remaining: 32.9s\n",
      "Processed 250/1853 tweets. Estimated time remaining: 32.7s\n",
      "Processed 260/1853 tweets. Estimated time remaining: 32.5s\n",
      "Processed 270/1853 tweets. Estimated time remaining: 32.2s\n",
      "Processed 280/1853 tweets. Estimated time remaining: 32.0s\n",
      "Processed 290/1853 tweets. Estimated time remaining: 31.8s\n",
      "Processed 300/1853 tweets. Estimated time remaining: 31.6s\n",
      "Processed 310/1853 tweets. Estimated time remaining: 31.4s\n",
      "Processed 320/1853 tweets. Estimated time remaining: 31.2s\n",
      "Processed 330/1853 tweets. Estimated time remaining: 31.0s\n",
      "Processed 340/1853 tweets. Estimated time remaining: 30.8s\n",
      "Processed 350/1853 tweets. Estimated time remaining: 30.6s\n",
      "Processed 360/1853 tweets. Estimated time remaining: 30.4s\n",
      "Processed 370/1853 tweets. Estimated time remaining: 30.2s\n",
      "Processed 380/1853 tweets. Estimated time remaining: 29.9s\n",
      "Processed 390/1853 tweets. Estimated time remaining: 29.7s\n",
      "Processed 400/1853 tweets. Estimated time remaining: 29.5s\n",
      "Processed 410/1853 tweets. Estimated time remaining: 29.3s\n",
      "Processed 420/1853 tweets. Estimated time remaining: 29.1s\n",
      "Processed 430/1853 tweets. Estimated time remaining: 28.9s\n",
      "Processed 440/1853 tweets. Estimated time remaining: 28.7s\n",
      "Processed 450/1853 tweets. Estimated time remaining: 28.5s\n",
      "Processed 460/1853 tweets. Estimated time remaining: 28.3s\n",
      "Processed 470/1853 tweets. Estimated time remaining: 28.1s\n",
      "Processed 480/1853 tweets. Estimated time remaining: 27.9s\n",
      "Processed 490/1853 tweets. Estimated time remaining: 27.7s\n",
      "Processed 500/1853 tweets. Estimated time remaining: 27.5s\n",
      "Processed 510/1853 tweets. Estimated time remaining: 27.3s\n",
      "Processed 520/1853 tweets. Estimated time remaining: 27.1s\n",
      "Processed 530/1853 tweets. Estimated time remaining: 26.9s\n",
      "Processed 540/1853 tweets. Estimated time remaining: 26.7s\n",
      "Processed 550/1853 tweets. Estimated time remaining: 26.5s\n",
      "Processed 560/1853 tweets. Estimated time remaining: 26.3s\n",
      "Processed 570/1853 tweets. Estimated time remaining: 26.1s\n",
      "Processed 580/1853 tweets. Estimated time remaining: 25.9s\n",
      "Processed 590/1853 tweets. Estimated time remaining: 25.7s\n",
      "Processed 600/1853 tweets. Estimated time remaining: 25.5s\n",
      "Processed 610/1853 tweets. Estimated time remaining: 25.3s\n",
      "Processed 620/1853 tweets. Estimated time remaining: 25.1s\n",
      "Processed 630/1853 tweets. Estimated time remaining: 24.9s\n",
      "Processed 640/1853 tweets. Estimated time remaining: 24.7s\n",
      "Processed 650/1853 tweets. Estimated time remaining: 24.5s\n",
      "Processed 660/1853 tweets. Estimated time remaining: 24.3s\n",
      "Processed 670/1853 tweets. Estimated time remaining: 24.1s\n",
      "Processed 680/1853 tweets. Estimated time remaining: 23.8s\n",
      "Processed 690/1853 tweets. Estimated time remaining: 23.6s\n",
      "Processed 700/1853 tweets. Estimated time remaining: 23.4s\n",
      "Processed 710/1853 tweets. Estimated time remaining: 23.2s\n",
      "Processed 720/1853 tweets. Estimated time remaining: 23.0s\n",
      "Processed 730/1853 tweets. Estimated time remaining: 22.8s\n",
      "Processed 740/1853 tweets. Estimated time remaining: 22.6s\n",
      "Processed 750/1853 tweets. Estimated time remaining: 22.4s\n",
      "Processed 760/1853 tweets. Estimated time remaining: 22.2s\n",
      "Processed 770/1853 tweets. Estimated time remaining: 22.0s\n",
      "Processed 780/1853 tweets. Estimated time remaining: 21.8s\n",
      "Processed 790/1853 tweets. Estimated time remaining: 21.6s\n",
      "Processed 800/1853 tweets. Estimated time remaining: 21.4s\n",
      "Processed 810/1853 tweets. Estimated time remaining: 21.2s\n",
      "Processed 820/1853 tweets. Estimated time remaining: 21.0s\n",
      "Processed 830/1853 tweets. Estimated time remaining: 20.8s\n",
      "Processed 840/1853 tweets. Estimated time remaining: 20.6s\n",
      "Processed 850/1853 tweets. Estimated time remaining: 20.4s\n",
      "Processed 860/1853 tweets. Estimated time remaining: 20.2s\n",
      "Processed 870/1853 tweets. Estimated time remaining: 20.0s\n",
      "Processed 880/1853 tweets. Estimated time remaining: 19.8s\n",
      "Processed 890/1853 tweets. Estimated time remaining: 19.6s\n",
      "Processed 900/1853 tweets. Estimated time remaining: 19.4s\n",
      "Processed 910/1853 tweets. Estimated time remaining: 19.2s\n",
      "Processed 920/1853 tweets. Estimated time remaining: 19.0s\n",
      "Processed 930/1853 tweets. Estimated time remaining: 18.8s\n",
      "Processed 940/1853 tweets. Estimated time remaining: 18.6s\n",
      "Processed 950/1853 tweets. Estimated time remaining: 18.4s\n",
      "Processed 960/1853 tweets. Estimated time remaining: 18.2s\n",
      "Processed 970/1853 tweets. Estimated time remaining: 18.0s\n",
      "Processed 980/1853 tweets. Estimated time remaining: 17.8s\n",
      "Processed 990/1853 tweets. Estimated time remaining: 17.6s\n",
      "Processed 1000/1853 tweets. Estimated time remaining: 17.4s\n",
      "Processed 1010/1853 tweets. Estimated time remaining: 17.2s\n",
      "Processed 1020/1853 tweets. Estimated time remaining: 17.0s\n",
      "Processed 1030/1853 tweets. Estimated time remaining: 16.8s\n",
      "Processed 1040/1853 tweets. Estimated time remaining: 16.6s\n",
      "Processed 1050/1853 tweets. Estimated time remaining: 16.4s\n",
      "Processed 1060/1853 tweets. Estimated time remaining: 16.2s\n",
      "Processed 1070/1853 tweets. Estimated time remaining: 16.0s\n",
      "Processed 1080/1853 tweets. Estimated time remaining: 15.8s\n",
      "Processed 1090/1853 tweets. Estimated time remaining: 15.6s\n",
      "Processed 1100/1853 tweets. Estimated time remaining: 15.4s\n",
      "Processed 1110/1853 tweets. Estimated time remaining: 15.2s\n",
      "Processed 1120/1853 tweets. Estimated time remaining: 14.9s\n",
      "Processed 1130/1853 tweets. Estimated time remaining: 14.7s\n",
      "Processed 1140/1853 tweets. Estimated time remaining: 14.5s\n",
      "Processed 1150/1853 tweets. Estimated time remaining: 14.3s\n",
      "Processed 1160/1853 tweets. Estimated time remaining: 14.1s\n",
      "Processed 1170/1853 tweets. Estimated time remaining: 13.9s\n",
      "Processed 1180/1853 tweets. Estimated time remaining: 13.7s\n",
      "Processed 1190/1853 tweets. Estimated time remaining: 13.5s\n",
      "Processed 1200/1853 tweets. Estimated time remaining: 13.3s\n",
      "Processed 1210/1853 tweets. Estimated time remaining: 13.1s\n",
      "Processed 1220/1853 tweets. Estimated time remaining: 12.9s\n",
      "Processed 1230/1853 tweets. Estimated time remaining: 12.7s\n",
      "Processed 1240/1853 tweets. Estimated time remaining: 12.5s\n",
      "Processed 1250/1853 tweets. Estimated time remaining: 12.3s\n",
      "Processed 1260/1853 tweets. Estimated time remaining: 12.1s\n",
      "Processed 1270/1853 tweets. Estimated time remaining: 11.9s\n",
      "Processed 1280/1853 tweets. Estimated time remaining: 11.7s\n",
      "Processed 1290/1853 tweets. Estimated time remaining: 11.5s\n",
      "Processed 1300/1853 tweets. Estimated time remaining: 11.3s\n",
      "Processed 1310/1853 tweets. Estimated time remaining: 11.1s\n",
      "Processed 1320/1853 tweets. Estimated time remaining: 10.9s\n",
      "Processed 1330/1853 tweets. Estimated time remaining: 10.7s\n",
      "Processed 1340/1853 tweets. Estimated time remaining: 10.5s\n",
      "Processed 1350/1853 tweets. Estimated time remaining: 10.3s\n",
      "Processed 1360/1853 tweets. Estimated time remaining: 10.1s\n",
      "Processed 1370/1853 tweets. Estimated time remaining: 9.9s\n",
      "Processed 1380/1853 tweets. Estimated time remaining: 9.6s\n",
      "Processed 1390/1853 tweets. Estimated time remaining: 9.4s\n",
      "Processed 1400/1853 tweets. Estimated time remaining: 9.2s\n",
      "Processed 1410/1853 tweets. Estimated time remaining: 9.0s\n",
      "Processed 1420/1853 tweets. Estimated time remaining: 8.8s\n",
      "Processed 1430/1853 tweets. Estimated time remaining: 8.6s\n",
      "Processed 1440/1853 tweets. Estimated time remaining: 8.4s\n",
      "Processed 1450/1853 tweets. Estimated time remaining: 8.2s\n",
      "Processed 1460/1853 tweets. Estimated time remaining: 8.0s\n",
      "Processed 1470/1853 tweets. Estimated time remaining: 7.8s\n",
      "Processed 1480/1853 tweets. Estimated time remaining: 7.6s\n",
      "Processed 1490/1853 tweets. Estimated time remaining: 7.4s\n",
      "Processed 1500/1853 tweets. Estimated time remaining: 7.2s\n",
      "Processed 1510/1853 tweets. Estimated time remaining: 7.0s\n",
      "Processed 1520/1853 tweets. Estimated time remaining: 6.8s\n",
      "Processed 1530/1853 tweets. Estimated time remaining: 6.6s\n",
      "Processed 1540/1853 tweets. Estimated time remaining: 6.4s\n",
      "Processed 1550/1853 tweets. Estimated time remaining: 6.2s\n",
      "Processed 1560/1853 tweets. Estimated time remaining: 6.0s\n",
      "Processed 1570/1853 tweets. Estimated time remaining: 5.8s\n",
      "Processed 1580/1853 tweets. Estimated time remaining: 5.6s\n",
      "Processed 1590/1853 tweets. Estimated time remaining: 5.4s\n",
      "Processed 1600/1853 tweets. Estimated time remaining: 5.2s\n",
      "Processed 1610/1853 tweets. Estimated time remaining: 5.0s\n",
      "Processed 1620/1853 tweets. Estimated time remaining: 4.8s\n",
      "Processed 1630/1853 tweets. Estimated time remaining: 4.6s\n",
      "Processed 1640/1853 tweets. Estimated time remaining: 4.4s\n",
      "Processed 1650/1853 tweets. Estimated time remaining: 4.1s\n",
      "Processed 1660/1853 tweets. Estimated time remaining: 3.9s\n",
      "Processed 1670/1853 tweets. Estimated time remaining: 3.7s\n",
      "Processed 1680/1853 tweets. Estimated time remaining: 3.5s\n",
      "Processed 1690/1853 tweets. Estimated time remaining: 3.3s\n",
      "Processed 1700/1853 tweets. Estimated time remaining: 3.1s\n",
      "Processed 1710/1853 tweets. Estimated time remaining: 2.9s\n",
      "Processed 1720/1853 tweets. Estimated time remaining: 2.7s\n",
      "Processed 1730/1853 tweets. Estimated time remaining: 2.5s\n",
      "Processed 1740/1853 tweets. Estimated time remaining: 2.3s\n",
      "Processed 1750/1853 tweets. Estimated time remaining: 2.1s\n",
      "Processed 1760/1853 tweets. Estimated time remaining: 1.9s\n",
      "Processed 1770/1853 tweets. Estimated time remaining: 1.7s\n",
      "Processed 1780/1853 tweets. Estimated time remaining: 1.5s\n",
      "Processed 1790/1853 tweets. Estimated time remaining: 1.3s\n",
      "Processed 1800/1853 tweets. Estimated time remaining: 1.1s\n",
      "Processed 1810/1853 tweets. Estimated time remaining: 0.9s\n",
      "Processed 1820/1853 tweets. Estimated time remaining: 0.7s\n",
      "Processed 1830/1853 tweets. Estimated time remaining: 0.5s\n",
      "Processed 1840/1853 tweets. Estimated time remaining: 0.3s\n",
      "Processed 1850/1853 tweets. Estimated time remaining: 0.1s\n",
      "\n",
      "Class-specific metrics:\n",
      "negative: Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "neutral: Precision=0.3779, Recall=0.8401, F1=0.5213\n",
      "positive: Precision=0.6530, Recall=0.2434, F1=0.3546\n",
      "\n",
      "Test Accuracy: 0.4323\n",
      "Precision: 0.3436\n",
      "Recall: 0.3611\n",
      "F1 Score: 0.2920\n",
      "Average Confidence: 0.319582\n",
      "Prediction Distribution: {'neutral': 1487, 'positive': 366}\n",
      "Confusion Matrix:\n",
      "[[  0 182  20]\n",
      " [  0 562 107]\n",
      " [  0 743 239]]\n",
      "\n",
      "Top 5 most predicted tokens:\n",
      "'neutral': 1487 times (80.2%)\n",
      "'positive': 362 times (19.5%)\n",
      "'good': 4 times (0.2%)\n",
      "\n",
      "Total evaluation time: 37.88 seconds (0.020s per tweet)\n",
      "\n",
      "Evaluating on test set: twitter-test3.txt\n",
      "Processed 10/2379 tweets. Estimated time remaining: 49.8s\n",
      "Processed 20/2379 tweets. Estimated time remaining: 48.9s\n",
      "Processed 30/2379 tweets. Estimated time remaining: 48.7s\n",
      "Processed 40/2379 tweets. Estimated time remaining: 48.1s\n",
      "Processed 50/2379 tweets. Estimated time remaining: 48.1s\n",
      "Processed 60/2379 tweets. Estimated time remaining: 48.0s\n",
      "Processed 70/2379 tweets. Estimated time remaining: 48.0s\n",
      "Processed 80/2379 tweets. Estimated time remaining: 47.7s\n",
      "Processed 90/2379 tweets. Estimated time remaining: 47.4s\n",
      "Processed 100/2379 tweets. Estimated time remaining: 47.2s\n",
      "Processed 110/2379 tweets. Estimated time remaining: 47.0s\n",
      "Processed 120/2379 tweets. Estimated time remaining: 46.7s\n",
      "Processed 130/2379 tweets. Estimated time remaining: 46.4s\n",
      "Processed 140/2379 tweets. Estimated time remaining: 46.2s\n",
      "Processed 150/2379 tweets. Estimated time remaining: 45.9s\n",
      "Processed 160/2379 tweets. Estimated time remaining: 45.7s\n",
      "Processed 170/2379 tweets. Estimated time remaining: 45.5s\n",
      "Processed 180/2379 tweets. Estimated time remaining: 45.4s\n",
      "Processed 190/2379 tweets. Estimated time remaining: 45.1s\n",
      "Processed 200/2379 tweets. Estimated time remaining: 45.0s\n",
      "Processed 210/2379 tweets. Estimated time remaining: 44.7s\n",
      "Processed 220/2379 tweets. Estimated time remaining: 44.5s\n",
      "Processed 230/2379 tweets. Estimated time remaining: 44.2s\n",
      "Processed 240/2379 tweets. Estimated time remaining: 44.0s\n",
      "Processed 250/2379 tweets. Estimated time remaining: 43.8s\n",
      "Processed 260/2379 tweets. Estimated time remaining: 43.6s\n",
      "Processed 270/2379 tweets. Estimated time remaining: 43.3s\n",
      "Processed 280/2379 tweets. Estimated time remaining: 43.1s\n",
      "Processed 290/2379 tweets. Estimated time remaining: 42.9s\n",
      "Processed 300/2379 tweets. Estimated time remaining: 42.7s\n",
      "Processed 310/2379 tweets. Estimated time remaining: 42.5s\n",
      "Processed 320/2379 tweets. Estimated time remaining: 42.3s\n",
      "Processed 330/2379 tweets. Estimated time remaining: 42.1s\n",
      "Processed 340/2379 tweets. Estimated time remaining: 41.9s\n",
      "Processed 350/2379 tweets. Estimated time remaining: 41.7s\n",
      "Processed 360/2379 tweets. Estimated time remaining: 41.5s\n",
      "Processed 370/2379 tweets. Estimated time remaining: 41.3s\n",
      "Processed 380/2379 tweets. Estimated time remaining: 41.1s\n",
      "Processed 390/2379 tweets. Estimated time remaining: 40.9s\n",
      "Processed 400/2379 tweets. Estimated time remaining: 40.7s\n",
      "Processed 410/2379 tweets. Estimated time remaining: 40.5s\n",
      "Processed 420/2379 tweets. Estimated time remaining: 40.3s\n",
      "Processed 430/2379 tweets. Estimated time remaining: 40.1s\n",
      "Processed 440/2379 tweets. Estimated time remaining: 39.9s\n",
      "Processed 450/2379 tweets. Estimated time remaining: 39.7s\n",
      "Processed 460/2379 tweets. Estimated time remaining: 39.5s\n",
      "Processed 470/2379 tweets. Estimated time remaining: 39.3s\n",
      "Processed 480/2379 tweets. Estimated time remaining: 39.0s\n",
      "Processed 490/2379 tweets. Estimated time remaining: 38.8s\n",
      "Processed 500/2379 tweets. Estimated time remaining: 38.6s\n",
      "Processed 510/2379 tweets. Estimated time remaining: 38.4s\n",
      "Processed 520/2379 tweets. Estimated time remaining: 38.2s\n",
      "Processed 530/2379 tweets. Estimated time remaining: 38.0s\n",
      "Processed 540/2379 tweets. Estimated time remaining: 37.8s\n",
      "Processed 550/2379 tweets. Estimated time remaining: 37.5s\n",
      "Processed 560/2379 tweets. Estimated time remaining: 37.3s\n",
      "Processed 570/2379 tweets. Estimated time remaining: 37.1s\n",
      "Processed 580/2379 tweets. Estimated time remaining: 36.9s\n",
      "Processed 590/2379 tweets. Estimated time remaining: 36.7s\n",
      "Processed 600/2379 tweets. Estimated time remaining: 36.5s\n",
      "Processed 610/2379 tweets. Estimated time remaining: 36.3s\n",
      "Processed 620/2379 tweets. Estimated time remaining: 36.1s\n",
      "Processed 630/2379 tweets. Estimated time remaining: 35.9s\n",
      "Processed 640/2379 tweets. Estimated time remaining: 35.7s\n",
      "Processed 650/2379 tweets. Estimated time remaining: 35.5s\n",
      "Processed 660/2379 tweets. Estimated time remaining: 35.3s\n",
      "Processed 670/2379 tweets. Estimated time remaining: 35.1s\n",
      "Processed 680/2379 tweets. Estimated time remaining: 34.9s\n",
      "Processed 690/2379 tweets. Estimated time remaining: 34.7s\n",
      "Processed 700/2379 tweets. Estimated time remaining: 34.5s\n",
      "Processed 710/2379 tweets. Estimated time remaining: 34.3s\n",
      "Processed 720/2379 tweets. Estimated time remaining: 34.1s\n",
      "Processed 730/2379 tweets. Estimated time remaining: 33.9s\n",
      "Processed 740/2379 tweets. Estimated time remaining: 33.7s\n",
      "Processed 750/2379 tweets. Estimated time remaining: 33.4s\n",
      "Processed 760/2379 tweets. Estimated time remaining: 33.2s\n",
      "Processed 770/2379 tweets. Estimated time remaining: 33.0s\n",
      "Processed 780/2379 tweets. Estimated time remaining: 32.8s\n",
      "Processed 790/2379 tweets. Estimated time remaining: 32.6s\n",
      "Processed 800/2379 tweets. Estimated time remaining: 32.4s\n",
      "Processed 810/2379 tweets. Estimated time remaining: 32.2s\n",
      "Processed 820/2379 tweets. Estimated time remaining: 32.0s\n",
      "Processed 830/2379 tweets. Estimated time remaining: 31.8s\n",
      "Processed 840/2379 tweets. Estimated time remaining: 31.6s\n",
      "Processed 850/2379 tweets. Estimated time remaining: 31.3s\n",
      "Processed 860/2379 tweets. Estimated time remaining: 31.1s\n",
      "Processed 870/2379 tweets. Estimated time remaining: 30.9s\n",
      "Processed 880/2379 tweets. Estimated time remaining: 30.7s\n",
      "Processed 890/2379 tweets. Estimated time remaining: 30.5s\n",
      "Processed 900/2379 tweets. Estimated time remaining: 30.3s\n",
      "Processed 910/2379 tweets. Estimated time remaining: 30.1s\n",
      "Processed 920/2379 tweets. Estimated time remaining: 29.9s\n",
      "Processed 930/2379 tweets. Estimated time remaining: 29.7s\n",
      "Processed 940/2379 tweets. Estimated time remaining: 29.5s\n",
      "Processed 950/2379 tweets. Estimated time remaining: 29.3s\n",
      "Processed 960/2379 tweets. Estimated time remaining: 29.1s\n",
      "Processed 970/2379 tweets. Estimated time remaining: 28.8s\n",
      "Processed 980/2379 tweets. Estimated time remaining: 28.6s\n",
      "Processed 990/2379 tweets. Estimated time remaining: 28.4s\n",
      "Processed 1000/2379 tweets. Estimated time remaining: 28.2s\n",
      "Processed 1010/2379 tweets. Estimated time remaining: 28.0s\n",
      "Processed 1020/2379 tweets. Estimated time remaining: 27.8s\n",
      "Processed 1030/2379 tweets. Estimated time remaining: 27.6s\n",
      "Processed 1040/2379 tweets. Estimated time remaining: 27.4s\n",
      "Processed 1050/2379 tweets. Estimated time remaining: 27.2s\n",
      "Processed 1060/2379 tweets. Estimated time remaining: 27.0s\n",
      "Processed 1070/2379 tweets. Estimated time remaining: 26.8s\n",
      "Processed 1080/2379 tweets. Estimated time remaining: 26.6s\n",
      "Processed 1090/2379 tweets. Estimated time remaining: 26.4s\n",
      "Processed 1100/2379 tweets. Estimated time remaining: 26.2s\n",
      "Processed 1110/2379 tweets. Estimated time remaining: 26.0s\n",
      "Processed 1120/2379 tweets. Estimated time remaining: 25.7s\n",
      "Processed 1130/2379 tweets. Estimated time remaining: 25.5s\n",
      "Processed 1140/2379 tweets. Estimated time remaining: 25.3s\n",
      "Processed 1150/2379 tweets. Estimated time remaining: 25.1s\n",
      "Processed 1160/2379 tweets. Estimated time remaining: 24.9s\n",
      "Processed 1170/2379 tweets. Estimated time remaining: 24.7s\n",
      "Processed 1180/2379 tweets. Estimated time remaining: 24.6s\n",
      "Processed 1190/2379 tweets. Estimated time remaining: 24.4s\n",
      "Processed 1200/2379 tweets. Estimated time remaining: 24.2s\n",
      "Processed 1210/2379 tweets. Estimated time remaining: 24.0s\n",
      "Processed 1220/2379 tweets. Estimated time remaining: 23.8s\n",
      "Processed 1230/2379 tweets. Estimated time remaining: 23.6s\n",
      "Processed 1240/2379 tweets. Estimated time remaining: 23.4s\n",
      "Processed 1250/2379 tweets. Estimated time remaining: 23.2s\n",
      "Processed 1260/2379 tweets. Estimated time remaining: 22.9s\n",
      "Processed 1270/2379 tweets. Estimated time remaining: 22.7s\n",
      "Processed 1280/2379 tweets. Estimated time remaining: 22.5s\n",
      "Processed 1290/2379 tweets. Estimated time remaining: 22.3s\n",
      "Processed 1300/2379 tweets. Estimated time remaining: 22.1s\n",
      "Processed 1310/2379 tweets. Estimated time remaining: 21.9s\n",
      "Processed 1320/2379 tweets. Estimated time remaining: 21.7s\n",
      "Processed 1330/2379 tweets. Estimated time remaining: 21.5s\n",
      "Processed 1340/2379 tweets. Estimated time remaining: 21.3s\n",
      "Processed 1350/2379 tweets. Estimated time remaining: 21.1s\n",
      "Processed 1360/2379 tweets. Estimated time remaining: 20.9s\n",
      "Processed 1370/2379 tweets. Estimated time remaining: 20.7s\n",
      "Processed 1380/2379 tweets. Estimated time remaining: 20.5s\n",
      "Processed 1390/2379 tweets. Estimated time remaining: 20.3s\n",
      "Processed 1400/2379 tweets. Estimated time remaining: 20.1s\n",
      "Processed 1410/2379 tweets. Estimated time remaining: 19.9s\n",
      "Processed 1420/2379 tweets. Estimated time remaining: 19.7s\n",
      "Processed 1430/2379 tweets. Estimated time remaining: 19.5s\n",
      "Processed 1440/2379 tweets. Estimated time remaining: 19.3s\n",
      "Processed 1450/2379 tweets. Estimated time remaining: 19.1s\n",
      "Processed 1460/2379 tweets. Estimated time remaining: 18.8s\n",
      "Processed 1470/2379 tweets. Estimated time remaining: 18.6s\n",
      "Processed 1480/2379 tweets. Estimated time remaining: 18.4s\n",
      "Processed 1490/2379 tweets. Estimated time remaining: 18.2s\n",
      "Processed 1500/2379 tweets. Estimated time remaining: 18.0s\n",
      "Processed 1510/2379 tweets. Estimated time remaining: 17.8s\n",
      "Processed 1520/2379 tweets. Estimated time remaining: 17.6s\n",
      "Processed 1530/2379 tweets. Estimated time remaining: 17.4s\n",
      "Processed 1540/2379 tweets. Estimated time remaining: 17.2s\n",
      "Processed 1550/2379 tweets. Estimated time remaining: 17.0s\n",
      "Processed 1560/2379 tweets. Estimated time remaining: 16.8s\n",
      "Processed 1570/2379 tweets. Estimated time remaining: 16.6s\n",
      "Processed 1580/2379 tweets. Estimated time remaining: 16.4s\n",
      "Processed 1590/2379 tweets. Estimated time remaining: 16.2s\n",
      "Processed 1600/2379 tweets. Estimated time remaining: 16.0s\n",
      "Processed 1610/2379 tweets. Estimated time remaining: 15.8s\n",
      "Processed 1620/2379 tweets. Estimated time remaining: 15.6s\n",
      "Processed 1630/2379 tweets. Estimated time remaining: 15.4s\n",
      "Processed 1640/2379 tweets. Estimated time remaining: 15.1s\n",
      "Processed 1650/2379 tweets. Estimated time remaining: 14.9s\n",
      "Processed 1660/2379 tweets. Estimated time remaining: 14.7s\n",
      "Processed 1670/2379 tweets. Estimated time remaining: 14.5s\n",
      "Processed 1680/2379 tweets. Estimated time remaining: 14.3s\n",
      "Processed 1690/2379 tweets. Estimated time remaining: 14.1s\n",
      "Processed 1700/2379 tweets. Estimated time remaining: 13.9s\n",
      "Processed 1710/2379 tweets. Estimated time remaining: 13.7s\n",
      "Processed 1720/2379 tweets. Estimated time remaining: 13.5s\n",
      "Processed 1730/2379 tweets. Estimated time remaining: 13.3s\n",
      "Processed 1740/2379 tweets. Estimated time remaining: 13.1s\n",
      "Processed 1750/2379 tweets. Estimated time remaining: 12.9s\n",
      "Processed 1760/2379 tweets. Estimated time remaining: 12.7s\n",
      "Processed 1770/2379 tweets. Estimated time remaining: 12.5s\n",
      "Processed 1780/2379 tweets. Estimated time remaining: 12.3s\n",
      "Processed 1790/2379 tweets. Estimated time remaining: 12.1s\n",
      "Processed 1800/2379 tweets. Estimated time remaining: 11.9s\n",
      "Processed 1810/2379 tweets. Estimated time remaining: 11.7s\n",
      "Processed 1820/2379 tweets. Estimated time remaining: 11.5s\n",
      "Processed 1830/2379 tweets. Estimated time remaining: 11.2s\n",
      "Processed 1840/2379 tweets. Estimated time remaining: 11.0s\n",
      "Processed 1850/2379 tweets. Estimated time remaining: 10.8s\n",
      "Processed 1860/2379 tweets. Estimated time remaining: 10.6s\n",
      "Processed 1870/2379 tweets. Estimated time remaining: 10.4s\n",
      "Processed 1880/2379 tweets. Estimated time remaining: 10.2s\n",
      "Processed 1890/2379 tweets. Estimated time remaining: 10.0s\n",
      "Processed 1900/2379 tweets. Estimated time remaining: 9.8s\n",
      "Processed 1910/2379 tweets. Estimated time remaining: 9.6s\n",
      "Processed 1920/2379 tweets. Estimated time remaining: 9.4s\n",
      "Processed 1930/2379 tweets. Estimated time remaining: 9.2s\n",
      "Processed 1940/2379 tweets. Estimated time remaining: 9.0s\n",
      "Processed 1950/2379 tweets. Estimated time remaining: 8.8s\n",
      "Processed 1960/2379 tweets. Estimated time remaining: 8.6s\n",
      "Processed 1970/2379 tweets. Estimated time remaining: 8.4s\n",
      "Processed 1980/2379 tweets. Estimated time remaining: 8.2s\n",
      "Processed 1990/2379 tweets. Estimated time remaining: 8.0s\n",
      "Processed 2000/2379 tweets. Estimated time remaining: 7.8s\n",
      "Processed 2010/2379 tweets. Estimated time remaining: 7.6s\n",
      "Processed 2020/2379 tweets. Estimated time remaining: 7.4s\n",
      "Processed 2030/2379 tweets. Estimated time remaining: 7.2s\n",
      "Processed 2040/2379 tweets. Estimated time remaining: 7.0s\n",
      "Processed 2050/2379 tweets. Estimated time remaining: 6.7s\n",
      "Processed 2060/2379 tweets. Estimated time remaining: 6.5s\n",
      "Processed 2070/2379 tweets. Estimated time remaining: 6.3s\n",
      "Processed 2080/2379 tweets. Estimated time remaining: 6.1s\n",
      "Processed 2090/2379 tweets. Estimated time remaining: 5.9s\n",
      "Processed 2100/2379 tweets. Estimated time remaining: 5.7s\n",
      "Processed 2110/2379 tweets. Estimated time remaining: 5.5s\n",
      "Processed 2120/2379 tweets. Estimated time remaining: 5.3s\n",
      "Processed 2130/2379 tweets. Estimated time remaining: 5.1s\n",
      "Processed 2140/2379 tweets. Estimated time remaining: 4.9s\n",
      "Processed 2150/2379 tweets. Estimated time remaining: 4.7s\n",
      "Processed 2160/2379 tweets. Estimated time remaining: 4.5s\n",
      "Processed 2170/2379 tweets. Estimated time remaining: 4.3s\n",
      "Processed 2180/2379 tweets. Estimated time remaining: 4.1s\n",
      "Processed 2190/2379 tweets. Estimated time remaining: 3.9s\n",
      "Processed 2200/2379 tweets. Estimated time remaining: 3.7s\n",
      "Processed 2210/2379 tweets. Estimated time remaining: 3.5s\n",
      "Processed 2220/2379 tweets. Estimated time remaining: 3.3s\n",
      "Processed 2230/2379 tweets. Estimated time remaining: 3.1s\n",
      "Processed 2240/2379 tweets. Estimated time remaining: 2.9s\n",
      "Processed 2250/2379 tweets. Estimated time remaining: 2.6s\n",
      "Processed 2260/2379 tweets. Estimated time remaining: 2.4s\n",
      "Processed 2270/2379 tweets. Estimated time remaining: 2.2s\n",
      "Processed 2280/2379 tweets. Estimated time remaining: 2.0s\n",
      "Processed 2290/2379 tweets. Estimated time remaining: 1.8s\n",
      "Processed 2300/2379 tweets. Estimated time remaining: 1.6s\n",
      "Processed 2310/2379 tweets. Estimated time remaining: 1.4s\n",
      "Processed 2320/2379 tweets. Estimated time remaining: 1.2s\n",
      "Processed 2330/2379 tweets. Estimated time remaining: 1.0s\n",
      "Processed 2340/2379 tweets. Estimated time remaining: 0.8s\n",
      "Processed 2350/2379 tweets. Estimated time remaining: 0.6s\n",
      "Processed 2360/2379 tweets. Estimated time remaining: 0.4s\n",
      "Processed 2370/2379 tweets. Estimated time remaining: 0.2s\n",
      "\n",
      "Class-specific metrics:\n",
      "negative: Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "neutral: Precision=0.4227, Recall=0.8728, F1=0.5695\n",
      "positive: Precision=0.5473, Recall=0.1849, F1=0.2764\n",
      "\n",
      "Test Accuracy: 0.4409\n",
      "Precision: 0.3233\n",
      "Recall: 0.3526\n",
      "F1 Score: 0.2820\n",
      "Average Confidence: 0.346823\n",
      "Prediction Distribution: {'positive': 349, 'neutral': 2030}\n",
      "Confusion Matrix:\n",
      "[[  0 330  33]\n",
      " [  0 858 125]\n",
      " [  0 842 191]]\n",
      "\n",
      "Top 5 most predicted tokens:\n",
      "'neutral': 2030 times (85.3%)\n",
      "'positive': 330 times (13.9%)\n",
      "'good': 19 times (0.8%)\n",
      "\n",
      "Total evaluation time: 48.81 seconds (0.021s per tweet)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "# Loop over each test set and evaluate\n",
    "for test_set in testsets:\n",
    "    print(f\"\\nEvaluating on test set: {test_set}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get the raw tweet texts and true sentiment labels (as strings)\n",
    "    test_texts = tweets[test_set]\n",
    "    test_labels_str = tweetgts[test_set]  # e.g., [\"positive\", \"negative\", \"neutral\", ...]\n",
    "    \n",
    "    # Lists to store predictions and debugging information\n",
    "    pred_labels = []\n",
    "    confidences = []\n",
    "    token_prediction_counts = {}  # Count which tokens are most commonly predicted\n",
    "    \n",
    "    # Process each tweet using the enhanced BERT MLM function\n",
    "    for i, tweet in enumerate(test_texts):\n",
    "        try:\n",
    "            # Use the new function signature with debugging info\n",
    "            predicted_sentiment, sentiment_scores, _, debug_info = prompt_sentiment_few_shot(tweet)\n",
    "            pred_labels.append(predicted_sentiment)\n",
    "            \n",
    "            # Store confidence for analysis\n",
    "            if \"confidence\" in debug_info:\n",
    "                confidences.append(debug_info[\"confidence\"])\n",
    "                \n",
    "            # Track what tokens BERT is actually predicting\n",
    "            if \"top_predicted_token\" in debug_info:\n",
    "                top_token = debug_info[\"top_predicted_token\"]\n",
    "                token_prediction_counts[top_token] = token_prediction_counts.get(top_token, 0) + 1\n",
    "            \n",
    "            # Print progress every 10 tweets\n",
    "            if (i + 1) % 10 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                avg_time = elapsed / (i + 1)\n",
    "                remaining = avg_time * (len(test_texts) - (i + 1))\n",
    "                print(f\"Processed {i + 1}/{len(test_texts)} tweets. Estimated time remaining: {remaining:.1f}s\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing tweet {i}: {e}\")\n",
    "            # Skip this example or use a default sentiment (e.g., most common in the dataset)\n",
    "            most_common_sentiment = max(set(test_labels_str), key=test_labels_str.count)\n",
    "            pred_labels.append(most_common_sentiment)\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    test_accuracy = accuracy_score(test_labels_str, pred_labels)\n",
    "    precision = precision_score(test_labels_str, pred_labels, average='macro', zero_division=0)\n",
    "    recall = recall_score(test_labels_str, pred_labels, average='macro', zero_division=0)\n",
    "    f1 = f1_score(test_labels_str, pred_labels, average='macro', zero_division=0)\n",
    "    cm = confusion_matrix(test_labels_str, pred_labels)\n",
    "    \n",
    "    # Count prediction distribution\n",
    "    pred_counts = {}\n",
    "    for label in pred_labels:\n",
    "        pred_counts[label] = pred_counts.get(label, 0) + 1\n",
    "    \n",
    "    # Class-specific metrics\n",
    "    unique_labels = sorted(set(test_labels_str))\n",
    "    print(\"\\nClass-specific metrics:\")\n",
    "    for label in unique_labels:\n",
    "        # Binary classification metrics for this class\n",
    "        true_binary = [1 if l == label else 0 for l in test_labels_str]\n",
    "        pred_binary = [1 if l == label else 0 for l in pred_labels]\n",
    "        \n",
    "        class_precision = precision_score(true_binary, pred_binary, zero_division=0)\n",
    "        class_recall = recall_score(true_binary, pred_binary, zero_division=0)\n",
    "        class_f1 = f1_score(true_binary, pred_binary, zero_division=0)\n",
    "        \n",
    "        print(f\"{label}: Precision={class_precision:.4f}, Recall={class_recall:.4f}, F1={class_f1:.4f}\")\n",
    "    \n",
    "    # Print out the results\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    if confidences:\n",
    "        print(f\"Average Confidence: {sum(confidences)/len(confidences):.6f}\")\n",
    "    \n",
    "    print(\"Prediction Distribution:\", pred_counts)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Show most common predicted tokens\n",
    "    print(\"\\nTop 5 most predicted tokens:\")\n",
    "    sorted_tokens = sorted(token_prediction_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    for token, count in sorted_tokens[:5]:\n",
    "        print(f\"'{token}': {count} times ({count/len(test_texts)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nTotal evaluation time: {total_time:.2f} seconds ({total_time/len(test_texts):.3f}s per tweet)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Language Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26.0/26.0 [00:00<00:00, 219kB/s]\n",
      "vocab.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.04M/1.04M [00:00<00:00, 30.5MB/s]\n",
      "merges.txt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 456k/456k [00:00<00:00, 3.09MB/s]\n",
      "tokenizer.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.36M/1.36M [00:00<00:00, 5.38MB/s]\n",
      "config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 718/718 [00:00<00:00, 4.89MB/s]\n",
      "model.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.52G/1.52G [00:52<00:00, 29.2MB/s]\n",
      "generation_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 124/124 [00:00<00:00, 676kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "# Sentiment Analysis Task\n",
      "\n",
      "## Instructions\n",
      "Analyze the sentiment of tweets and classify them as exactly one of:\n",
      "* POSITIVE - Expresses happiness, satisfaction, enthusiasm, or approval\n",
      "* NEGATIVE - Expresses dissatisfaction, disappointment, anger, or disapproval\n",
      "* NEUTRAL - Expresses neither strong positive nor negative sentiment\n",
      "\n",
      "## Examples\n",
      "\n",
      "Tweet: 'I love this new phone! The battery life is incredible.'\n",
      "Sentiment: POSITIVE\n",
      "\n",
      "Tweet: 'Just had the best meal of my life! The service was amazing too.'\n",
      "Sentiment: POSITIVE\n",
      "\n",
      "Tweet: 'This app is so user-friendly and helpful, totally worth the money!'\n",
      "Sentiment: POSITIVE\n",
      "\n",
      "Tweet: 'The movie was fantastic - great acting and a compelling story.'\n",
      "Sentiment: POSITIVE\n",
      "\n",
      "Tweet: 'I'm really impressed with the quality of this product, exceeded expectations.'\n",
      "Sentiment: POSITIVE\n",
      "\n",
      "Tweet: 'This restaurant was a total disappointment, horrible food and service.'\n",
      "Sentiment: NEGATIVE\n",
      "\n",
      "Tweet: 'The customer support was useless and rude, won't be using this service again.'\n",
      "Sentiment: NEGATIVE\n",
      "\n",
      "Tweet: 'Terrible experience with this product, broke after just one week.'\n",
      "Sentiment: NEGATIVE\n",
      "\n",
      "Tweet: 'The hotel room was dirty and uncomfortable, ruined our vacation.'\n",
      "Sentiment: NEGATIVE\n",
      "\n",
      "Tweet: 'This app is full of bugs and crashes constantly, waste of money.'\n",
      "Sentiment: NEGATIVE\n",
      "\n",
      "Tweet: 'The weather is partly cloudy today with a chance of rain later.'\n",
      "Sentiment: NEUTRAL\n",
      "\n",
      "Tweet: 'I received the package on time, standard delivery as expected.'\n",
      "Sentiment: NEUTRAL\n",
      "\n",
      "Tweet: 'This product works as advertised, nothing special but gets the job done.'\n",
      "Sentiment: NEUTRAL\n",
      "\n",
      "Tweet: 'The movie had some good parts and some boring parts, it was okay overall.'\n",
      "Sentiment: NEUTRAL\n",
      "\n",
      "Tweet: 'I'm neither impressed nor disappointed with the new features.'\n",
      "Sentiment: NEUTRAL\n",
      "\n",
      "## New Tweet to Classify\n",
      "\n",
      "Tweet: 'I love the new design of the app!'\n",
      "\n",
      "The sentiment of this tweet is \n",
      "\n",
      "Predicted Sentiment: positive\n",
      "Sentiment Scores: {'positive': 0.000824103073682636, 'negative': 0.0002800598740577698, 'neutral': 0.00020438720821402967}\n",
      "Confidence: 0.0005440431996248662\n",
      "Debug Info: {'positive': {'token_scores': [('POSITIVE', 37997, 1.587892802490387e-05), ('positive', 24561, 0.000285296089714393), ('Positive', 21604, 0.0002839649096131325), (' positive', 3967, 0.000824103073682636), (' POSITIVE', 28069, 0.00020861404482275248)], 'words': ['POSITIVE', 'positive', 'Positive', ' positive', ' POSITIVE']}, 'negative': {'token_scores': [('NEGATIVE', 45, 7.627724698977545e-05), ('negative', 31591, 0.00010744758765213192), ('Negative', 32863, 0.0002800598740577698), (' negative', 4633, 0.00021281623048707843), (' NEGATIVE', 399, 1.6920450434554368e-05)], 'words': ['NEGATIVE', 'negative', 'Negative', ' negative', ' NEGATIVE']}, 'neutral': {'token_scores': [('NEUTRAL', 12161, 1.1356684126440086e-06), ('neutral', 29797, 4.6139357436914e-05), ('Neutral', 8199, 0.00020438720821402967), (' neutral', 8500, 0.00010806006321217865), (' NEUTRAL', 10635, 1.8546854789747158e-06)], 'words': ['NEUTRAL', 'neutral', 'Neutral', ' neutral', ' NEUTRAL']}}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Set up the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load GPT2 model and tokenizer - using a larger model if available\n",
    "model_name_or_path = \"gpt2-medium\"  # Try using a larger model for better performance\n",
    "try:\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\n",
    "    lm_model = GPT2LMHeadModel.from_pretrained(model_name_or_path)\n",
    "except:\n",
    "    # Fall back to standard GPT2 if medium not available\n",
    "    model_name_or_path = \"gpt2\"\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\n",
    "    lm_model = GPT2LMHeadModel.from_pretrained(model_name_or_path)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "lm_model.to(device)\n",
    "lm_model.eval()\n",
    "\n",
    "def prompt_sentiment_few_shot(\n",
    "    tweet,\n",
    "    few_shot_examples = [\n",
    "        # Positive examples - more diverse, clearer patterns\n",
    "        (\"I love this new phone! The battery life is incredible.\", \"positive\"),\n",
    "        (\"Just had the best meal of my life! The service was amazing too.\", \"positive\"),\n",
    "        (\"This app is so user-friendly and helpful, totally worth the money!\", \"positive\"),\n",
    "        (\"The movie was fantastic - great acting and a compelling story.\", \"positive\"),\n",
    "        (\"I'm really impressed with the quality of this product, exceeded expectations.\", \"positive\"),\n",
    "        \n",
    "        # Negative examples - more diverse, clearer patterns\n",
    "        (\"This restaurant was a total disappointment, horrible food and service.\", \"negative\"),\n",
    "        (\"The customer support was useless and rude, won't be using this service again.\", \"negative\"),\n",
    "        (\"Terrible experience with this product, broke after just one week.\", \"negative\"),\n",
    "        (\"The hotel room was dirty and uncomfortable, ruined our vacation.\", \"negative\"),\n",
    "        (\"This app is full of bugs and crashes constantly, waste of money.\", \"negative\"),\n",
    "        \n",
    "        # Neutral examples - more diverse, clearer patterns\n",
    "        (\"The weather is partly cloudy today with a chance of rain later.\", \"neutral\"),\n",
    "        (\"I received the package on time, standard delivery as expected.\", \"neutral\"),\n",
    "        (\"This product works as advertised, nothing special but gets the job done.\", \"neutral\"),\n",
    "        (\"The movie had some good parts and some boring parts, it was okay overall.\", \"neutral\"),\n",
    "        (\"I'm neither impressed nor disappointed with the new features.\", \"neutral\")\n",
    "    ],\n",
    "    # Improved template with clearer instructions and formatting\n",
    "    template=\n",
    "    \n",
    "\"\"\"\n",
    "# Sentiment Analysis Task\n",
    "\n",
    "## Instructions\n",
    "Analyze the sentiment of tweets and classify them as exactly one of:\n",
    "* POSITIVE - Expresses happiness, satisfaction, enthusiasm, or approval\n",
    "* NEGATIVE - Expresses dissatisfaction, disappointment, anger, or disapproval\n",
    "* NEUTRAL - Expresses neither strong positive nor negative sentiment\n",
    "\n",
    "## Examples\n",
    "\n",
    "{examples}\n",
    "\n",
    "## New Tweet to Classify\n",
    "\n",
    "Tweet: '{tweet}'\n",
    "\n",
    "The sentiment of this tweet is \n",
    "\"\"\",\n",
    "    \n",
    "    # Expanded verbalizer with more options and exact class names\n",
    "    verbalizer={\n",
    "        \"positive\": [\"POSITIVE\", \"positive\", \"Positive\", \" positive\", \" POSITIVE\"],\n",
    "        \"negative\": [\"NEGATIVE\", \"negative\", \"Negative\", \" negative\", \" NEGATIVE\"],\n",
    "        \"neutral\": [\"NEUTRAL\", \"neutral\", \"Neutral\", \" neutral\", \" NEUTRAL\"]\n",
    "    },\n",
    "    max_length=512\n",
    "):\n",
    "    \"\"\"\n",
    "    Enhanced function that generates a prompt from the tweet and uses GPT2 to compute\n",
    "    sentiment probabilities based on next token prediction.\n",
    "    \"\"\"\n",
    "    # Format examples with clear separation and consistent structure\n",
    "    examples_str = \"\\n\\n\".join([f\"Tweet: '{ex_tweet}'\\nSentiment: {ex_sent.upper()}\" for ex_tweet, ex_sent in few_shot_examples])\n",
    "    prompt_text = template.format(examples=examples_str, tweet=tweet)\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
    "    inputs = {key: tensor.to(device) for key, tensor in inputs.items()}\n",
    "    \n",
    "    # Get logits for next token prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = lm_model(**inputs)\n",
    "    \n",
    "    next_token_logits = outputs.logits[0, -1, :]  # shape: (vocab_size,)\n",
    "    \n",
    "    # Apply softmax to get probabilities\n",
    "    next_token_probs = torch.nn.functional.softmax(next_token_logits, dim=0)\n",
    "    \n",
    "    # Score each sentiment class\n",
    "    sentiment_scores = {}\n",
    "    debug_info = {}\n",
    "    \n",
    "    for sentiment, words in verbalizer.items():\n",
    "        word_scores = []\n",
    "        token_scores = []\n",
    "        \n",
    "        for word in words:\n",
    "            # Get token IDs for the word with and without space prefix\n",
    "            # Try both with and without space prefix\n",
    "            word_tokens = tokenizer.encode(word, add_special_tokens=False)\n",
    "            \n",
    "            if len(word_tokens) > 0:\n",
    "                # Get score for the first token\n",
    "                score = next_token_probs[word_tokens[0]].item()\n",
    "                token_scores.append((word, word_tokens[0], score))\n",
    "                word_scores.append(score)\n",
    "        \n",
    "        # Store debugging info\n",
    "        debug_info[sentiment] = {\n",
    "            \"token_scores\": token_scores,\n",
    "            \"words\": words\n",
    "        }\n",
    "        \n",
    "        # Use the maximum score for the sentiment class\n",
    "        sentiment_scores[sentiment] = max(word_scores) if word_scores else float('-inf')\n",
    "    \n",
    "    # Determine predicted sentiment\n",
    "    predicted_sentiment = max(sentiment_scores, key=sentiment_scores.get)\n",
    "    \n",
    "    # Calculate confidence as the difference between top score and second highest score\n",
    "    scores_list = list(sentiment_scores.values())\n",
    "    scores_list.sort(reverse=True)\n",
    "    confidence = scores_list[0] - scores_list[1] if len(scores_list) > 1 else scores_list[0]\n",
    "    \n",
    "    return predicted_sentiment, sentiment_scores, prompt_text, debug_info, confidence\n",
    "\n",
    "# Function to evaluate on a test set with improved diagnostics\n",
    "def evaluate_model(test_file_path, sample_size=None):\n",
    "    \"\"\"\n",
    "    Evaluates the sentiment model on a test file with improved diagnostics.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "    import random\n",
    "    \n",
    "    # Read test data\n",
    "    test_data = []\n",
    "    with open(test_file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) == 2:\n",
    "                    sentiment, tweet = parts\n",
    "                    test_data.append((tweet, sentiment))\n",
    "    \n",
    "    if not test_data:\n",
    "        print(f\"Warning: No valid data found in {test_file_path}\")\n",
    "        return\n",
    "    \n",
    "    # Sample a subset if specified\n",
    "    if sample_size and sample_size < len(test_data):\n",
    "        test_data = random.sample(test_data, sample_size)\n",
    "        print(f\"Sampling {sample_size} examples from {test_file_path}\")\n",
    "    \n",
    "    # Process each tweet\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    confidences = []\n",
    "    \n",
    "    # Track examples by correctness\n",
    "    correct_examples = []\n",
    "    incorrect_examples = []\n",
    "    \n",
    "    for tweet, true_sentiment in test_data:\n",
    "        predicted_sentiment, scores, _, debug, confidence = prompt_sentiment_few_shot(tweet)\n",
    "        predictions.append(predicted_sentiment)\n",
    "        true_labels.append(true_sentiment)\n",
    "        confidences.append(confidence)\n",
    "        \n",
    "        # Save examples for analysis\n",
    "        example_data = {\n",
    "            \"tweet\": tweet,\n",
    "            \"true\": true_sentiment,\n",
    "            \"predicted\": predicted_sentiment,\n",
    "            \"scores\": scores,\n",
    "            \"confidence\": confidence\n",
    "        }\n",
    "        \n",
    "        if predicted_sentiment == true_sentiment:\n",
    "            correct_examples.append(example_data)\n",
    "        else:\n",
    "            incorrect_examples.append(example_data)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = sum(p == t for p, t in zip(predictions, true_labels)) / len(predictions)\n",
    "    \n",
    "    # Convert string labels to integers for sklearn metrics\n",
    "    label_set = sorted(set(true_labels + predictions))\n",
    "    label_map = {label: i for i, label in enumerate(label_set)}\n",
    "    \n",
    "    y_true = np.array([label_map[label] for label in true_labels])\n",
    "    y_pred = np.array([label_map[label] for label in predictions])\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred, labels=range(len(label_set)))\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Average Confidence: {sum(confidences) / len(confidences):.6f}\")\n",
    "    print(f\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(f\"Label mapping: {label_map}\")\n",
    "    \n",
    "    # Count predictions per class\n",
    "    pred_counts = {}\n",
    "    for p in predictions:\n",
    "        pred_counts[p] = pred_counts.get(p, 0) + 1\n",
    "    print(f\"Prediction distribution: {pred_counts}\")\n",
    "    \n",
    "    # Display some example predictions\n",
    "    print(\"\\n=== EXAMPLE PREDICTIONS ===\")\n",
    "    \n",
    "    # Show some correct predictions\n",
    "    if correct_examples:\n",
    "        print(\"\\nCORRECT PREDICTIONS:\")\n",
    "        for i, example in enumerate(correct_examples[:3]):\n",
    "            print(f\"{i+1}. Tweet: '{example['tweet']}'\")\n",
    "            print(f\"   True: {example['true']}, Predicted: {example['predicted']}\")\n",
    "            print(f\"   Confidence: {example['confidence']:.6f}\")\n",
    "            print(f\"   Scores: {example['scores']}\")\n",
    "    \n",
    "    # Show some incorrect predictions\n",
    "    if incorrect_examples:\n",
    "        print(\"\\nINCORRECT PREDICTIONS:\")\n",
    "        for i, example in enumerate(incorrect_examples[:3]):\n",
    "            print(f\"{i+1}. Tweet: '{example['tweet']}'\")\n",
    "            print(f\"   True: {example['true']}, Predicted: {example['predicted']}\")\n",
    "            print(f\"   Confidence: {example['confidence']:.6f}\")\n",
    "            print(f\"   Scores: {example['scores']}\")\n",
    "    \n",
    "    return accuracy, precision, recall, f1, conf_matrix, pred_counts\n",
    "\n",
    "# Example usage with a single tweet\n",
    "tweet_example = \"I love the new design of the app!\"\n",
    "predicted_sentiment, scores, prompt_text, debug_info, confidence = prompt_sentiment_few_shot(tweet_example)\n",
    "\n",
    "print(\"Prompt:\")\n",
    "print(prompt_text)\n",
    "print(\"\\nPredicted Sentiment:\", predicted_sentiment)\n",
    "print(\"Sentiment Scores:\", scores)\n",
    "print(\"Confidence:\", confidence)\n",
    "print(\"Debug Info:\", debug_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set: twitter-test1.txt\n",
      "Processed 20/3531 tweets...\n",
      "Processed 40/3531 tweets...\n",
      "Processed 60/3531 tweets...\n",
      "Processed 80/3531 tweets...\n",
      "Processed 100/3531 tweets...\n",
      "Processed 120/3531 tweets...\n",
      "Processed 140/3531 tweets...\n",
      "Processed 160/3531 tweets...\n",
      "Processed 180/3531 tweets...\n",
      "Processed 200/3531 tweets...\n",
      "Processed 220/3531 tweets...\n",
      "Processed 240/3531 tweets...\n",
      "Processed 260/3531 tweets...\n",
      "Processed 280/3531 tweets...\n",
      "Processed 300/3531 tweets...\n",
      "Processed 320/3531 tweets...\n",
      "Processed 340/3531 tweets...\n",
      "Processed 360/3531 tweets...\n",
      "Processed 380/3531 tweets...\n",
      "Processed 400/3531 tweets...\n",
      "Processed 420/3531 tweets...\n",
      "Processed 440/3531 tweets...\n",
      "Processed 460/3531 tweets...\n",
      "Processed 480/3531 tweets...\n",
      "Processed 500/3531 tweets...\n",
      "Processed 520/3531 tweets...\n",
      "Processed 540/3531 tweets...\n",
      "Processed 560/3531 tweets...\n",
      "Processed 580/3531 tweets...\n",
      "Processed 600/3531 tweets...\n",
      "Processed 620/3531 tweets...\n",
      "Processed 640/3531 tweets...\n",
      "Processed 660/3531 tweets...\n",
      "Processed 680/3531 tweets...\n",
      "Processed 700/3531 tweets...\n",
      "Processed 720/3531 tweets...\n",
      "Processed 740/3531 tweets...\n",
      "Processed 760/3531 tweets...\n",
      "Processed 780/3531 tweets...\n",
      "Processed 800/3531 tweets...\n",
      "Processed 820/3531 tweets...\n",
      "Processed 840/3531 tweets...\n",
      "Processed 860/3531 tweets...\n",
      "Processed 880/3531 tweets...\n",
      "Processed 900/3531 tweets...\n",
      "Processed 920/3531 tweets...\n",
      "Processed 940/3531 tweets...\n",
      "Processed 960/3531 tweets...\n",
      "Processed 980/3531 tweets...\n",
      "Processed 1000/3531 tweets...\n",
      "Processed 1020/3531 tweets...\n",
      "Processed 1040/3531 tweets...\n",
      "Processed 1060/3531 tweets...\n",
      "Processed 1080/3531 tweets...\n",
      "Processed 1100/3531 tweets...\n",
      "Processed 1120/3531 tweets...\n",
      "Processed 1140/3531 tweets...\n",
      "Processed 1160/3531 tweets...\n",
      "Processed 1180/3531 tweets...\n",
      "Processed 1200/3531 tweets...\n",
      "Processed 1220/3531 tweets...\n",
      "Processed 1240/3531 tweets...\n",
      "Processed 1260/3531 tweets...\n",
      "Processed 1280/3531 tweets...\n",
      "Processed 1300/3531 tweets...\n",
      "Processed 1320/3531 tweets...\n",
      "Processed 1340/3531 tweets...\n",
      "Processed 1360/3531 tweets...\n",
      "Processed 1380/3531 tweets...\n",
      "Processed 1400/3531 tweets...\n",
      "Processed 1420/3531 tweets...\n",
      "Processed 1440/3531 tweets...\n",
      "Processed 1460/3531 tweets...\n",
      "Processed 1480/3531 tweets...\n",
      "Processed 1500/3531 tweets...\n",
      "Processed 1520/3531 tweets...\n",
      "Processed 1540/3531 tweets...\n",
      "Processed 1560/3531 tweets...\n",
      "Processed 1580/3531 tweets...\n",
      "Processed 1600/3531 tweets...\n",
      "Processed 1620/3531 tweets...\n",
      "Processed 1640/3531 tweets...\n",
      "Processed 1660/3531 tweets...\n",
      "Processed 1680/3531 tweets...\n",
      "Processed 1700/3531 tweets...\n",
      "Processed 1720/3531 tweets...\n",
      "Processed 1740/3531 tweets...\n",
      "Processed 1760/3531 tweets...\n",
      "Processed 1780/3531 tweets...\n",
      "Processed 1800/3531 tweets...\n",
      "Processed 1820/3531 tweets...\n",
      "Processed 1840/3531 tweets...\n",
      "Processed 1860/3531 tweets...\n",
      "Processed 1880/3531 tweets...\n",
      "Processed 1900/3531 tweets...\n",
      "Processed 1920/3531 tweets...\n",
      "Processed 1940/3531 tweets...\n",
      "Processed 1960/3531 tweets...\n",
      "Processed 1980/3531 tweets...\n",
      "Processed 2000/3531 tweets...\n",
      "Processed 2020/3531 tweets...\n",
      "Processed 2040/3531 tweets...\n",
      "Processed 2060/3531 tweets...\n",
      "Processed 2080/3531 tweets...\n",
      "Processed 2100/3531 tweets...\n",
      "Processed 2120/3531 tweets...\n",
      "Processed 2140/3531 tweets...\n",
      "Processed 2160/3531 tweets...\n",
      "Processed 2180/3531 tweets...\n",
      "Processed 2200/3531 tweets...\n",
      "Processed 2220/3531 tweets...\n",
      "Processed 2240/3531 tweets...\n",
      "Processed 2260/3531 tweets...\n",
      "Processed 2280/3531 tweets...\n",
      "Processed 2300/3531 tweets...\n",
      "Processed 2320/3531 tweets...\n",
      "Processed 2340/3531 tweets...\n",
      "Processed 2360/3531 tweets...\n",
      "Processed 2380/3531 tweets...\n",
      "Processed 2400/3531 tweets...\n",
      "Processed 2420/3531 tweets...\n",
      "Processed 2440/3531 tweets...\n",
      "Processed 2460/3531 tweets...\n",
      "Processed 2480/3531 tweets...\n",
      "Processed 2500/3531 tweets...\n",
      "Processed 2520/3531 tweets...\n",
      "Processed 2540/3531 tweets...\n",
      "Processed 2560/3531 tweets...\n",
      "Processed 2580/3531 tweets...\n",
      "Processed 2600/3531 tweets...\n",
      "Processed 2620/3531 tweets...\n",
      "Processed 2640/3531 tweets...\n",
      "Processed 2660/3531 tweets...\n",
      "Processed 2680/3531 tweets...\n",
      "Processed 2700/3531 tweets...\n",
      "Processed 2720/3531 tweets...\n",
      "Processed 2740/3531 tweets...\n",
      "Processed 2760/3531 tweets...\n",
      "Processed 2780/3531 tweets...\n",
      "Processed 2800/3531 tweets...\n",
      "Processed 2820/3531 tweets...\n",
      "Processed 2840/3531 tweets...\n",
      "Processed 2860/3531 tweets...\n",
      "Processed 2880/3531 tweets...\n",
      "Processed 2900/3531 tweets...\n",
      "Processed 2920/3531 tweets...\n",
      "Processed 2940/3531 tweets...\n",
      "Processed 2960/3531 tweets...\n",
      "Processed 2980/3531 tweets...\n",
      "Processed 3000/3531 tweets...\n",
      "Processed 3020/3531 tweets...\n",
      "Processed 3040/3531 tweets...\n",
      "Processed 3060/3531 tweets...\n",
      "Processed 3080/3531 tweets...\n",
      "Processed 3100/3531 tweets...\n",
      "Processed 3120/3531 tweets...\n",
      "Processed 3140/3531 tweets...\n",
      "Processed 3160/3531 tweets...\n",
      "Processed 3180/3531 tweets...\n",
      "Processed 3200/3531 tweets...\n",
      "Processed 3220/3531 tweets...\n",
      "Processed 3240/3531 tweets...\n",
      "Processed 3260/3531 tweets...\n",
      "Processed 3280/3531 tweets...\n",
      "Processed 3300/3531 tweets...\n",
      "Processed 3320/3531 tweets...\n",
      "Processed 3340/3531 tweets...\n",
      "Processed 3360/3531 tweets...\n",
      "Processed 3380/3531 tweets...\n",
      "Processed 3400/3531 tweets...\n",
      "Processed 3420/3531 tweets...\n",
      "Processed 3440/3531 tweets...\n",
      "Processed 3460/3531 tweets...\n",
      "Processed 3480/3531 tweets...\n",
      "Processed 3500/3531 tweets...\n",
      "Processed 3520/3531 tweets...\n",
      "\n",
      "Results for twitter-test1.txt:\n",
      "Test Accuracy: 0.3662\n",
      "Precision: 0.3130\n",
      "Recall: 0.3389\n",
      "F1 Score: 0.2502\n",
      "Average Confidence: 0.004350\n",
      "Average Sentiment Scores: positive=0.005693, negative=0.002378, neutral=0.001381\n",
      "Prediction Distribution: {'positive': 2647, 'negative': 856, 'neutral': 28}\n",
      "Confusion Matrix:\n",
      "[[ 123    9  425]\n",
      " [ 432   10 1062]\n",
      " [ 301    9 1160]]\n",
      "Label Mapping: ['negative', 'neutral', 'positive']\n",
      "\n",
      "Per-Class Metrics:\n",
      "negative: Precision=0.1437, Recall=0.1437, F1=0.1741\n",
      "neutral: Precision=0.3571, Recall=0.3571, F1=0.0131\n",
      "positive: Precision=0.4382, Recall=0.4382, F1=0.5635\n",
      "\n",
      "Error Analysis:\n",
      "\n",
      "Example Misclassifications:\n",
      "Tweet: 'Candids: Heading to the Chateau Marmont in West Hollywood (October 10th) http://t.co/87hjAFmB'\n",
      "True: neutral, Predicted: positive\n",
      "Tweet: '@Dont__KAY_me omg same I was reading it in school after PSSAS and I just sat there crying'\n",
      "True: negative, Predicted: positive\n",
      "Tweet: 'Watching MTV  Hits! The Wanted Chasing the sun!'\n",
      "True: neutral, Predicted: positive\n",
      "Tweet: '\"Bing one-ups knowledge graph, hires Encyclopaedia Britannica to supply results:   It may have retired from the cut-throat world of pr...\"'\n",
      "True: neutral, Predicted: positive\n",
      "Tweet: '\"On Thursday, concealed-carry gun license holders will be given a new right in the state of Oklahoma: the ability... http://t.co/oSgGHKi1\"'\n",
      "True: neutral, Predicted: positive\n",
      "\n",
      "Execution Time: 310.33 seconds (0.09 seconds per tweet)\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluating on test set: twitter-test2.txt\n",
      "Processed 20/1853 tweets...\n",
      "Processed 40/1853 tweets...\n",
      "Processed 60/1853 tweets...\n",
      "Processed 80/1853 tweets...\n",
      "Processed 100/1853 tweets...\n",
      "Processed 120/1853 tweets...\n",
      "Processed 140/1853 tweets...\n",
      "Processed 160/1853 tweets...\n",
      "Processed 180/1853 tweets...\n",
      "Processed 200/1853 tweets...\n",
      "Processed 220/1853 tweets...\n",
      "Processed 240/1853 tweets...\n",
      "Processed 260/1853 tweets...\n",
      "Processed 280/1853 tweets...\n",
      "Processed 300/1853 tweets...\n",
      "Processed 320/1853 tweets...\n",
      "Processed 340/1853 tweets...\n",
      "Processed 360/1853 tweets...\n",
      "Processed 380/1853 tweets...\n",
      "Processed 400/1853 tweets...\n",
      "Processed 420/1853 tweets...\n",
      "Processed 440/1853 tweets...\n",
      "Processed 460/1853 tweets...\n",
      "Processed 480/1853 tweets...\n",
      "Processed 500/1853 tweets...\n",
      "Processed 520/1853 tweets...\n",
      "Processed 540/1853 tweets...\n",
      "Processed 560/1853 tweets...\n",
      "Processed 580/1853 tweets...\n",
      "Processed 600/1853 tweets...\n",
      "Processed 620/1853 tweets...\n",
      "Processed 640/1853 tweets...\n",
      "Processed 660/1853 tweets...\n",
      "Processed 680/1853 tweets...\n",
      "Processed 700/1853 tweets...\n",
      "Processed 720/1853 tweets...\n",
      "Processed 740/1853 tweets...\n",
      "Processed 760/1853 tweets...\n",
      "Processed 780/1853 tweets...\n",
      "Processed 800/1853 tweets...\n",
      "Processed 820/1853 tweets...\n",
      "Processed 840/1853 tweets...\n",
      "Processed 860/1853 tweets...\n",
      "Processed 880/1853 tweets...\n",
      "Processed 900/1853 tweets...\n",
      "Processed 920/1853 tweets...\n",
      "Processed 940/1853 tweets...\n",
      "Processed 960/1853 tweets...\n",
      "Processed 980/1853 tweets...\n",
      "Processed 1000/1853 tweets...\n",
      "Processed 1020/1853 tweets...\n",
      "Processed 1040/1853 tweets...\n",
      "Processed 1060/1853 tweets...\n",
      "Processed 1080/1853 tweets...\n",
      "Processed 1100/1853 tweets...\n",
      "Processed 1120/1853 tweets...\n",
      "Processed 1140/1853 tweets...\n",
      "Processed 1160/1853 tweets...\n",
      "Processed 1180/1853 tweets...\n",
      "Processed 1200/1853 tweets...\n",
      "Processed 1220/1853 tweets...\n",
      "Processed 1240/1853 tweets...\n",
      "Processed 1260/1853 tweets...\n",
      "Processed 1280/1853 tweets...\n",
      "Processed 1300/1853 tweets...\n",
      "Processed 1320/1853 tweets...\n",
      "Processed 1340/1853 tweets...\n",
      "Processed 1360/1853 tweets...\n",
      "Processed 1380/1853 tweets...\n",
      "Processed 1400/1853 tweets...\n",
      "Processed 1420/1853 tweets...\n",
      "Processed 1440/1853 tweets...\n",
      "Processed 1460/1853 tweets...\n",
      "Processed 1480/1853 tweets...\n",
      "Processed 1500/1853 tweets...\n",
      "Processed 1520/1853 tweets...\n",
      "Processed 1540/1853 tweets...\n",
      "Processed 1560/1853 tweets...\n",
      "Processed 1580/1853 tweets...\n",
      "Processed 1600/1853 tweets...\n",
      "Processed 1620/1853 tweets...\n",
      "Processed 1640/1853 tweets...\n",
      "Processed 1660/1853 tweets...\n",
      "Processed 1680/1853 tweets...\n",
      "Processed 1700/1853 tweets...\n",
      "Processed 1720/1853 tweets...\n",
      "Processed 1740/1853 tweets...\n",
      "Processed 1760/1853 tweets...\n",
      "Processed 1780/1853 tweets...\n",
      "Processed 1800/1853 tweets...\n",
      "Processed 1820/1853 tweets...\n",
      "Processed 1840/1853 tweets...\n",
      "\n",
      "Results for twitter-test2.txt:\n",
      "Test Accuracy: 0.4539\n",
      "Precision: 0.3161\n",
      "Recall: 0.3469\n",
      "F1 Score: 0.2758\n",
      "Average Confidence: 0.004124\n",
      "Average Sentiment Scores: positive=0.005425, negative=0.002117, neutral=0.001396\n",
      "Prediction Distribution: {'positive': 1414, 'negative': 414, 'neutral': 25}\n",
      "Confusion Matrix:\n",
      "[[ 46   6 150]\n",
      " [186   7 476]\n",
      " [182  12 788]]\n",
      "Label Mapping: ['negative', 'neutral', 'positive']\n",
      "\n",
      "Per-Class Metrics:\n",
      "negative: Precision=0.1111, Recall=0.1111, F1=0.1494\n",
      "neutral: Precision=0.2800, Recall=0.2800, F1=0.0202\n",
      "positive: Precision=0.5573, Recall=0.5573, F1=0.6578\n",
      "\n",
      "Error Analysis:\n",
      "\n",
      "Example Misclassifications:\n",
      "Tweet: 'Anybody going to that 4th of July pool party in Knollwood?'\n",
      "True: neutral, Predicted: positive\n",
      "Tweet: 'The Kee to Bala just got Drizzy: Intimate concert in one of greatest venues with rapper @Drake this Saturday pm in #Muskoka's @TheKEEtoBala'\n",
      "True: neutral, Predicted: negative\n",
      "Tweet: 'Going to see Richard Dawkins &amp; Mehdi Hasan debate at the Oxford union tomorrow.'\n",
      "True: neutral, Predicted: positive\n",
      "Tweet: 'Watching Crossfire Hurricane for the 5th time @MickJagger'\n",
      "True: neutral, Predicted: positive\n",
      "Tweet: '\"i want it to be Tuesday to i can watch Styled To Rock. actually, while i'm watching it, TA will be playing. that's awfully depressing.\"'\n",
      "True: negative, Predicted: positive\n",
      "\n",
      "Execution Time: 162.76 seconds (0.09 seconds per tweet)\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluating on test set: twitter-test3.txt\n",
      "Processed 20/2379 tweets...\n",
      "Processed 40/2379 tweets...\n",
      "Processed 60/2379 tweets...\n",
      "Processed 80/2379 tweets...\n",
      "Processed 100/2379 tweets...\n",
      "Processed 120/2379 tweets...\n",
      "Processed 140/2379 tweets...\n",
      "Processed 160/2379 tweets...\n",
      "Processed 180/2379 tweets...\n",
      "Processed 200/2379 tweets...\n",
      "Processed 220/2379 tweets...\n",
      "Processed 240/2379 tweets...\n",
      "Processed 260/2379 tweets...\n",
      "Processed 280/2379 tweets...\n",
      "Processed 300/2379 tweets...\n",
      "Processed 320/2379 tweets...\n",
      "Processed 340/2379 tweets...\n",
      "Processed 360/2379 tweets...\n",
      "Processed 380/2379 tweets...\n",
      "Processed 400/2379 tweets...\n",
      "Processed 420/2379 tweets...\n",
      "Processed 440/2379 tweets...\n",
      "Processed 460/2379 tweets...\n",
      "Processed 480/2379 tweets...\n",
      "Processed 500/2379 tweets...\n",
      "Processed 520/2379 tweets...\n",
      "Processed 540/2379 tweets...\n",
      "Processed 560/2379 tweets...\n",
      "Processed 580/2379 tweets...\n",
      "Processed 600/2379 tweets...\n",
      "Processed 620/2379 tweets...\n",
      "Processed 640/2379 tweets...\n",
      "Processed 660/2379 tweets...\n",
      "Processed 680/2379 tweets...\n",
      "Processed 700/2379 tweets...\n",
      "Processed 720/2379 tweets...\n",
      "Processed 740/2379 tweets...\n",
      "Processed 760/2379 tweets...\n",
      "Processed 780/2379 tweets...\n",
      "Processed 800/2379 tweets...\n",
      "Processed 820/2379 tweets...\n",
      "Processed 840/2379 tweets...\n",
      "Processed 860/2379 tweets...\n",
      "Processed 880/2379 tweets...\n",
      "Processed 900/2379 tweets...\n",
      "Processed 920/2379 tweets...\n",
      "Processed 940/2379 tweets...\n",
      "Processed 960/2379 tweets...\n",
      "Processed 980/2379 tweets...\n",
      "Processed 1000/2379 tweets...\n",
      "Processed 1020/2379 tweets...\n",
      "Processed 1040/2379 tweets...\n",
      "Processed 1060/2379 tweets...\n",
      "Processed 1080/2379 tweets...\n",
      "Processed 1100/2379 tweets...\n",
      "Processed 1120/2379 tweets...\n",
      "Processed 1140/2379 tweets...\n",
      "Processed 1160/2379 tweets...\n",
      "Processed 1180/2379 tweets...\n",
      "Processed 1200/2379 tweets...\n",
      "Processed 1220/2379 tweets...\n",
      "Processed 1240/2379 tweets...\n",
      "Processed 1260/2379 tweets...\n",
      "Processed 1280/2379 tweets...\n",
      "Processed 1300/2379 tweets...\n",
      "Processed 1320/2379 tweets...\n",
      "Processed 1340/2379 tweets...\n",
      "Processed 1360/2379 tweets...\n",
      "Processed 1380/2379 tweets...\n",
      "Processed 1400/2379 tweets...\n",
      "Processed 1420/2379 tweets...\n",
      "Processed 1440/2379 tweets...\n",
      "Processed 1460/2379 tweets...\n",
      "Processed 1480/2379 tweets...\n",
      "Processed 1500/2379 tweets...\n",
      "Processed 1520/2379 tweets...\n",
      "Processed 1540/2379 tweets...\n",
      "Processed 1560/2379 tweets...\n",
      "Processed 1580/2379 tweets...\n",
      "Processed 1600/2379 tweets...\n",
      "Processed 1620/2379 tweets...\n",
      "Processed 1640/2379 tweets...\n",
      "Processed 1660/2379 tweets...\n",
      "Processed 1680/2379 tweets...\n",
      "Processed 1700/2379 tweets...\n",
      "Processed 1720/2379 tweets...\n",
      "Processed 1740/2379 tweets...\n",
      "Processed 1760/2379 tweets...\n",
      "Processed 1780/2379 tweets...\n",
      "Processed 1800/2379 tweets...\n",
      "Processed 1820/2379 tweets...\n",
      "Processed 1840/2379 tweets...\n",
      "Processed 1860/2379 tweets...\n",
      "Processed 1880/2379 tweets...\n",
      "Processed 1900/2379 tweets...\n",
      "Processed 1920/2379 tweets...\n",
      "Processed 1940/2379 tweets...\n",
      "Processed 1960/2379 tweets...\n",
      "Processed 1980/2379 tweets...\n",
      "Processed 2000/2379 tweets...\n",
      "Processed 2020/2379 tweets...\n",
      "Processed 2040/2379 tweets...\n",
      "Processed 2060/2379 tweets...\n",
      "Processed 2080/2379 tweets...\n",
      "Processed 2100/2379 tweets...\n",
      "Processed 2120/2379 tweets...\n",
      "Processed 2140/2379 tweets...\n",
      "Processed 2160/2379 tweets...\n",
      "Processed 2180/2379 tweets...\n",
      "Processed 2200/2379 tweets...\n",
      "Processed 2220/2379 tweets...\n",
      "Processed 2240/2379 tweets...\n",
      "Processed 2260/2379 tweets...\n",
      "Processed 2280/2379 tweets...\n",
      "Processed 2300/2379 tweets...\n",
      "Processed 2320/2379 tweets...\n",
      "Processed 2340/2379 tweets...\n",
      "Processed 2360/2379 tweets...\n",
      "\n",
      "Results for twitter-test3.txt:\n",
      "Test Accuracy: 0.3665\n",
      "Precision: 0.3641\n",
      "Recall: 0.3245\n",
      "F1 Score: 0.2466\n",
      "Average Confidence: 0.004331\n",
      "Average Sentiment Scores: positive=0.005465, negative=0.002490, neutral=0.001253\n",
      "Prediction Distribution: {'positive': 1731, 'negative': 625, 'neutral': 23}\n",
      "Confusion Matrix:\n",
      "[[ 72   6 285]\n",
      " [313  12 658]\n",
      " [240   5 788]]\n",
      "Label Mapping: ['negative', 'neutral', 'positive']\n",
      "\n",
      "Per-Class Metrics:\n",
      "negative: Precision=0.1152, Recall=0.1152, F1=0.1457\n",
      "neutral: Precision=0.5217, Recall=0.5217, F1=0.0239\n",
      "positive: Precision=0.4552, Recall=0.4552, F1=0.5702\n",
      "\n",
      "Error Analysis:\n",
      "\n",
      "Example Misclassifications:\n",
      "Tweet: '@MoodieNathan Yeah dont think 8 or 9 like some.. Is a risk but Welbeck must be amongst the goals! As for Delph got a knock rested for Sunday'\n",
      "True: neutral, Predicted: positive\n",
      "Tweet: 'Very Unfair: West Indies players to fly back on their own expense after the 4th ODI in Dharamsala (TimesNow) #INDvsWI #WestIndies'\n",
      "True: negative, Predicted: positive\n",
      "Tweet: '\"@TerryFoster971 @MikeValenti971 Ben Affleck is in EL cuz the students wanted him to be the \"\"\"\"surprise\"\"\"\" guest at the Izzone campout tomorrow!\"'\n",
      "True: positive, Predicted: negative\n",
      "Tweet: 'Subscribe to Nash's channel to see when his new youtube video with Skylynn is uploaded tomorrow! @Nashgrier http://t.co/AAjfz26RCR'\n",
      "True: neutral, Predicted: positive\n",
      "Tweet: 'A rep from UCLA will be at the Pilot Center tomorrow during lunch. See you there!'\n",
      "True: neutral, Predicted: positive\n",
      "\n",
      "Execution Time: 207.84 seconds (0.09 seconds per tweet)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop for testing the enhanced sentiment analysis model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Loop over each test set and evaluate\n",
    "for test_set in testsets:\n",
    "    print(f\"\\nEvaluating on test set: {test_set}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get the raw tweet texts and true sentiment labels (as strings)\n",
    "    test_texts = tweets[test_set]\n",
    "    test_labels_str = tweetgts[test_set]  # e.g., [\"positive\", \"negative\", \"neutral\", ...]\n",
    "    \n",
    "    # Lists to store predictions and confidence scores\n",
    "    pred_labels = []\n",
    "    confidence_scores = []\n",
    "    sentiment_score_values = {\n",
    "        \"positive\": [],\n",
    "        \"negative\": [],\n",
    "        \"neutral\": []\n",
    "    }\n",
    "    \n",
    "    # Process each tweet using the enhanced few-shot prompting function\n",
    "    for i, tweet in enumerate(test_texts):\n",
    "        # Use the enhanced function that returns additional information\n",
    "        predicted_sentiment, sentiment_scores, _, _, confidence = prompt_sentiment_few_shot(tweet)\n",
    "        pred_labels.append(predicted_sentiment)\n",
    "        confidence_scores.append(confidence)\n",
    "        \n",
    "        # Store sentiment scores for analysis\n",
    "        for sentiment, score in sentiment_scores.items():\n",
    "            sentiment_score_values[sentiment].append(score)\n",
    "        \n",
    "        # Print progress update every 20 tweets\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(test_texts)} tweets...\")\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    test_accuracy = accuracy_score(test_labels_str, pred_labels)\n",
    "    precision = precision_score(test_labels_str, pred_labels, average='macro', zero_division=0)\n",
    "    recall = recall_score(test_labels_str, pred_labels, average='macro', zero_division=0)\n",
    "    f1 = f1_score(test_labels_str, pred_labels, average='macro', zero_division=0)\n",
    "    cm = confusion_matrix(test_labels_str, pred_labels)\n",
    "    \n",
    "    # Calculate average confidence and sentiment scores\n",
    "    avg_confidence = sum(confidence_scores) / len(confidence_scores)\n",
    "    avg_positive_score = sum(sentiment_score_values[\"positive\"]) / len(sentiment_score_values[\"positive\"])\n",
    "    avg_negative_score = sum(sentiment_score_values[\"negative\"]) / len(sentiment_score_values[\"negative\"])\n",
    "    avg_neutral_score = sum(sentiment_score_values[\"neutral\"]) / len(sentiment_score_values[\"neutral\"])\n",
    "    \n",
    "    # Count predictions per class\n",
    "    pred_counts = {}\n",
    "    for label in pred_labels:\n",
    "        pred_counts[label] = pred_counts.get(label, 0) + 1\n",
    "    \n",
    "    # Calculate class-specific metrics\n",
    "    unique_labels = sorted(set(test_labels_str) | set(pred_labels))\n",
    "    class_metrics = {}\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        # Create binary arrays for this class\n",
    "        true_binary = [1 if l == label else 0 for l in test_labels_str]\n",
    "        pred_binary = [1 if l == label else 0 for l in pred_labels]\n",
    "        \n",
    "        # Calculate precision and recall for this class\n",
    "        class_precision = precision_score(true_binary, pred_binary, zero_division=0)\n",
    "        class_recall = precision_score(true_binary, pred_binary, zero_division=0)\n",
    "        class_f1 = f1_score(true_binary, pred_binary, zero_division=0)\n",
    "        \n",
    "        class_metrics[label] = {\n",
    "            \"precision\": class_precision,\n",
    "            \"recall\": class_recall,\n",
    "            \"f1\": class_f1\n",
    "        }\n",
    "    \n",
    "    # Calculate execution time\n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    # Print out the results\n",
    "    print(f\"\\nResults for {test_set}:\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Average Confidence: {avg_confidence:.6f}\")\n",
    "    print(f\"Average Sentiment Scores: positive={avg_positive_score:.6f}, negative={avg_negative_score:.6f}, neutral={avg_neutral_score:.6f}\")\n",
    "    print(f\"Prediction Distribution: {pred_counts}\")\n",
    "    print(f\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"Label Mapping: {unique_labels}\")\n",
    "    \n",
    "    # Print per-class metrics\n",
    "    print(\"\\nPer-Class Metrics:\")\n",
    "    for label in unique_labels:\n",
    "        metrics = class_metrics[label]\n",
    "        print(f\"{label}: Precision={metrics['precision']:.4f}, Recall={metrics['recall']:.4f}, F1={metrics['f1']:.4f}\")\n",
    "    \n",
    "    # Calculate and print error analysis\n",
    "    print(\"\\nError Analysis:\")\n",
    "    misclassified_indices = [i for i, (true, pred) in enumerate(zip(test_labels_str, pred_labels)) if true != pred]\n",
    "    \n",
    "    # Print a few example errors\n",
    "    if misclassified_indices:\n",
    "        print(\"\\nExample Misclassifications:\")\n",
    "        for idx in misclassified_indices[:min(5, len(misclassified_indices))]:\n",
    "            tweet = test_texts[idx]\n",
    "            true_label = test_labels_str[idx]\n",
    "            pred_label = pred_labels[idx]\n",
    "            print(f\"Tweet: '{tweet}'\")\n",
    "            print(f\"True: {true_label}, Predicted: {pred_label}\")\n",
    "    \n",
    "    print(f\"\\nExecution Time: {execution_time:.2f} seconds ({execution_time/len(test_texts):.2f} seconds per tweet)\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to run all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 45101 tweets from twitter-training-data.txt\n",
      "Sentiments distribution in twitter-training-data.txt: {'positive': 15986, 'negative': 8326, 'neutral': 20789}\n",
      "Loaded 2000 tweets from twitter-dev-data.txt\n",
      "Sentiments distribution in twitter-dev-data.txt: {'positive': 703, 'negative': 378, 'neutral': 919}\n",
      "Loaded 3531 tweets from twitter-test1.txt\n",
      "Sentiments distribution in twitter-test1.txt: {'positive': 1470, 'negative': 557, 'neutral': 1504}\n",
      "Loaded 1853 tweets from twitter-test2.txt\n",
      "Sentiments distribution in twitter-test2.txt: {'positive': 982, 'negative': 202, 'neutral': 669}\n",
      "Loaded 2379 tweets from twitter-test3.txt\n",
      "Sentiments distribution in twitter-test3.txt: {'positive': 1033, 'negative': 363, 'neutral': 983}\n"
     ]
    }
   ],
   "source": [
    "# Loading Data\n",
    "def sentiment_counts(sentiments):\n",
    "    counts = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "    for sentiment in sentiments:\n",
    "        if sentiment in counts:\n",
    "            counts[sentiment] += 1\n",
    "    return counts\n",
    "\n",
    "# Load training set, dev set and testing set\n",
    "data = {}\n",
    "tweetids = {}\n",
    "tweetgts = {}\n",
    "tweets = {}\n",
    "\n",
    "# Array of testsets\n",
    "testsets = ['twitter-test1.txt', 'twitter-test2.txt', 'twitter-test3.txt']\n",
    "\n",
    "# Define base directory where files are located\n",
    "base_dir = os.path.join('semeval-tweets', 'semeval-tweets')\n",
    "\n",
    "# Add dev set to the list of datasets to load\n",
    "datasets = ['twitter-training-data.txt', 'twitter-dev-data.txt'] + testsets\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    data[dataset] = []\n",
    "    tweets[dataset] = []\n",
    "    tweetids[dataset] = []\n",
    "    tweetgts[dataset] = []\n",
    "    \n",
    "    file_path = os.path.join(base_dir, dataset)\n",
    "    \n",
    "    # Read the dataset\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                # Split by tab character\n",
    "                fields = line.strip().split('\\t')\n",
    "                \n",
    "                # Check if line has enough fields\n",
    "                if len(fields) >= 3:\n",
    "                    tweet_id = fields[0]          # First column: tweet ID\n",
    "                    sentiment = fields[1]         # Second column: sentiment label\n",
    "                    tweet_text = fields[2]        # Third column: tweet text\n",
    "                    \n",
    "                    # Store the data\n",
    "                    data[dataset].append((tweet_id, sentiment, tweet_text))\n",
    "                    tweetids[dataset].append(tweet_id)\n",
    "                    tweetgts[dataset].append(sentiment)\n",
    "                    tweets[dataset].append(tweet_text)\n",
    "        \n",
    "        print(f\"Loaded {len(tweets[dataset])} tweets from {dataset}\")\n",
    "        print(f\"Sentiments distribution in {dataset}: {sentiment_counts(tweetgts[dataset])}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {dataset}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import html\n",
    "from typing import List, Dict, Optional, Union, Set, Tuple\n",
    "import warnings\n",
    "import emoji\n",
    "\n",
    "# Suppress any warnings to keep the notebook clean\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class TwitterPreprocessor:\n",
    "    \"\"\"\n",
    "    A comprehensive text preprocessing pipeline for Twitter data, \n",
    "    optimized for sentiment analysis tasks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 remove_urls: bool = True,\n",
    "                 remove_mentions: bool = True,\n",
    "                 replace_emojis: bool = True,\n",
    "                 handle_negations: bool = True,\n",
    "                 replace_elongations: bool = True,\n",
    "                 handle_hashtags: bool = True,\n",
    "                 remove_numbers: bool = True):\n",
    "        \"\"\"\n",
    "        Initialize the preprocessor with configurable options.\n",
    "        \n",
    "        Args:\n",
    "            remove_urls: Whether to replace URLs with <URL> tag\n",
    "            remove_mentions: Whether to replace @mentions with <USER> tag\n",
    "            replace_emojis: Whether to replace emojis with semantic tags\n",
    "            handle_negations: Whether to mark words after negation terms\n",
    "            replace_elongations: Whether to normalize elongated words\n",
    "            handle_hashtags: Whether to process hashtags\n",
    "            remove_numbers: Whether to replace numbers with <NUMBER> tag\n",
    "        \"\"\"\n",
    "        self.remove_urls = remove_urls\n",
    "        self.remove_mentions = remove_mentions\n",
    "        self.replace_emojis = replace_emojis\n",
    "        self.handle_negations = handle_negations\n",
    "        self.replace_elongations = replace_elongations\n",
    "        self.handle_hashtags = handle_hashtags\n",
    "        self.remove_numbers = remove_numbers\n",
    "        \n",
    "        # Regex flags for multiline processing\n",
    "        self.flags = re.MULTILINE | re.DOTALL\n",
    "        \n",
    "        # Stopwords and function words that shouldn't be negated\n",
    "        self.non_negatable_words = self._get_non_negatable_words()\n",
    "        \n",
    "        # Compile all regex patterns for efficiency\n",
    "        self._compile_regex_patterns()\n",
    "    \n",
    "    def _compile_regex_patterns(self):\n",
    "        \"\"\"Compile all regex patterns used in preprocessing for better performance.\"\"\"\n",
    "        # Entity patterns\n",
    "        self.url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "        self.email_pattern = re.compile(r'[\\w.+-]+@[\\w-]+\\.(?:[\\w-]\\.?)+[\\w-]')\n",
    "        self.mention_pattern = re.compile(r'@\\w+')\n",
    "        self.hashtag_pattern = re.compile(r'#(\\w+)')\n",
    "        self.hashtag_split_pattern = re.compile(r'(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|_')\n",
    "        self.number_pattern = re.compile(r'\\b[-+]?[\\d,]*\\.?\\d+\\b')\n",
    "        self.emoticon_pattern = self._get_emoticon_patterns()\n",
    "        \n",
    "        # Text feature patterns\n",
    "        self.elongated_pattern = re.compile(r'\\b(\\w*?)(.)\\2{2,}\\b')\n",
    "        self.repeated_punct_pattern = re.compile(r'([!?])\\1{1,}')  # Only for ! and ?\n",
    "        self.ellipsis_pattern = re.compile(r'\\.{3,}')\n",
    "        self.word_split_pattern = re.compile(r'[/\\-_]')\n",
    "        self.all_caps_pattern = re.compile(r'\\b([A-Z]{2,})\\b(?!>)')\n",
    "        self.emphasis_pattern = re.compile(r'\\*(\\w+|\\s+\\w+\\s+)\\*')\n",
    "        \n",
    "        # Contraction and possessive patterns\n",
    "        self.contraction_patterns = self._get_contraction_patterns()\n",
    "        self.possessive_pattern = re.compile(r'(\\w+)\\'s\\b', re.IGNORECASE)\n",
    "        \n",
    "        # Negation pattern - improved to match specific negation terms\n",
    "        self.negation_pattern = re.compile(\n",
    "            r'\\b(?:not|no|never|n\\'t|isn\\'t|aren\\'t|wasn\\'t|weren\\'t|haven\\'t|'\n",
    "            r'hasn\\'t|hadn\\'t|won\\'t|wouldn\\'t|don\\'t|doesn\\'t|didn\\'t)\\b'\n",
    "            r'(?:\\s+(?:so|very|too|that|just|a|the|an|very|really|much|\\w+ly))?'  # Optional intensifiers\n",
    "            r'\\s+(\\w+(?:\\s+\\w+)?)'  # Capture up to 2 words that might be negated\n",
    "        )\n",
    "        \n",
    "        # Double negation pattern - to avoid applying negation twice\n",
    "        self.double_negation_pattern = re.compile(\n",
    "            r'\\b(?:not|no|never|n\\'t)\\b\\s+\\w+\\s+\\b(?:not|no|never|n\\'t)\\b'\n",
    "        )\n",
    "        \n",
    "        # Heart emoticon pattern - needs to be detected before number handling\n",
    "        self.heart_pattern = re.compile(r'<3')\n",
    "        \n",
    "        # Control characters and spacing\n",
    "        self.control_char_pattern = re.compile(r'[\\n\\t\\r]')\n",
    "        self.multi_space_pattern = re.compile(r'\\s+')\n",
    "        \n",
    "        # Special protected tags pattern\n",
    "        self.protected_tags_pattern = re.compile(\n",
    "            r'<(?:URL|USER|EMAIL|NUMBER|HASHTAG|SMILE|LOL|SAD|NEUTRAL|HEART|'\n",
    "            r'REPEAT|ELONG|ALLCAPS|ANGRY|LOVE|EMPHASIS|ELLIPSIS)>|</HASHTAG>'\n",
    "        )\n",
    "        \n",
    "        # Emoji dictionaries for Unicode emoji handling\n",
    "        self.emoji_mappings = self._get_emoji_mappings()\n",
    "    \n",
    "    def _get_emoticon_patterns(self) -> Dict[str, re.Pattern]:\n",
    "        \"\"\"Create patterns for detecting common emoticons.\"\"\"\n",
    "        eyes = r'[8:=;]'\n",
    "        nose = r\"['`\\-^]?\"\n",
    "        \n",
    "        return {\n",
    "            'smile': re.compile(f'{eyes}{nose}[)Dd]+|[(Dd]+{nose}{eyes}'),\n",
    "            'lol': re.compile(f'{eyes}{nose}[pP]+'),\n",
    "            'sad': re.compile(f'{eyes}{nose}\\\\(+|\\\\)+{nose}{eyes}'),\n",
    "            'neutral': re.compile(f'{eyes}{nose}[|\\\\\\\\/]'),\n",
    "            'heart': re.compile(r'‚ô•')  # Moved <3 to separate pattern\n",
    "        }\n",
    "        \n",
    "    def _get_emoji_mappings(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"Define mappings for Unicode emojis to sentiment categories.\"\"\"\n",
    "        return {\n",
    "            'SMILE': [\n",
    "                'üòÄ', 'üòÉ', 'üòÑ', 'üòÅ', 'üòÜ', 'üòä', 'üôÇ', 'üòâ', 'üòå', 'üòç', \n",
    "                'ü•∞', 'üòò', 'üòó', 'üòô', 'üòö', 'üòã', 'üòõ', 'üòù', 'üòú', 'ü§™',\n",
    "                'ü§ó', 'ü§≠', 'ü•≤', '‚ò∫Ô∏è', 'üëç', 'üí™', 'üî•', '‚ú®', 'üíØ', 'üëä',\n",
    "                'üëè', 'üôè', 'ü§ù', 'üëå', 'üëë', 'üíê', 'üåü', '‚≠ê', 'üåà', 'üåû'\n",
    "            ],\n",
    "            'SAD': [\n",
    "                '‚òπÔ∏è', 'üòû', 'üòî', 'üòü', 'üòï', 'üôÅ', 'üò£', 'üòñ', 'üò´', 'üò©',\n",
    "                'ü•∫', 'üò¢', 'üò≠', 'üòÆ‚Äçüí®', 'üò§', 'ü•±', 'üò¥', 'üëé', 'üíî', 'üòø'\n",
    "            ],\n",
    "            'ANGRY': [\n",
    "                'üò†', 'üò°', 'ü§¨', 'üëø', 'üò§', 'üòæ', 'üí¢', 'üóØÔ∏è', '‚ö°', '‚ò†Ô∏è'\n",
    "            ],\n",
    "            'LOL': [\n",
    "                'üòÇ', 'ü§£', 'ü§≠', 'ü§™', 'ü§°'\n",
    "            ],\n",
    "            'NEUTRAL': [\n",
    "                'üòê', 'üòë', 'üò∂', 'ü§ê', 'üò∂‚Äçüå´Ô∏è', 'üòè', 'üòí', 'ü§∑', 'ü§∑‚Äç‚ôÇÔ∏è', \n",
    "                'ü§∑‚Äç‚ôÄÔ∏è', 'üëÄ', 'üßê', 'ü§î'\n",
    "            ],\n",
    "            'HEART': [\n",
    "                '‚ù§Ô∏è', 'üß°', 'üíõ', 'üíö', 'üíô', 'üíú', 'üñ§', 'ü§ç', 'ü§é', '‚ù£Ô∏è',\n",
    "                'üíï', 'üíû', 'üíì', 'üíó', 'üíñ', 'üíò', 'üíù', 'üíü', 'üíå', '‚ô•Ô∏è'\n",
    "            ],\n",
    "            'LOVE': [\n",
    "                'ü•∞', 'üòç', 'üòò', 'üòó', 'üòô', 'üòö', 'üíë', 'üë©‚Äç‚ù§Ô∏è‚Äçüë®', 'üë®‚Äç‚ù§Ô∏è‚Äçüë®', 'üë©‚Äç‚ù§Ô∏è‚Äçüë©',\n",
    "                'üíè', 'üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë®', 'üë®‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë®', 'üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë©'\n",
    "            ],\n",
    "            'PARTY': [\n",
    "                'üéâ', 'üéä', 'üéÇ', 'üéà', 'üéÅ', 'üéÜ', 'üéá', 'üéÄ', 'üçæ', 'ü•Ç'\n",
    "            ],\n",
    "            'FOOD': [\n",
    "                'üçï', 'üçî', 'üçü', 'üå≠', 'üçø', 'üßÇ', 'ü•ì', 'üçñ', 'üçó', 'ü•©',\n",
    "                'üç§', 'üç≥', 'üç≤', 'ü•£', 'ü•ó', 'üçú', 'üçù', 'üç±', 'üçö', 'üçõ',\n",
    "                'üç†', 'üç¢', 'üç£', 'üç§', 'üç•', 'ü•Æ', 'üç°', 'ü•ü', 'ü•†', 'ü•°',\n",
    "                'üç¶', 'üçß', 'üç®', 'üç©', 'üç™', 'üéÇ', 'üç∞', 'üßÅ', 'ü•ß', 'üç´',\n",
    "                'üç¨', 'üç≠', 'üçÆ', 'üçØ', 'üçº', 'ü•õ', '‚òï', 'üçµ', 'üç∂', 'üçæ',\n",
    "                'üç∑', 'üç∏', 'üçπ', 'üç∫', 'üçª', 'ü•Ç', 'ü•É', 'üßÉ', 'üßâ', 'üßä'\n",
    "            ],\n",
    "            'SARCASM': [\n",
    "                'üôÑ', 'üòí', 'üòè', 'ü§¶', 'ü§¶‚Äç‚ôÇÔ∏è', 'ü§¶‚Äç‚ôÄÔ∏è', 'ü§®', 'üßê'\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def _get_contraction_patterns(self) -> Dict[str, str]:\n",
    "        \"\"\"Define mappings for expanding English contractions.\"\"\"\n",
    "        return {\n",
    "            r\"\\bwon\\'t\\b\": \"will not\",\n",
    "            r\"\\bcan\\'t\\b\": \"cannot\",\n",
    "            r\"\\bcan't\\b\": \"cannot\",\n",
    "            r\"\\bn\\'t\\b\": \" not\",\n",
    "            r\"\\bn't\\b\": \" not\",\n",
    "            r\"\\b\\'re\\b\": \" are\",\n",
    "            r\"\\b're\\b\": \" are\",\n",
    "            r\"\\b\\'ve\\b\": \" have\",\n",
    "            r\"\\b've\\b\": \" have\",\n",
    "            r\"\\b\\'ll\\b\": \" will\",\n",
    "            r\"\\b'll\\b\": \" will\",\n",
    "            r\"\\b\\'d\\b\": \" would\",\n",
    "            r\"\\b'd\\b\": \" would\",\n",
    "            r\"\\b\\'m\\b\": \" am\",\n",
    "            r\"\\b'm\\b\": \" am\"\n",
    "        }\n",
    "    \n",
    "    def decode_html_entities(self, text: str) -> str:\n",
    "        \"\"\"Decode HTML entities like &amp; to &.\"\"\"\n",
    "        return html.unescape(text)\n",
    "        \n",
    "    def normalize_unicode(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Normalize Unicode characters and remove control characters.\n",
    "        \n",
    "        Args:\n",
    "            text: Input text\n",
    "            \n",
    "        Returns:\n",
    "            Normalized text with consistent Unicode representation\n",
    "        \"\"\"\n",
    "        # Normalize to NFKD form and remove accents\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        text = ''.join([c for c in text if not unicodedata.combining(c)])\n",
    "        \n",
    "        # Remove control characters\n",
    "        text = self.control_char_pattern.sub(' ', text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def replace_urls(self, text: str) -> str:\n",
    "        \"\"\"Replace URLs with <URL> tag.\"\"\"\n",
    "        if self.remove_urls:\n",
    "            return self.url_pattern.sub('<URL>', text)\n",
    "        return text\n",
    "    \n",
    "    def replace_emails(self, text: str) -> str:\n",
    "        \"\"\"Replace email addresses with <EMAIL> tag.\"\"\"\n",
    "        return self.email_pattern.sub('<EMAIL>', text)\n",
    "    \n",
    "    def replace_mentions(self, text: str) -> str:\n",
    "        \"\"\"Replace user mentions with <USER> tag.\"\"\"\n",
    "        if self.remove_mentions:\n",
    "            return self.mention_pattern.sub('<USER>', text)\n",
    "        return text\n",
    "    \n",
    "    def replace_heart_emoticon(self, text: str) -> str:\n",
    "        \"\"\"Replace heart emoticon with <HEART> tag before number processing.\"\"\"\n",
    "        return self.heart_pattern.sub('<HEART>', text)\n",
    "    \n",
    "    def replace_numbers(self, text: str) -> str:\n",
    "        \"\"\"Replace numeric values with <NUMBER> tag.\"\"\"\n",
    "        if self.remove_numbers:\n",
    "            return self.number_pattern.sub('<NUMBER>', text)\n",
    "        return text\n",
    "    \n",
    "    def process_hashtags(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Process hashtags by splitting them into component words and adding <HASHTAG> tags.\n",
    "        For example: #DataScience -> <HASHTAG> data science </HASHTAG>\n",
    "        Handles both camelCase and underscores.\n",
    "        \"\"\"\n",
    "        if not self.handle_hashtags:\n",
    "            return text\n",
    "            \n",
    "        def split_hashtag(match):\n",
    "            tag = match.group(1)\n",
    "            # Convert camelCase or PascalCase or snake_case to space-separated words\n",
    "            words = self.hashtag_split_pattern.sub(' ', tag)\n",
    "            # Add spaces for all-caps hashtags (e.g., #NASA -> N A S A)\n",
    "            if tag.isupper() and len(tag) > 1:\n",
    "                words = ' '.join(list(words))\n",
    "            return f'<HASHTAG> {words.lower()} </HASHTAG>'\n",
    "            \n",
    "        return self.hashtag_pattern.sub(split_hashtag, text)\n",
    "    \n",
    "    def replace_emoticons(self, text: str) -> str:\n",
    "        \"\"\"Replace text-based emoticons with semantic tags.\"\"\"\n",
    "        if not self.replace_emojis:\n",
    "            return text\n",
    "            \n",
    "        for emotion, pattern in self.emoticon_pattern.items():\n",
    "            text = pattern.sub(f'<{emotion.upper()}>', text)\n",
    "        \n",
    "        return text\n",
    "        \n",
    "    def replace_unicode_emojis(self, text: str) -> str:\n",
    "        \"\"\"Replace Unicode emojis with semantic tags.\"\"\"\n",
    "        if not self.replace_emojis:\n",
    "            return text\n",
    "            \n",
    "        # Extract emojis and their positions\n",
    "        emoji_list = emoji.emoji_list(text)\n",
    "        \n",
    "        # Replace from end to beginning to avoid position shifts\n",
    "        result = text\n",
    "        for item in reversed(emoji_list):\n",
    "            emoji_char = item['emoji']\n",
    "            start, end = item['match_start'], item['match_end']\n",
    "            \n",
    "            # Find which category this emoji belongs to\n",
    "            category = None\n",
    "            for cat, emoji_chars in self.emoji_mappings.items():\n",
    "                if emoji_char in emoji_chars:\n",
    "                    category = cat\n",
    "                    break\n",
    "            \n",
    "            # If found, replace with the category tag\n",
    "            if category:\n",
    "                result = result[:start] + f\" <{category}> \" + result[end:]\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def handle_emphasis(self, text: str) -> str:\n",
    "        \"\"\"Convert *emphasized* text to an <EMPHASIS> tag.\"\"\"\n",
    "        return self.emphasis_pattern.sub(r'<EMPHASIS>\\1</EMPHASIS>', text)\n",
    "    \n",
    "    def handle_ellipsis(self, text: str) -> str:\n",
    "        \"\"\"Replace ellipsis with <ELLIPSIS> tag to distinguish from repeated punctuation.\"\"\"\n",
    "        return self.ellipsis_pattern.sub(' <ELLIPSIS> ', text)\n",
    "    \n",
    "    def expand_contractions(self, text: str) -> str:\n",
    "        \"\"\"Expand common English contractions.\"\"\"\n",
    "        for pattern, replacement in self.contraction_patterns.items():\n",
    "            text = re.sub(pattern, replacement, text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def handle_possessives(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Preserve possessive forms instead of expanding them as contractions.\n",
    "        For example: \"competitor's\" should remain as a possessive, not \"competitor is\"\n",
    "        \"\"\"\n",
    "        return self.possessive_pattern.sub(r'\\1s', text)\n",
    "    \n",
    "    def expand_contractions(self, text: str) -> str:\n",
    "        \"\"\"Expand common English contractions.\"\"\"\n",
    "        for pattern, replacement in self.contraction_patterns.items():\n",
    "            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def handle_text_features(self, text: str) -> str:\n",
    "        \"\"\"Process text features like all-caps and elongated words.\"\"\"\n",
    "        # Mark all-caps words and convert to lowercase\n",
    "        text = self.all_caps_pattern.sub(lambda m: f'{m.group(1).lower()}<ALLCAPS>', text)\n",
    "        \n",
    "        # Mark and normalize elongated words\n",
    "        if self.replace_elongations:\n",
    "            text = self.elongated_pattern.sub(lambda m: f'{m.group(1)}{m.group(2)} <ELONG>', text)\n",
    "        \n",
    "        # Mark repeated punctuation (only for ! and ?)\n",
    "        text = self.repeated_punct_pattern.sub(lambda m: f'{m.group(1)} <REPEAT>', text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def mark_negations(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Mark words following negation terms with NEG_ prefix, with improved scope detection.\n",
    "        Only negates sentiment-carrying words, not function words.\n",
    "        \"\"\"\n",
    "        if not self.handle_negations:\n",
    "            return text\n",
    "        \n",
    "        # First check if there's a double negation, which would be a positive\n",
    "        if self.double_negation_pattern.search(text):\n",
    "            # Don't mark negations in double negative constructions\n",
    "            return text\n",
    "            \n",
    "        def negate(match):\n",
    "            negation = match.group(0)\n",
    "            following_words = match.group(1) if match.group(1) else \"\"\n",
    "            \n",
    "            # Split the following words\n",
    "            words = following_words.split()\n",
    "            \n",
    "            # Only negate sentiment-relevant terms and limit the scope\n",
    "            negated_words = []\n",
    "            for word in words:\n",
    "                # Skip negation for stopwords, function words, protected tags\n",
    "                word_lower = word.lower()\n",
    "                if (self.protected_tags_pattern.search(word) or \n",
    "                    word_lower in self.non_negatable_words or\n",
    "                    word in string.punctuation):\n",
    "                    negated_words.append(word)\n",
    "                else:\n",
    "                    # Only negate content words that might carry sentiment\n",
    "                    negated_words.append(f'NEG_{word}')\n",
    "            \n",
    "            # Join the negated words back together\n",
    "            negated_text = ' '.join(negated_words)\n",
    "            \n",
    "            # Return the original negation term followed by the negated words\n",
    "            return negation.replace(following_words, negated_text)\n",
    "            \n",
    "        return self.negation_pattern.sub(negate, text)\n",
    "    \n",
    "    def normalize_spacing(self, text: str) -> str:\n",
    "        \"\"\"Normalize spacing in text.\"\"\"\n",
    "        # Replace multiple spaces with a single space\n",
    "        text = self.multi_space_pattern.sub(' ', text)\n",
    "        # Strip leading and trailing spaces\n",
    "        return text.strip()\n",
    "    \n",
    "    def preprocess(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Apply the complete preprocessing pipeline to input text.\n",
    "        \n",
    "        Args:\n",
    "            text: Raw input text\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text ready for sentiment analysis\n",
    "        \"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return \"\"\n",
    "        \n",
    "        # Step 1: Decode HTML entities\n",
    "        text = self.decode_html_entities(text)\n",
    "            \n",
    "        # Step 2: Basic normalization\n",
    "        text = self.normalize_unicode(text)\n",
    "        \n",
    "        # Step 3: Handle <3 heart emoticon before number processing\n",
    "        text = self.replace_heart_emoticon(text)\n",
    "        \n",
    "        # Step 4: Replace Unicode emojis - must be done early \n",
    "        # before they could be affected by other processing\n",
    "        text = self.replace_unicode_emojis(text)\n",
    "        \n",
    "        # Step 5: Replace entities\n",
    "        text = self.replace_urls(text)\n",
    "        text = self.replace_emails(text)\n",
    "        text = self.replace_mentions(text)\n",
    "        text = self.replace_numbers(text)\n",
    "        \n",
    "        # Step 6: Process hashtags\n",
    "        text = self.process_hashtags(text)\n",
    "        \n",
    "        # Step 7: Replace text-based emoticons\n",
    "        text = self.replace_emoticons(text)\n",
    "        \n",
    "        # Step 8: Handle special text features\n",
    "        text = self.handle_emphasis(text)\n",
    "        text = self.handle_ellipsis(text)\n",
    "        \n",
    "        # Step 9: Handle possessives (before expanding contractions)\n",
    "        text = self.handle_possessives(text)\n",
    "        \n",
    "        # Step 10: Expand contractions\n",
    "        text = self.expand_contractions(text)\n",
    "        \n",
    "        # Step 11: Handle text features\n",
    "        text = self.handle_text_features(text)\n",
    "        \n",
    "        # Step 12: Mark negations (important for sentiment)\n",
    "        text = self.mark_negations(text)\n",
    "        \n",
    "        # Step 13: Final cleanup\n",
    "        text = self.normalize_spacing(text)\n",
    "        \n",
    "        # Step 14: Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def preprocess_batch(self, texts: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Preprocess a batch of texts.\n",
    "        \n",
    "        Args:\n",
    "            texts: List of raw input texts\n",
    "            \n",
    "        Returns:\n",
    "            List of preprocessed texts\n",
    "        \"\"\"\n",
    "        return [self.preprocess(text) for text in texts]\n",
    "\n",
    "    def _get_non_negatable_words(self) -> Set[str]:\n",
    "        \"\"\"Return a set of words that shouldn't be negated.\"\"\"\n",
    "        return {\n",
    "            # Articles\n",
    "            'a', 'an', 'the',\n",
    "            # Prepositions\n",
    "            'in', 'on', 'at', 'by', 'for', 'with', 'about', 'against', 'between', \n",
    "            'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', \n",
    "            'from', 'up', 'down', 'of', 'off',\n",
    "            # Conjunctions\n",
    "            'and', 'but', 'or', 'nor', 'so', 'yet', 'because', 'although', 'since',\n",
    "            # Pronouns\n",
    "            'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them',\n",
    "            'my', 'your', 'his', 'its', 'our', 'their', 'mine', 'yours', 'hers', 'ours', 'theirs',\n",
    "            'this', 'that', 'these', 'those', 'who', 'whom', 'whose', 'which', 'what',\n",
    "            # Other function words\n",
    "            'is', 'am', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n",
    "            'do', 'does', 'did', 'will', 'would', 'shall', 'should', 'can', 'could', 'may',\n",
    "            'might', 'must', 'ought', 'there', 'here', 'now', 'then', 'always', 'never'\n",
    "        }\n",
    "\n",
    "# Example function for tokenization after preprocessing\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Tokenize preprocessed text into words.\n",
    "    \n",
    "    Args:\n",
    "        text: Preprocessed text\n",
    "        \n",
    "    Returns:\n",
    "        List of tokens\n",
    "    \"\"\"\n",
    "    # Simple whitespace tokenization for preprocessed text\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "# Function to show example preprocessing\n",
    "def show_preprocessing_example(preprocessor: TwitterPreprocessor, example_texts: List[str]):\n",
    "    \"\"\"\n",
    "    Demonstrate preprocessing on example texts.\n",
    "    \n",
    "    Args:\n",
    "        preprocessor: Initialized TwitterPreprocessor\n",
    "        example_texts: List of example raw texts\n",
    "    \"\"\"\n",
    "    for i, text in enumerate(example_texts):\n",
    "        processed = preprocessor.preprocess(text)\n",
    "        print(f\"Example {i+1}:\")\n",
    "        print(f\"Original: {text}\")\n",
    "        print(f\"Processed: {processed}\")\n",
    "        print(f\"Tokens: {tokenize(processed)}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Preprocessing tweets...\n",
      "Loading GloVe embeddings...\n",
      "Loaded 400000 word vectors\n",
      "Building and evaluating classifiers...\n",
      "\n",
      "Training naive_bayes with bow features...\n",
      "Training Naive Bayes classifier with bow features...\n",
      "\n",
      "Evaluating on twitter-test1.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test1.txt (bow-naive_bayes): 0.570\n",
      "            positive  negative  neutral\n",
      "positive    0.629     0.073     0.298     \n",
      "negative    0.228     0.560     0.212     \n",
      "neutral     0.244     0.135     0.621     \n",
      "\n",
      "\n",
      "Evaluating on twitter-test2.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test2.txt (bow-naive_bayes): 0.609\n",
      "            positive  negative  neutral\n",
      "positive    0.697     0.062     0.241     \n",
      "negative    0.175     0.627     0.198     \n",
      "neutral     0.307     0.088     0.605     \n",
      "\n",
      "\n",
      "Evaluating on twitter-test3.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test3.txt (bow-naive_bayes): 0.536\n",
      "            positive  negative  neutral\n",
      "positive    0.684     0.085     0.231     \n",
      "negative    0.271     0.431     0.297     \n",
      "neutral     0.271     0.123     0.606     \n",
      "\n",
      "\n",
      "Training naive_bayes with tfidf features...\n",
      "Training Naive Bayes classifier with tfidf features...\n",
      "\n",
      "Evaluating on twitter-test1.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test1.txt (tfidf-naive_bayes): 0.374\n",
      "            positive  negative  neutral\n",
      "positive    0.684     0.083     0.233     \n",
      "negative    0.053     0.842     0.105     \n",
      "neutral     0.264     0.190     0.546     \n",
      "\n",
      "\n",
      "Evaluating on twitter-test2.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test2.txt (tfidf-naive_bayes): 0.439\n",
      "            positive  negative  neutral\n",
      "positive    0.737     0.067     0.196     \n",
      "negative    0.000     0.947     0.053     \n",
      "neutral     0.330     0.134     0.536     \n",
      "\n",
      "\n",
      "Evaluating on twitter-test3.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test3.txt (tfidf-naive_bayes): 0.367\n",
      "            positive  negative  neutral\n",
      "positive    0.729     0.093     0.179     \n",
      "negative    0.077     0.846     0.077     \n",
      "neutral     0.298     0.170     0.532     \n",
      "\n",
      "\n",
      "Training maxent with bow features...\n",
      "Training MaxEnt (Logistic Regression) classifier...\n",
      "Using TF-IDF features (embeddings not available)\n",
      "Best parameters: {'C': 1.0, 'class_weight': 'balanced', 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "Evaluating on twitter-test1.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test1.txt (bow-maxent): 0.602\n",
      "            positive  negative  neutral\n",
      "positive    0.707     0.051     0.241     \n",
      "negative    0.184     0.660     0.156     \n",
      "neutral     0.238     0.139     0.623     \n",
      "\n",
      "\n",
      "Evaluating on twitter-test2.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test2.txt (bow-maxent): 0.611\n",
      "            positive  negative  neutral\n",
      "positive    0.762     0.049     0.188     \n",
      "negative    0.201     0.612     0.187     \n",
      "neutral     0.321     0.093     0.586     \n",
      "\n",
      "\n",
      "Evaluating on twitter-test3.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test3.txt (bow-maxent): 0.561\n",
      "            positive  negative  neutral\n",
      "positive    0.773     0.070     0.157     \n",
      "negative    0.229     0.508     0.262     \n",
      "neutral     0.281     0.119     0.600     \n",
      "\n",
      "\n",
      "Training maxent with tfidf features...\n",
      "Training MaxEnt (Logistic Regression) classifier...\n",
      "Using TF-IDF features (embeddings not available)\n",
      "Best parameters: {'C': 1.0, 'class_weight': 'balanced', 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "Evaluating on twitter-test1.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test1.txt (tfidf-maxent): 0.602\n",
      "            positive  negative  neutral\n",
      "positive    0.707     0.051     0.241     \n",
      "negative    0.184     0.660     0.156     \n",
      "neutral     0.238     0.139     0.623     \n",
      "\n",
      "\n",
      "Evaluating on twitter-test2.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test2.txt (tfidf-maxent): 0.611\n",
      "            positive  negative  neutral\n",
      "positive    0.762     0.049     0.188     \n",
      "negative    0.201     0.612     0.187     \n",
      "neutral     0.321     0.093     0.586     \n",
      "\n",
      "\n",
      "Evaluating on twitter-test3.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test3.txt (tfidf-maxent): 0.561\n",
      "            positive  negative  neutral\n",
      "positive    0.773     0.070     0.157     \n",
      "negative    0.229     0.508     0.262     \n",
      "neutral     0.281     0.119     0.600     \n",
      "\n",
      "\n",
      "Training maxent with embeddings features...\n",
      "Training MaxEnt (Logistic Regression) classifier...\n",
      "Using combined embeddings and sentiment features\n",
      "Best parameters: {'C': 10.0, 'class_weight': 'balanced', 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "\n",
      "Evaluating on twitter-test1.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test1.txt (embeddings-maxent): 0.561\n",
      "            positive  negative  neutral\n",
      "positive    0.647     0.069     0.284     \n",
      "negative    0.203     0.574     0.223     \n",
      "neutral     0.272     0.133     0.594     \n",
      "\n",
      "\n",
      "Evaluating on twitter-test2.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test2.txt (embeddings-maxent): 0.520\n",
      "            positive  negative  neutral\n",
      "positive    0.682     0.081     0.237     \n",
      "negative    0.342     0.418     0.241     \n",
      "neutral     0.372     0.079     0.549     \n",
      "\n",
      "\n",
      "Evaluating on twitter-test3.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test3.txt (embeddings-maxent): 0.529\n",
      "            positive  negative  neutral\n",
      "positive    0.684     0.078     0.238     \n",
      "negative    0.237     0.409     0.354     \n",
      "neutral     0.304     0.120     0.576     \n",
      "\n",
      "\n",
      "Training lstm with embeddings features...\n",
      "Training Basic LSTM model...\n",
      "Epoch 1/10 - Train Loss: 0.8700, Train Acc: 0.5800 | Dev Loss: 0.8078, Dev Acc: 0.6290\n",
      "Epoch 2/10 - Train Loss: 0.7914, Train Acc: 0.6312 | Dev Loss: 0.7863, Dev Acc: 0.6350\n",
      "Epoch 3/10 - Train Loss: 0.7606, Train Acc: 0.6487 | Dev Loss: 0.7565, Dev Acc: 0.6550\n",
      "Epoch 4/10 - Train Loss: 0.7361, Train Acc: 0.6615 | Dev Loss: 0.7577, Dev Acc: 0.6450\n",
      "Epoch 5/10 - Train Loss: 0.7139, Train Acc: 0.6740 | Dev Loss: 0.7406, Dev Acc: 0.6610\n",
      "Epoch 6/10 - Train Loss: 0.6893, Train Acc: 0.6880 | Dev Loss: 0.7368, Dev Acc: 0.6550\n",
      "Epoch 7/10 - Train Loss: 0.6650, Train Acc: 0.7009 | Dev Loss: 0.7357, Dev Acc: 0.6705\n",
      "Epoch 8/10 - Train Loss: 0.6363, Train Acc: 0.7187 | Dev Loss: 0.7408, Dev Acc: 0.6575\n",
      "Epoch 9/10 - Train Loss: 0.6052, Train Acc: 0.7338 | Dev Loss: 0.7541, Dev Acc: 0.6600\n",
      "Epoch 10/10 - Train Loss: 0.5714, Train Acc: 0.7493 | Dev Loss: 0.7774, Dev Acc: 0.6555\n",
      "Early stopping triggered after 10 epochs\n",
      "Loaded the best model (Dev accuracy: 0.6705)\n",
      "\n",
      "Evaluating on twitter-test1.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test1.txt (embeddings-lstm): 0.605\n",
      "            positive  negative  neutral\n",
      "positive    0.782     0.038     0.180     \n",
      "negative    0.130     0.699     0.171     \n",
      "neutral     0.226     0.152     0.622     \n",
      "\n",
      "\n",
      "Evaluating on twitter-test2.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test2.txt (embeddings-lstm): 0.602\n",
      "            positive  negative  neutral\n",
      "positive    0.809     0.040     0.152     \n",
      "negative    0.146     0.699     0.155     \n",
      "neutral     0.332     0.104     0.564     \n",
      "\n",
      "\n",
      "Evaluating on twitter-test3.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test3.txt (embeddings-lstm): 0.562\n",
      "            positive  negative  neutral\n",
      "positive    0.778     0.055     0.167     \n",
      "negative    0.172     0.612     0.216     \n",
      "neutral     0.293     0.130     0.576     \n",
      "\n",
      "\n",
      "Training enhanced_lstm with embeddings features...\n",
      "Training Enhanced LSTM with Attention model...\n",
      "Epoch 1/15 - Train Loss: 0.8398, Train Acc: 0.5978 | Dev Loss: 0.7831, Dev Acc: 0.6235\n",
      "Epoch 2/15 - Train Loss: 0.7653, Train Acc: 0.6412 | Dev Loss: 0.7334, Dev Acc: 0.6690\n",
      "Epoch 3/15 - Train Loss: 0.7348, Train Acc: 0.6601 | Dev Loss: 0.7217, Dev Acc: 0.6725\n",
      "Epoch 4/15 - Train Loss: 0.7060, Train Acc: 0.6763 | Dev Loss: 0.7062, Dev Acc: 0.6815\n",
      "Epoch 5/15 - Train Loss: 0.6796, Train Acc: 0.6893 | Dev Loss: 0.6959, Dev Acc: 0.6870\n",
      "Epoch 6/15 - Train Loss: 0.6559, Train Acc: 0.7044 | Dev Loss: 0.6915, Dev Acc: 0.6910\n",
      "Epoch 7/15 - Train Loss: 0.6307, Train Acc: 0.7179 | Dev Loss: 0.6986, Dev Acc: 0.6830\n",
      "Epoch 8/15 - Train Loss: 0.6061, Train Acc: 0.7287 | Dev Loss: 0.7140, Dev Acc: 0.6765\n",
      "Epoch 9/15 - Train Loss: 0.5750, Train Acc: 0.7492 | Dev Loss: 0.7155, Dev Acc: 0.6790\n",
      "Early stopping triggered after 9 epochs\n",
      "Loaded the best model (Dev accuracy: 0.6910)\n",
      "\n",
      "Evaluating on twitter-test1.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test1.txt (embeddings-enhanced_lstm): 0.633\n",
      "            positive  negative  neutral\n",
      "positive    0.762     0.029     0.210     \n",
      "negative    0.106     0.777     0.116     \n",
      "neutral     0.214     0.155     0.631     \n",
      "\n",
      "\n",
      "Evaluating on twitter-test2.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test2.txt (embeddings-enhanced_lstm): 0.633\n",
      "            positive  negative  neutral\n",
      "positive    0.815     0.023     0.162     \n",
      "negative    0.098     0.765     0.137     \n",
      "neutral     0.315     0.115     0.570     \n",
      "\n",
      "\n",
      "Evaluating on twitter-test3.txt...\n",
      "semeval-tweets/semeval-tweets/twitter-test3.txt (embeddings-enhanced_lstm): 0.619\n",
      "            positive  negative  neutral\n",
      "positive    0.803     0.034     0.163     \n",
      "negative    0.110     0.665     0.224     \n",
      "neutral     0.272     0.130     0.598     \n",
      "\n",
      "\n",
      "Model comparison completed!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import os\n",
    "from os.path import join\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For LSTM model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# For text preprocessing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define test sets\n",
    "testsets = ['twitter-test1.txt', 'twitter-test2.txt', 'twitter-test3.txt']\n",
    "\n",
    "# Evaluation code for the test sets\n",
    "def read_test(testset):\n",
    "    '''\n",
    "    readin the testset and return a dictionary\n",
    "    :param testset: str, the file name of the testset to compare\n",
    "    '''\n",
    "    id_gts = {}\n",
    "    with open(testset, 'r', encoding='utf8') as fh:\n",
    "        for line in fh:\n",
    "            fields = line.split('\\t')\n",
    "            tweetid = fields[0]\n",
    "            gt = fields[1]\n",
    "\n",
    "            id_gts[tweetid] = gt\n",
    "\n",
    "    return id_gts\n",
    "\n",
    "\n",
    "def confusion(id_preds, testset, classifier):\n",
    "    '''\n",
    "    print the confusion matrix of {'positive', 'netative'} between preds and testset\n",
    "    :param id_preds: a dictionary of predictions formated as {<tweetid>:<sentiment>, ... }\n",
    "    :param testset: str, the file name of the testset to compare\n",
    "    :classifier: str, the name of the classifier\n",
    "    '''\n",
    "    id_gts = read_test(testset)\n",
    "\n",
    "    gts = []\n",
    "    for m, c1 in id_gts.items():\n",
    "        if c1 not in gts:\n",
    "            gts.append(c1)\n",
    "\n",
    "    gts = ['positive', 'negative', 'neutral']\n",
    "\n",
    "    conf = {}\n",
    "    for c1 in gts:\n",
    "        conf[c1] = {}\n",
    "        for c2 in gts:\n",
    "            conf[c1][c2] = 0\n",
    "\n",
    "    for tweetid, gt in id_gts.items():\n",
    "        if tweetid in id_preds:\n",
    "            pred = id_preds[tweetid]\n",
    "        else:\n",
    "            pred = 'neutral'\n",
    "        conf[pred][gt] += 1\n",
    "\n",
    "    print(''.ljust(12) + '  '.join(gts))\n",
    "\n",
    "    for c1 in gts:\n",
    "        print(c1.ljust(12), end='')\n",
    "        for c2 in gts:\n",
    "            if sum(conf[c1].values()) > 0:\n",
    "                print('%.3f     ' % (conf[c1][c2] / float(sum(conf[c1].values()))), end='')\n",
    "            else:\n",
    "                print('0.000     ', end='')\n",
    "        print('')\n",
    "\n",
    "    print('')\n",
    "\n",
    "\n",
    "def evaluate(id_preds, testset, classifier):\n",
    "    '''\n",
    "    print the macro-F1 score of {'positive', 'netative'} between preds and testset\n",
    "    :param id_preds: a dictionary of predictions formated as {<tweetid>:<sentiment>, ... }\n",
    "    :param testset: str, the file name of the testset to compare\n",
    "    :classifier: str, the name of the classifier\n",
    "    '''\n",
    "    id_gts = read_test(testset)\n",
    "\n",
    "    acc_by_class = {}\n",
    "    for gt in ['positive', 'negative', 'neutral']:\n",
    "        acc_by_class[gt] = {'tp': 0, 'fp': 0, 'tn': 0, 'fn': 0}\n",
    "\n",
    "    catf1s = {}\n",
    "\n",
    "    ok = 0\n",
    "    for tweetid, gt in id_gts.items():\n",
    "        if tweetid in id_preds:\n",
    "            pred = id_preds[tweetid]\n",
    "        else:\n",
    "            pred = 'neutral'\n",
    "\n",
    "        if gt == pred:\n",
    "            ok += 1\n",
    "            acc_by_class[gt]['tp'] += 1\n",
    "        else:\n",
    "            acc_by_class[gt]['fn'] += 1\n",
    "            acc_by_class[pred]['fp'] += 1\n",
    "\n",
    "    catcount = 0\n",
    "    itemcount = 0\n",
    "    macro = {'p': 0, 'r': 0, 'f1': 0}\n",
    "    micro = {'p': 0, 'r': 0, 'f1': 0}\n",
    "    semevalmacro = {'p': 0, 'r': 0, 'f1': 0}\n",
    "\n",
    "    microtp = 0\n",
    "    microfp = 0\n",
    "    microtn = 0\n",
    "    microfn = 0\n",
    "    for cat, acc in acc_by_class.items():\n",
    "        catcount += 1\n",
    "\n",
    "        microtp += acc['tp']\n",
    "        microfp += acc['fp']\n",
    "        microtn += acc['tn']\n",
    "        microfn += acc['fn']\n",
    "\n",
    "        p = 0\n",
    "        if (acc['tp'] + acc['fp']) > 0:\n",
    "            p = float(acc['tp']) / (acc['tp'] + acc['fp'])\n",
    "\n",
    "        r = 0\n",
    "        if (acc['tp'] + acc['fn']) > 0:\n",
    "            r = float(acc['tp']) / (acc['tp'] + acc['fn'])\n",
    "\n",
    "        f1 = 0\n",
    "        if (p + r) > 0:\n",
    "            f1 = 2 * p * r / (p + r)\n",
    "\n",
    "        catf1s[cat] = f1\n",
    "\n",
    "        n = acc['tp'] + acc['fn']\n",
    "\n",
    "        macro['p'] += p\n",
    "        macro['r'] += r\n",
    "        macro['f1'] += f1\n",
    "\n",
    "        if cat in ['positive', 'negative']:\n",
    "            semevalmacro['p'] += p\n",
    "            semevalmacro['r'] += r\n",
    "            semevalmacro['f1'] += f1\n",
    "\n",
    "        itemcount += n\n",
    "\n",
    "    micro['p'] = float(microtp) / float(microtp + microfp) if (microtp + microfp) > 0 else 0\n",
    "    micro['r'] = float(microtp) / float(microtp + microfn) if (microtp + microfn) > 0 else 0\n",
    "    micro['f1'] = 2 * float(micro['p']) * micro['r'] / float(micro['p'] + micro['r']) if (micro['p'] + micro['r']) > 0 else 0\n",
    "\n",
    "    semevalmacrof1 = semevalmacro['f1'] / 2\n",
    "\n",
    "    print(testset + ' (' + classifier + '): %.3f' % semevalmacrof1)\n",
    "\n",
    "# Load training set, dev set and testing set\n",
    "data = {}\n",
    "tweetids = {}\n",
    "tweetgts = {}\n",
    "tweets = {}\n",
    "\n",
    "# Function to load and preprocess datasets\n",
    "def load_datasets(base_dir='semeval-tweets'):\n",
    "    \"\"\"\n",
    "    Load and preprocess all datasets including dev set\n",
    "    \"\"\"\n",
    "    datasets = ['twitter-training-data.txt', 'twitter-dev-data.txt'] + testsets\n",
    "    data = {}\n",
    "    tweetids = {}\n",
    "    tweetgts = {}\n",
    "    tweets = {}\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        data[dataset] = []\n",
    "        tweets[dataset] = []\n",
    "        tweetids[dataset] = []\n",
    "        tweetgts[dataset] = []\n",
    "        \n",
    "        dataset_path = join(base_dir, dataset)\n",
    "        \n",
    "        try:\n",
    "            with open(dataset_path, 'r', encoding='utf8') as f:\n",
    "                for line in f:\n",
    "                    fields = line.strip().split('\\t')\n",
    "                    \n",
    "                    if len(fields) >= 3:\n",
    "                        tweet_id = fields[0]\n",
    "                        sentiment = fields[1]\n",
    "                        tweet_text = fields[2]\n",
    "                        \n",
    "                        tweetids[dataset].append(tweet_id)\n",
    "                        tweetgts[dataset].append(sentiment)\n",
    "                        tweets[dataset].append(tweet_text)\n",
    "                        data[dataset].append((tweet_id, sentiment, tweet_text))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File {dataset_path} not found\")\n",
    "    \n",
    "    return data, tweetids, tweetgts, tweets\n",
    "\n",
    "# Load opinion lexicon for sentiment features\n",
    "def load_opinion_lexicon(positive_file, negative_file):\n",
    "    \"\"\"Load the Opinion Lexicon.\"\"\"\n",
    "    positive_words = set()\n",
    "    negative_words = set()\n",
    "    \n",
    "    try:\n",
    "        with open(positive_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith(';'):\n",
    "                    positive_words.add(line.lower())\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Could not find {positive_file}. Using empty positive lexicon.\")\n",
    "    \n",
    "    try:\n",
    "        with open(negative_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith(';'):\n",
    "                    negative_words.add(line.lower())\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Could not find {negative_file}. Using empty negative lexicon.\")\n",
    "    \n",
    "    return positive_words, negative_words\n",
    "\n",
    "# For Naive Bayes with Bag of Words or TF-IDF (IMPROVED VERSION)\n",
    "def train_naive_bayes(X_train, y_train, features='bow'):\n",
    "    \"\"\"\n",
    "    Train a Naive Bayes classifier using either BOW or TF-IDF features\n",
    "    \"\"\"\n",
    "    print(f\"Training Naive Bayes classifier with {features} features...\")\n",
    "    \n",
    "    if features == 'bow':\n",
    "        # Bag of Words vectorizer\n",
    "        vectorizer = CountVectorizer(\n",
    "            analyzer='word',\n",
    "            tokenizer=lambda x: x.split(),  # Simple space tokenization\n",
    "            preprocessor=None,\n",
    "            min_df=5,  # Ignore terms that appear in less than 5 documents\n",
    "            max_df=0.7,  # Ignore terms that appear in more than 70% of documents\n",
    "            ngram_range=(1, 2)  # Include unigrams and bigrams\n",
    "        )\n",
    "    elif features == 'tfidf':\n",
    "        # TF-IDF vectorizer\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            analyzer='word',\n",
    "            tokenizer=lambda x: x.split(),\n",
    "            preprocessor=None,\n",
    "            min_df=5,\n",
    "            max_df=0.7,\n",
    "            ngram_range=(1, 2),\n",
    "            use_idf=True,\n",
    "            sublinear_tf=True  # Apply sublinear tf scaling\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported feature type: {features}\")\n",
    "    \n",
    "    # Create a pipeline\n",
    "    classifier = Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('classifier', MultinomialNB(alpha=1.0))  # Laplace smoothing\n",
    "    ])\n",
    "    \n",
    "    # Train on the data\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    return classifier, vectorizer\n",
    "\n",
    "# Helper function for MaxEnt to get sentiment features\n",
    "def get_sentiment_features(tweet, positive_words, negative_words):\n",
    "    \"\"\"\n",
    "    Compute sentiment features using the Opinion Lexicon.\n",
    "    \"\"\"\n",
    "    tokens = tweet.lower().split()\n",
    "    pos_count = sum(1 for token in tokens if token in positive_words)\n",
    "    neg_count = sum(1 for token in tokens if token in negative_words)\n",
    "    total = len(tokens) if tokens else 1\n",
    "    # Compound score: normalized difference between positive and negative counts\n",
    "    compound = (pos_count - neg_count) / total\n",
    "    return np.array([pos_count, neg_count, compound])\n",
    "\n",
    "# Helper function for MaxEnt to create combined features\n",
    "def tweet_to_combined_features(tweet, embedding_dict, positive_words, negative_words, embedding_dim=100):\n",
    "    \"\"\"\n",
    "    Convert a tweet into a combined feature vector of embeddings and sentiment scores\n",
    "    \"\"\"\n",
    "    # Compute average GloVe embedding\n",
    "    tokens = tweet.split()\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        if token in embedding_dict:\n",
    "            vectors.append(embedding_dict[token])\n",
    "    \n",
    "    glove_feature = np.mean(vectors, axis=0) if vectors else np.zeros(embedding_dim)\n",
    "    \n",
    "    # Compute sentiment features from Opinion Lexicon\n",
    "    sentiment_feature = get_sentiment_features(tweet, positive_words, negative_words)\n",
    "    \n",
    "    # Concatenate both feature sets\n",
    "    combined_feature = np.concatenate([glove_feature, sentiment_feature])\n",
    "    return combined_feature\n",
    "\n",
    "# Helper function for MaxEnt to prepare feature matrix\n",
    "def prepare_combined_features(tweets_list, embedding_dict, positive_words, negative_words, embedding_dim=100):\n",
    "    \"\"\"\n",
    "    Prepare a feature matrix for all tweets\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for tweet in tweets_list:\n",
    "        feature_vector = tweet_to_combined_features(tweet, embedding_dict, positive_words, negative_words, embedding_dim)\n",
    "        features.append(feature_vector)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# For MaxEnt (Logistic Regression) with improved features (IMPROVED VERSION)\n",
    "def train_maxent(X_train, y_train, embedding_dict=None, positive_words=None, negative_words=None, preprocessed=False):\n",
    "    \"\"\"\n",
    "    Train a MaxEnt (Logistic Regression) classifier\n",
    "    If embedding_dict is provided, use combined word embeddings and sentiment features\n",
    "    \"\"\"\n",
    "    print(\"Training MaxEnt (Logistic Regression) classifier...\")\n",
    "    \n",
    "    # Prepare the features\n",
    "    if preprocessed:\n",
    "        # X_train is already processed into feature vectors\n",
    "        X_train_features = X_train\n",
    "        vectorizer = None\n",
    "    elif embedding_dict is not None and positive_words is not None and negative_words is not None:\n",
    "        print(\"Using combined embeddings and sentiment features\")\n",
    "        X_train_features = prepare_combined_features(X_train, embedding_dict, positive_words, negative_words)\n",
    "        vectorizer = None\n",
    "    else:\n",
    "        # Use TF-IDF if no embeddings provided\n",
    "        print(\"Using TF-IDF features (embeddings not available)\")\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            analyzer='word',\n",
    "            tokenizer=lambda x: x.split(),\n",
    "            preprocessor=None,\n",
    "            min_df=5,\n",
    "            max_df=0.7,\n",
    "            ngram_range=(1, 2)\n",
    "        )\n",
    "        X_train_features = vectorizer.fit_transform(X_train)\n",
    "    \n",
    "    # Set up parameter grid for grid search\n",
    "    param_grid = [\n",
    "        # {\n",
    "        #     'C': [0.1, 1.0, 10.0],\n",
    "        #     'penalty': ['l2'],\n",
    "        #     'solver': ['lbfgs'],\n",
    "        #     'class_weight': [None, 'balanced'],\n",
    "        #     'multi_class': ['multinomial']\n",
    "        # },\n",
    "        {\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear'],\n",
    "            'class_weight': [None, 'balanced'],\n",
    "            'multi_class': ['ovr']\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Create and train the classifier with grid search\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    grid_search = GridSearchCV(lr, param_grid, cv=3, scoring='f1_macro', n_jobs=-1)\n",
    "    grid_search.fit(X_train_features, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    \n",
    "    return best_model, vectorizer\n",
    "\n",
    "# Basic LSTM Model\n",
    "class BasicLSTMClassifier(nn.Module):\n",
    "    def __init__(self, num_words, embedding_dim, embedding_matrix, hidden_dim, num_classes):\n",
    "        super(BasicLSTMClassifier, self).__init__()\n",
    "        # Embedding layer with pretrained GloVe embeddings (frozen)\n",
    "        self.embedding = nn.Embedding(num_words, embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False  # Freeze the embedding layer\n",
    "        \n",
    "        # Single LSTM layer (not bidirectional)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Linear classifier layer\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len)\n",
    "        x = self.embedding(x)  # (batch, seq_len, embedding_dim)\n",
    "        # Pass through LSTM\n",
    "        lstm_out, (hidden, _) = self.lstm(x)  # hidden: (1, batch, hidden_dim)\n",
    "        \n",
    "        # Use the final hidden state for classification\n",
    "        hidden = hidden.squeeze(0)  # (batch, hidden_dim)\n",
    "        \n",
    "        # Pass through linear layer for classification\n",
    "        logits = self.fc(hidden)\n",
    "        return logits\n",
    "\n",
    "# Attention mechanism for Enhanced LSTM\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        # Compute attention weights from bidirectional LSTM outputs (hidden_dim*2)\n",
    "        self.attn = nn.Linear(hidden_dim * 2, 1)\n",
    "        \n",
    "    def forward(self, lstm_out):\n",
    "        # lstm_out: (batch, seq_len, hidden_dim*2)\n",
    "        weights = self.attn(lstm_out)             # (batch, seq_len, 1)\n",
    "        weights = torch.softmax(weights, dim=1)    # softmax over sequence length\n",
    "        context = torch.sum(weights * lstm_out, dim=1)  # weighted sum: (batch, hidden_dim*2)\n",
    "        return context\n",
    "\n",
    "# Enhanced LSTM Model with Attention\n",
    "class EnhancedLSTMClassifier(nn.Module):\n",
    "    def __init__(self, num_words, embedding_dim, embedding_matrix, hidden_dim, num_layers,\n",
    "                num_classes, dropout, num_engineered_features, engineered_hidden_dim):\n",
    "        super(EnhancedLSTMClassifier, self).__init__()\n",
    "        # Embedding layer with pretrained GloVe embeddings (frozen)\n",
    "        self.embedding = nn.Embedding(num_words, embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Attention mechanism over LSTM outputs\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        \n",
    "        # Global pooling layers (average and max pooling)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Engineered features branch\n",
    "        self.feat_fc = nn.Linear(num_engineered_features, engineered_hidden_dim)\n",
    "        # Feature gating parameter (learnable scalar)\n",
    "        self.feat_gate = nn.Parameter(torch.ones(1))\n",
    "        \n",
    "        # Combine LSTM branch and engineered features branch\n",
    "        # For LSTM branch, we use attention output (hidden_dim*2), average and max pool (each hidden_dim*2)\n",
    "        lstm_feature_dim = hidden_dim * 2 * 3  # 3 components concatenated\n",
    "        combined_dim = lstm_feature_dim + engineered_hidden_dim\n",
    "        self.fc_combined = nn.Linear(combined_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x, engineered_features):\n",
    "        # x: (batch, seq_len)\n",
    "        x = self.embedding(x)  # (batch, seq_len, embedding_dim)\n",
    "        lstm_out, _ = self.lstm(x)  # (batch, seq_len, hidden_dim*2)\n",
    "        \n",
    "        # Compute attention output\n",
    "        attn_out = self.attention(lstm_out)  # (batch, hidden_dim*2)\n",
    "        \n",
    "        # Global average pooling and max pooling\n",
    "        avg_pool = torch.mean(lstm_out, dim=1)        # (batch, hidden_dim*2)\n",
    "        max_pool, _ = torch.max(lstm_out, dim=1)        # (batch, hidden_dim*2)\n",
    "        \n",
    "        # Concatenate LSTM branch features\n",
    "        lstm_features = torch.cat((attn_out, avg_pool, max_pool), dim=1)  # (batch, hidden_dim*2*3)\n",
    "        lstm_features = self.dropout(lstm_features)\n",
    "        \n",
    "        # Engineered features branch\n",
    "        feat = self.feat_fc(engineered_features)  # (batch, engineered_hidden_dim)\n",
    "        feat = torch.relu(feat)\n",
    "        feat = self.dropout(feat)\n",
    "        # Apply gating: learned scalar controls the contribution of engineered features\n",
    "        feat = self.feat_gate * feat\n",
    "        \n",
    "        # Combine both branches\n",
    "        combined = torch.cat((lstm_features, feat), dim=1)  # (batch, combined_dim)\n",
    "        logits = self.fc_combined(combined)\n",
    "        return logits\n",
    "\n",
    "# Train LSTM Model\n",
    "def train_lstm_model(X_train, y_train, X_dev, y_dev, embedding_dict, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Train a basic LSTM model for sentiment classification with dev set validation\n",
    "    \"\"\"\n",
    "    print(\"Training Basic LSTM model...\")\n",
    "    \n",
    "    # Preprocessing for both train and dev\n",
    "    preprocessor = TwitterPreprocessor()\n",
    "    processed_train = [preprocessor.preprocess(tweet) for tweet in X_train]\n",
    "    processed_dev = [preprocessor.preprocess(tweet) for tweet in X_dev]\n",
    "    \n",
    "    # Convert labels to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_labels_int = label_encoder.fit_transform(y_train)\n",
    "    dev_labels_int = label_encoder.transform(y_dev)\n",
    "    \n",
    "    # Tokenize and pad sequences\n",
    "    max_sequence_length = 128\n",
    "    tokenizer = Tokenizer(num_words=5000)\n",
    "    tokenizer.fit_on_texts(processed_train)  # Fit only on training data\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    train_sequences = tokenizer.texts_to_sequences(processed_train)\n",
    "    train_data = pad_sequences(train_sequences, maxlen=max_sequence_length)\n",
    "    \n",
    "    dev_sequences = tokenizer.texts_to_sequences(processed_dev)\n",
    "    dev_data = pad_sequences(dev_sequences, maxlen=max_sequence_length)\n",
    "    \n",
    "    # Prepare embedding matrix\n",
    "    embedding_dim = 100\n",
    "    num_words = min(5000, len(word_index) + 1)\n",
    "    embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        if i >= num_words:\n",
    "            continue\n",
    "        embedding_vector = embedding_dict.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    # Setup model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    hidden_dim = 128\n",
    "    num_classes = len(set(y_train))\n",
    "    \n",
    "    model = BasicLSTMClassifier(\n",
    "        num_words=num_words,\n",
    "        embedding_dim=embedding_dim,\n",
    "        embedding_matrix=embedding_matrix,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "    # Training setup\n",
    "    batch_size = 64\n",
    "    train_tensor = torch.tensor(train_data, dtype=torch.long)\n",
    "    train_labels_tensor = torch.tensor(train_labels_int, dtype=torch.long)\n",
    "    train_dataset = TensorDataset(train_tensor, train_labels_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Dev setup\n",
    "    dev_tensor = torch.tensor(dev_data, dtype=torch.long)\n",
    "    dev_labels_tensor = torch.tensor(dev_labels_int, dtype=torch.long)\n",
    "    dev_dataset = TensorDataset(dev_tensor, dev_labels_tensor)\n",
    "    dev_loader = DataLoader(dev_dataset, batch_size=batch_size)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=2, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    best_dev_acc = 0\n",
    "    patience = 3\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_inputs, batch_labels in train_loader:\n",
    "            batch_inputs = batch_inputs.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_inputs)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * batch_inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += batch_labels.size(0)\n",
    "            correct += (predicted == batch_labels).sum().item()\n",
    "        \n",
    "        train_loss = epoch_loss / total\n",
    "        train_accuracy = correct / total\n",
    "        \n",
    "        # Evaluate on dev set\n",
    "        model.eval()\n",
    "        dev_loss = 0.0\n",
    "        dev_correct = 0\n",
    "        dev_total = 0\n",
    "        with torch.no_grad():\n",
    "            for dev_inputs, dev_labels in dev_loader:\n",
    "                dev_inputs = dev_inputs.to(device)\n",
    "                dev_labels = dev_labels.to(device)\n",
    "                outputs = model(dev_inputs)\n",
    "                loss = criterion(outputs, dev_labels)\n",
    "                dev_loss += loss.item() * dev_inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                dev_total += dev_labels.size(0)\n",
    "                dev_correct += (predicted == dev_labels).sum().item()\n",
    "                \n",
    "        dev_loss = dev_loss / dev_total\n",
    "        dev_accuracy = dev_correct / dev_total\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f} | Dev Loss: {dev_loss:.4f}, Dev Acc: {dev_accuracy:.4f}\")\n",
    "        \n",
    "        # Learning rate scheduling and early stopping based on dev accuracy\n",
    "        scheduler.step(dev_accuracy)\n",
    "        if dev_accuracy > best_dev_acc:\n",
    "            best_dev_acc = dev_accuracy\n",
    "            patience_counter = 0\n",
    "            # Save the best model state\n",
    "            torch.save(model.state_dict(), 'best_lstm_model.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "    \n",
    "    # Load the best model if it was saved\n",
    "    try:\n",
    "        model.load_state_dict(torch.load('best_lstm_model.pt'))\n",
    "        print(f\"Loaded the best model (Dev accuracy: {best_dev_acc:.4f})\")\n",
    "    except:\n",
    "        print(\"Could not load the best model, using the last model\")\n",
    "    \n",
    "    return model, tokenizer, label_encoder, max_sequence_length\n",
    "\n",
    "# Function to preprocess tweets\n",
    "def preprocess_tweet(tweet):\n",
    "    \"\"\"Simple preprocessing function if the TwitterPreprocessor is not available\"\"\"\n",
    "    # Convert to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'https?://\\S+|www\\.\\S+', '', tweet)\n",
    "    # Remove mentions\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)\n",
    "    # Remove extra whitespace\n",
    "    tweet = ' '.join(tweet.split())\n",
    "    return tweet\n",
    "\n",
    "# Function to prepare embedding features\n",
    "def prepare_embedding_features(tweets, embedding_dict, embedding_dim=100):\n",
    "    \"\"\"\n",
    "    Create feature vectors based on word embeddings\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for tweet in tweets:\n",
    "        tokens = tweet.split()\n",
    "        # Get embedding for each token and average them\n",
    "        token_embeddings = [embedding_dict.get(token, np.zeros(embedding_dim)) for token in tokens if token]\n",
    "        if not token_embeddings:\n",
    "            tweet_vector = np.zeros(embedding_dim)\n",
    "        else:\n",
    "            tweet_vector = np.mean(token_embeddings, axis=0)\n",
    "        features.append(tweet_vector)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# Function to predict sentiments for Naive Bayes\n",
    "def predict_with_naive_bayes(classifier, tweets):\n",
    "    \"\"\"\n",
    "    Predict sentiments using Naive Bayes pipeline\n",
    "    \"\"\"\n",
    "    # The classifier is a pipeline with preprocessing included\n",
    "    predictions = classifier.predict(tweets)\n",
    "    return predictions\n",
    "\n",
    "# Function to predict sentiments for MaxEnt and convert to dictionary format\n",
    "def predict_with_maxent(classifier, vectorizer, X_test, tweetids, embedding_dict=None, positive_words=None, negative_words=None):\n",
    "    \"\"\"\n",
    "    Predict sentiments using MaxEnt model and appropriate features\n",
    "    \"\"\"\n",
    "    # Transform test data using appropriate method\n",
    "    if vectorizer:\n",
    "        X_test_features = vectorizer.transform(X_test)\n",
    "    elif embedding_dict is not None and positive_words is not None and negative_words is not None:\n",
    "        # Use combined features\n",
    "        X_test_features = prepare_combined_features(X_test, embedding_dict, positive_words, negative_words)\n",
    "    else:\n",
    "        # Assume X_test is already processed\n",
    "        X_test_features = X_test\n",
    "    \n",
    "    # Get the predictions\n",
    "    predictions = classifier.predict(X_test_features)\n",
    "    \n",
    "    # Create dictionary of tweet_id to predicted sentiment\n",
    "    id_preds = {}\n",
    "    for i, pred in enumerate(predictions):\n",
    "        id_preds[tweetids[i]] = pred\n",
    "        \n",
    "    return id_preds\n",
    "\n",
    "# Function to predict sentiments for LSTM\n",
    "def predict_with_lstm(model, tokenizer, label_encoder, X_test, tweetids, max_length, \n",
    "                     is_enhanced=False, positive_words=None, negative_words=None):\n",
    "    \"\"\"\n",
    "    Predict sentiments using LSTM model\n",
    "    \"\"\"\n",
    "    # Preprocess test data\n",
    "    preprocessor = TwitterPreprocessor()\n",
    "    processed_test = [preprocessor.preprocess(tweet) for tweet in X_test]\n",
    "    \n",
    "    # Tokenize and pad\n",
    "    test_sequences = tokenizer.texts_to_sequences(processed_test)\n",
    "    test_data = pad_sequences(test_sequences, maxlen=max_length)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    test_tensor = torch.tensor(test_data, dtype=torch.long)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    \n",
    "    # For Enhanced LSTM, we need engineered features\n",
    "    if is_enhanced:\n",
    "        # Extract engineered features\n",
    "        test_engineered = extract_engineered_features(processed_test, positive_words, negative_words)\n",
    "        test_engineered_tensor = torch.tensor(test_engineered, dtype=torch.float32)\n",
    "        \n",
    "        # Create test dataset and loader\n",
    "        test_dataset = TensorDataset(test_tensor, test_engineered_tensor)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "        \n",
    "        # Make predictions\n",
    "        with torch.no_grad():\n",
    "            for inputs, engineered in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                engineered = engineered.to(device)\n",
    "                outputs = model(inputs, engineered)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "    else:\n",
    "        # Basic LSTM doesn't need engineered features\n",
    "        # Create test dataset and loader\n",
    "        test_dataset = TensorDataset(test_tensor)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "        \n",
    "        # Make predictions\n",
    "        with torch.no_grad():\n",
    "            for (inputs,) in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # Convert numerical predictions back to original labels\n",
    "    predictions = label_encoder.inverse_transform(all_preds)\n",
    "    \n",
    "    # Create dictionary of tweet_id to predicted sentiment\n",
    "    id_preds = {}\n",
    "    for i, pred in enumerate(predictions):\n",
    "        id_preds[tweetids[i]] = pred\n",
    "        \n",
    "    return id_preds\n",
    "\n",
    "# Extract engineered features for Enhanced LSTM\n",
    "def extract_engineered_features(tweets, positive_words, negative_words):\n",
    "    \"\"\"\n",
    "    Extracts engineered features from tweets:\n",
    "      - Lexicon counts: positive and negative word counts (2 features)\n",
    "      - Ratio of positive to negative words (1 feature)\n",
    "      - Sentiment score: (pos - neg) / (pos + neg) (1 feature)\n",
    "      - Tweet length in words (1 feature)\n",
    "      - Capitalization ratio (1 feature)\n",
    "    Total = 6 features per tweet.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        tokens = tweet.split()\n",
    "        text_length = len(tokens)\n",
    "        uppercase_count = sum(1 for c in tweet if c.isupper())\n",
    "        \n",
    "        # Lexicon-based counts using Opinion Lexicon\n",
    "        pos_count = sum(1 for t in tokens if t.lower() in positive_words)\n",
    "        neg_count = sum(1 for t in tokens if t.lower() in negative_words)\n",
    "        \n",
    "        # Calculate ratio (handle division by zero)\n",
    "        pos_neg_ratio = pos_count / max(1, neg_count)\n",
    "        \n",
    "        # Calculate sentiment score: (pos - neg) / (pos + neg)\n",
    "        total_sentiment_words = pos_count + neg_count\n",
    "        sentiment_score = 0 if total_sentiment_words == 0 else (pos_count - neg_count) / total_sentiment_words\n",
    "        \n",
    "        # Calculate capitalization ratio\n",
    "        cap_ratio = 0 if len(tweet) == 0 else uppercase_count / len(tweet)\n",
    "        \n",
    "        # Combine all features\n",
    "        features.append([pos_count, neg_count, pos_neg_ratio, sentiment_score, text_length, cap_ratio])\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# Train Enhanced LSTM Model\n",
    "def train_enhanced_lstm_model(X_train, y_train, X_dev, y_dev, embedding_dict, positive_words, negative_words, num_epochs=15):\n",
    "    \"\"\"\n",
    "    Train an enhanced LSTM model with attention for sentiment classification with dev set validation\n",
    "    \"\"\"\n",
    "    print(\"Training Enhanced LSTM with Attention model...\")\n",
    "    \n",
    "    # Preprocessing for both train and dev\n",
    "    preprocessor = TwitterPreprocessor()\n",
    "    processed_train = [preprocessor.preprocess(tweet) for tweet in X_train]\n",
    "    processed_dev = [preprocessor.preprocess(tweet) for tweet in X_dev]\n",
    "    \n",
    "    # Extract engineered features for both train and dev\n",
    "    train_engineered = extract_engineered_features(processed_train, positive_words, negative_words)\n",
    "    dev_engineered = extract_engineered_features(processed_dev, positive_words, negative_words)\n",
    "    \n",
    "    # Convert labels to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_labels_int = label_encoder.fit_transform(y_train)\n",
    "    dev_labels_int = label_encoder.transform(y_dev)\n",
    "    \n",
    "    # Tokenize and pad sequences\n",
    "    max_sequence_length = 128\n",
    "    tokenizer = Tokenizer(num_words=40000)  # Increased vocabulary size\n",
    "    tokenizer.fit_on_texts(processed_train)  # Fit only on training data\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    train_sequences = tokenizer.texts_to_sequences(processed_train)\n",
    "    train_data = pad_sequences(train_sequences, maxlen=max_sequence_length)\n",
    "    \n",
    "    dev_sequences = tokenizer.texts_to_sequences(processed_dev)\n",
    "    dev_data = pad_sequences(dev_sequences, maxlen=max_sequence_length)\n",
    "    \n",
    "    # Prepare embedding matrix\n",
    "    embedding_dim = 100\n",
    "    num_words = min(40000, len(word_index) + 1)  # Increased vocabulary size\n",
    "    embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        if i >= num_words:\n",
    "            continue\n",
    "        embedding_vector = embedding_dict.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    # Setup model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    hidden_dim = 128\n",
    "    num_classes = len(set(y_train))\n",
    "    num_layers = 2\n",
    "    dropout = 0.5\n",
    "    num_engineered_features = train_engineered.shape[1]  # Dynamic based on extracted features\n",
    "    engineered_hidden_dim = 32\n",
    "    \n",
    "    model = EnhancedLSTMClassifier(\n",
    "        num_words=num_words,\n",
    "        embedding_dim=embedding_dim,\n",
    "        embedding_matrix=embedding_matrix,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        num_classes=num_classes,\n",
    "        dropout=dropout,\n",
    "        num_engineered_features=num_engineered_features,\n",
    "        engineered_hidden_dim=engineered_hidden_dim\n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "    # Training setup\n",
    "    batch_size = 64\n",
    "    train_tensor = torch.tensor(train_data, dtype=torch.long)\n",
    "    train_engineered_tensor = torch.tensor(train_engineered, dtype=torch.float32)\n",
    "    train_labels_tensor = torch.tensor(train_labels_int, dtype=torch.long)\n",
    "    train_dataset = TensorDataset(train_tensor, train_engineered_tensor, train_labels_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Dev setup\n",
    "    dev_tensor = torch.tensor(dev_data, dtype=torch.long)\n",
    "    dev_engineered_tensor = torch.tensor(dev_engineered, dtype=torch.float32)\n",
    "    dev_labels_tensor = torch.tensor(dev_labels_int, dtype=torch.long)\n",
    "    dev_dataset = TensorDataset(dev_tensor, dev_engineered_tensor, dev_labels_tensor)\n",
    "    dev_loader = DataLoader(dev_dataset, batch_size=batch_size)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # weight decay for regularization\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=2, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    best_dev_acc = 0\n",
    "    patience = 3\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_inputs, batch_engineered, batch_labels in train_loader:\n",
    "            batch_inputs = batch_inputs.to(device)\n",
    "            batch_engineered = batch_engineered.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_inputs, batch_engineered)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * batch_inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += batch_labels.size(0)\n",
    "            correct += (predicted == batch_labels).sum().item()\n",
    "        \n",
    "        train_loss = epoch_loss / total\n",
    "        train_accuracy = correct / total\n",
    "        \n",
    "        # Evaluate on dev set\n",
    "        model.eval()\n",
    "        dev_loss = 0.0\n",
    "        dev_correct = 0\n",
    "        dev_total = 0\n",
    "        with torch.no_grad():\n",
    "            for dev_inputs, dev_engineered, dev_labels in dev_loader:\n",
    "                dev_inputs = dev_inputs.to(device)\n",
    "                dev_engineered = dev_engineered.to(device)\n",
    "                dev_labels = dev_labels.to(device)\n",
    "                outputs = model(dev_inputs, dev_engineered)\n",
    "                loss = criterion(outputs, dev_labels)\n",
    "                dev_loss += loss.item() * dev_inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                dev_total += dev_labels.size(0)\n",
    "                dev_correct += (predicted == dev_labels).sum().item()\n",
    "                \n",
    "        dev_loss = dev_loss / dev_total\n",
    "        dev_accuracy = dev_correct / dev_total\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f} | Dev Loss: {dev_loss:.4f}, Dev Acc: {dev_accuracy:.4f}\")\n",
    "        \n",
    "        # Learning rate scheduling and early stopping based on dev accuracy\n",
    "        scheduler.step(dev_accuracy)\n",
    "        if dev_accuracy > best_dev_acc:\n",
    "            best_dev_acc = dev_accuracy\n",
    "            patience_counter = 0\n",
    "            # Save the best model state\n",
    "            torch.save(model.state_dict(), 'best_enhanced_lstm_model.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "    \n",
    "    # Load the best model if it was saved\n",
    "    try:\n",
    "        model.load_state_dict(torch.load('best_enhanced_lstm_model.pt'))\n",
    "        print(f\"Loaded the best model (Dev accuracy: {best_dev_acc:.4f})\")\n",
    "    except:\n",
    "        print(\"Could not load the best model, using the last model\")\n",
    "    \n",
    "    return model, tokenizer, label_encoder, max_sequence_length\n",
    "\n",
    "# Load GloVe embeddings\n",
    "def load_glove_embeddings(glove_file_path):\n",
    "    \"\"\"\n",
    "    Load GloVe word embeddings from file\n",
    "    \"\"\"\n",
    "    print(\"Loading GloVe embeddings...\")\n",
    "    embedding_dict = {}\n",
    "    embedding_dim = 100\n",
    "    \n",
    "    try:\n",
    "        with open(glove_file_path, encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                values = line.strip().split()\n",
    "                word = values[0]\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                if len(vector) == embedding_dim:\n",
    "                    embedding_dict[word] = vector\n",
    "        print(f\"Loaded {len(embedding_dict)} word vectors\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: GloVe file {glove_file_path} not found. Using empty embeddings.\")\n",
    "    \n",
    "    return embedding_dict, embedding_dim\n",
    "\n",
    "# Main function to run the sentiment analysis\n",
    "def main():\n",
    "    # Load the datasets\n",
    "    base_dir = 'semeval-tweets/semeval-tweets'\n",
    "    print(\"Loading datasets...\")\n",
    "    data, tweetids, tweetgts, tweets = load_datasets(base_dir)\n",
    "\n",
    "    # Initialize the preprocessor\n",
    "    preprocessor = TwitterPreprocessor(\n",
    "        remove_urls=True,\n",
    "        remove_mentions=True,\n",
    "        replace_emojis=True,\n",
    "        handle_negations=True,\n",
    "        replace_elongations=True,\n",
    "        handle_hashtags=True,\n",
    "        remove_numbers=True\n",
    "    )\n",
    "\n",
    "    # Preprocess the tweets\n",
    "    print(\"Preprocessing tweets...\")\n",
    "    preprocessed_tweets = {}\n",
    "    for dataset in data:\n",
    "        preprocessed_tweets[dataset] = [preprocessor.preprocess(tweet) for tweet in tweets[dataset]]\n",
    "\n",
    "    # Try to load GloVe embeddings (if available)\n",
    "    glove_file_path = \"glove.6B.100d.txt\"\n",
    "    embedding_dict, embedding_dim = load_glove_embeddings(glove_file_path)\n",
    "\n",
    "    # Try to load opinion lexicon (if available)\n",
    "    positive_lexicon_file = 'positive-words.txt'\n",
    "    negative_lexicon_file = 'negative-words.txt'\n",
    "    positive_words, negative_words = load_opinion_lexicon(positive_lexicon_file, negative_lexicon_file)\n",
    "\n",
    "    # Get training data\n",
    "    X_train = preprocessed_tweets['twitter-training-data.txt']\n",
    "    y_train = tweetgts['twitter-training-data.txt']\n",
    "    \n",
    "    # Get dev data\n",
    "    X_dev = preprocessed_tweets['twitter-dev-data.txt']\n",
    "    y_dev = tweetgts['twitter-dev-data.txt']\n",
    "\n",
    "    # Build sentiment classifiers\n",
    "    print(\"Building and evaluating classifiers...\")\n",
    "    for classifier in ['naive_bayes', 'maxent', 'lstm', 'enhanced_lstm']:\n",
    "        for features in ['bow', 'tfidf', 'embeddings']:\n",
    "            # Skip incompatible combinations\n",
    "            if classifier in ['lstm', 'enhanced_lstm'] and features in ['bow', 'tfidf']:\n",
    "                continue\n",
    "            if classifier == 'naive_bayes' and features == 'embeddings':\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\nTraining {classifier} with {features} features...\")\n",
    "            \n",
    "            # Train the classifier\n",
    "            if classifier == 'naive_bayes':\n",
    "                clf, feature_extractor = train_naive_bayes(X_train, y_train, features=features)\n",
    "                \n",
    "            elif classifier == 'maxent':\n",
    "                if features == 'embeddings':\n",
    "                    # Use combined features (embeddings + sentiment scores) for MaxEnt\n",
    "                    if embedding_dict and positive_words and negative_words:\n",
    "                        clf, feature_extractor = train_maxent(\n",
    "                            X_train, y_train, \n",
    "                            embedding_dict=embedding_dict,\n",
    "                            positive_words=positive_words,\n",
    "                            negative_words=negative_words\n",
    "                        )\n",
    "                    else:\n",
    "                        print(\"Embeddings or lexicon not available, using TF-IDF instead\")\n",
    "                        clf, feature_extractor = train_maxent(X_train, y_train)\n",
    "                else:\n",
    "                    clf, feature_extractor = train_maxent(X_train, y_train)\n",
    "                    \n",
    "            elif classifier == 'lstm':\n",
    "                # LSTM only uses embeddings and now includes dev set\n",
    "                if embedding_dict:\n",
    "                    model, tokenizer, label_encoder, max_length = train_lstm_model(\n",
    "                        X_train, y_train, X_dev, y_dev, embedding_dict\n",
    "                    )\n",
    "                else:\n",
    "                    print(\"Embeddings not available for LSTM, skipping\")\n",
    "                    continue\n",
    "                    \n",
    "            elif classifier == 'enhanced_lstm':\n",
    "                # Enhanced LSTM needs embeddings and lexicon data and now includes dev set\n",
    "                if embedding_dict and (positive_words or negative_words):\n",
    "                    model, tokenizer, label_encoder, max_length = train_enhanced_lstm_model(\n",
    "                        X_train, y_train, X_dev, y_dev, embedding_dict, positive_words, negative_words\n",
    "                    )\n",
    "                else:\n",
    "                    print(\"Embeddings or lexicon not available for Enhanced LSTM, skipping\")\n",
    "                    continue\n",
    "            \n",
    "            # Evaluate on each test set\n",
    "            for test_set in testsets:\n",
    "                print(f\"\\nEvaluating on {test_set}...\")\n",
    "                \n",
    "                # Get test data\n",
    "                X_test = preprocessed_tweets[test_set]\n",
    "                test_ids = tweetids[test_set]\n",
    "                \n",
    "                # Make predictions\n",
    "                if classifier == 'naive_bayes':\n",
    "                    # Use the pipeline directly for Naive Bayes\n",
    "                    predictions = predict_with_naive_bayes(clf, X_test)\n",
    "                    id_preds = {test_ids[i]: predictions[i] for i in range(len(test_ids))}\n",
    "                \n",
    "                elif classifier == 'maxent':\n",
    "                    if features == 'embeddings' and embedding_dict and positive_words and negative_words:\n",
    "                        # Use combined features for prediction\n",
    "                        id_preds = predict_with_maxent(\n",
    "                            clf, None, X_test, test_ids, \n",
    "                            embedding_dict=embedding_dict,\n",
    "                            positive_words=positive_words,\n",
    "                            negative_words=negative_words\n",
    "                        )\n",
    "                    else:\n",
    "                        id_preds = predict_with_maxent(clf, feature_extractor, X_test, test_ids)\n",
    "                        \n",
    "                elif classifier == 'lstm':\n",
    "                    id_preds = predict_with_lstm(model, tokenizer, label_encoder, X_test, test_ids, max_length)\n",
    "                    \n",
    "                elif classifier == 'enhanced_lstm':\n",
    "                    id_preds = predict_with_lstm(\n",
    "                        model, tokenizer, label_encoder, X_test, test_ids, max_length, \n",
    "                        is_enhanced=True, positive_words=positive_words, negative_words=negative_words\n",
    "                    )\n",
    "                \n",
    "                # Evaluate predictions\n",
    "                testset_path = join(base_dir, test_set)\n",
    "                evaluate(id_preds, testset_path, f\"{features}-{classifier}\")\n",
    "                confusion(id_preds, testset_path, f\"{features}-{classifier}\")\n",
    "\n",
    "    print(\"\\nModel comparison completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
